@prefix ns1: <http://example.org/course/> .
@prefix ns2: <http://align.org/> .
@prefix ns3: <http://provo.org/> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

ns1:UE_X31A060 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.64215916"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap: Lecture focuses on scientific English communication skills, while KU addresses programming language design, accessibility, and ethics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.64215916"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on scientific communication in English, while the KU covers programming languages and accessibility." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Design_Design_Principles_of_Programming_Languages.txt> ;
            ns2:ku_text """Pages: 146-147 HOURS CS Core = 0 KA Core = 0 FPL-Design: Design Principles of
Programming Languages Non-core: 1\\. Language design principles a. Simplicity
b. Security (See also: SEC-Coding) c. Fast translation d. Efficient object
code e. Orthogonality f. Readability g. Completeness h. Implementation
strategies 2\\. Designing a language to fit a specific domain or problem 3\\.
Interoperability between programming languages 4\\. Language portability 5\\.
Formal description of a programming language 6\\. Green computing principles
(See also: SEP-Sustainability) Illustrative Learning Outcomes: Non-core: 1\\.
Understand what constitutes good language design and apply that knowledge to
evaluate a real programming language."""^^xsd:string ;
            ns2:score "0.63870883"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on communication skills in English for scientific purposes, whereas the KU discusses design principles of programming languages, which are unrelated topics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Design_Design_Principles_of_Programming_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.64215916"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics related to scientific communication, vocabulary development, and presentation skills, which align with the knowledge unit's focus on programming languages, accessibility, and inclusivity." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns2:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns2:score "0.64577204"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on scientific communication in English, while the KU covers technical NLP topics." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns2:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns2:score "0.64577204"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on communication skills in English for scientific purposes, whereas the KU covers Natural Language Processing topics, such as grammars, parsing, semantics, and machine learning." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Design_Design_Principles_of_Programming_Languages.txt> ;
            ns2:ku_text """Pages: 146-147 HOURS CS Core = 0 KA Core = 0 FPL-Design: Design Principles of
Programming Languages Non-core: 1\\. Language design principles a. Simplicity
b. Security (See also: SEC-Coding) c. Fast translation d. Efficient object
code e. Orthogonality f. Readability g. Completeness h. Implementation
strategies 2\\. Designing a language to fit a specific domain or problem 3\\.
Interoperability between programming languages 4\\. Language portability 5\\.
Formal description of a programming language 6\\. Green computing principles
(See also: SEP-Sustainability) Illustrative Learning Outcomes: Non-core: 1\\.
Understand what constitutes good language design and apply that knowledge to
evaluate a real programming language."""^^xsd:string ;
            ns2:score "0.63870883"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in topics; lecture focuses on communication skills while KU covers programming language design principles." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Design_Design_Principles_of_Programming_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Design_Design_Principles_of_Programming_Languages.txt> ;
            ns2:ku_text """Pages: 146-147 HOURS CS Core = 0 KA Core = 0 FPL-Design: Design Principles of
Programming Languages Non-core: 1\\. Language design principles a. Simplicity
b. Security (See also: SEC-Coding) c. Fast translation d. Efficient object
code e. Orthogonality f. Readability g. Completeness h. Implementation
strategies 2\\. Designing a language to fit a specific domain or problem 3\\.
Interoperability between programming languages 4\\. Language portability 5\\.
Formal description of a programming language 6\\. Green computing principles
(See also: SEP-Sustainability) Illustrative Learning Outcomes: Non-core: 1\\.
Understand what constitutes good language design and apply that knowledge to
evaluate a real programming language."""^^xsd:string ;
            ns2:score "0.63870883"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on communication skills in English for scientific purposes, whereas the KU discusses design principles of programming languages, which are unrelated topics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Design_Design_Principles_of_Programming_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns2:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns2:score "0.64577204"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on scientific communication in English, while the KU covers technical NLP topics." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Design_Design_Principles_of_Programming_Languages.txt> ;
            ns2:ku_text """Pages: 146-147 HOURS CS Core = 0 KA Core = 0 FPL-Design: Design Principles of
Programming Languages Non-core: 1\\. Language design principles a. Simplicity
b. Security (See also: SEC-Coding) c. Fast translation d. Efficient object
code e. Orthogonality f. Readability g. Completeness h. Implementation
strategies 2\\. Designing a language to fit a specific domain or problem 3\\.
Interoperability between programming languages 4\\. Language portability 5\\.
Formal description of a programming language 6\\. Green computing principles
(See also: SEP-Sustainability) Illustrative Learning Outcomes: Non-core: 1\\.
Understand what constitutes good language design and apply that knowledge to
evaluate a real programming language."""^^xsd:string ;
            ns2:score "0.63870883"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on scientific communication in English, while the KU covers programming language design principles." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Design_Design_Principles_of_Programming_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Design_Design_Principles_of_Programming_Languages.txt> ;
            ns2:ku_text """Pages: 146-147 HOURS CS Core = 0 KA Core = 0 FPL-Design: Design Principles of
Programming Languages Non-core: 1\\. Language design principles a. Simplicity
b. Security (See also: SEC-Coding) c. Fast translation d. Efficient object
code e. Orthogonality f. Readability g. Completeness h. Implementation
strategies 2\\. Designing a language to fit a specific domain or problem 3\\.
Interoperability between programming languages 4\\. Language portability 5\\.
Formal description of a programming language 6\\. Green computing principles
(See also: SEP-Sustainability) Illustrative Learning Outcomes: Non-core: 1\\.
Understand what constitutes good language design and apply that knowledge to
evaluate a real programming language."""^^xsd:string ;
            ns2:score "0.63870883"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on scientific communication in English, while the KU covers programming language design principles." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Design_Design_Principles_of_Programming_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns2:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns2:score "0.64577204"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on communication skills in English for scientific purposes, whereas the KU covers Natural Language Processing topics, such as grammars, parsing, semantics, and machine learning." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.64215916"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap: Lecture focuses on scientific English communication skills, while KU addresses programming language design, accessibility, and ethics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.64215916"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics related to scientific communication, vocabulary development, and presentation skills, which align with the knowledge unit's focus on programming languages, accessibility, and inclusivity." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Design_Design_Principles_of_Programming_Languages.txt> ;
            ns2:ku_text """Pages: 146-147 HOURS CS Core = 0 KA Core = 0 FPL-Design: Design Principles of
Programming Languages Non-core: 1\\. Language design principles a. Simplicity
b. Security (See also: SEC-Coding) c. Fast translation d. Efficient object
code e. Orthogonality f. Readability g. Completeness h. Implementation
strategies 2\\. Designing a language to fit a specific domain or problem 3\\.
Interoperability between programming languages 4\\. Language portability 5\\.
Formal description of a programming language 6\\. Green computing principles
(See also: SEP-Sustainability) Illustrative Learning Outcomes: Non-core: 1\\.
Understand what constitutes good language design and apply that knowledge to
evaluate a real programming language."""^^xsd:string ;
            ns2:score "0.63870883"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in topics; lecture focuses on communication skills while KU covers programming language design principles." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Design_Design_Principles_of_Programming_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.64215916"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on scientific communication in English, while the KU covers programming languages and accessibility." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns2:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns2:score "0.64577204"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in topics: lecture focuses on language communication skills, KU covers NLP technical concepts." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns2:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns2:score "0.64577204"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in topics: lecture focuses on language communication skills, KU covers NLP technical concepts." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns2:uetext """Label: Anglais pour la communication scientifique (info) Objectif: (résultats d'apprentissage)
replacer l’article dans son contexte et expliquer les enjeux de la recherche ou de la thématique
abordée dans cet article.
3. présenter son travail dans un anglais clair et phonologiquement approprié, en utilisant des outils
de présentation adaptés et en communiquant avec un degré d’aisance et de spontanéité qui rende
possible une interaction normale avec un locuteur natif, sans recours excessif aux notes.
1. Développement du vocabulaire scientifique général
2. Développement du vocabulaire scientifique de spécialité
3. Analyse de textes scientifiques
4. Développement de la capacité à adapter son discours à différentes situations de communication Course content: scientifique
4. Analyse de documents audio ou vidéo
5. Pratique de l’oral en contexte
6. Sensibilisation au système phonologique de l’anglais pour améliorer la prise de parole des
étudiant-e-s Course name: http://example.org/course/UE_X31A060""" .

ns1:UE_X31I010 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.70884264"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on formal aspects and verification, lacking coverage of common algorithms and their examples as in the KU." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.7138155"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on algorithm verification/complexity, while KU emphasizes logic programming fundamentals (unification, Horn clauses, etc.) not directly covered." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.7138155"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as algorithm verification, program verification, and logic programming, which are all relevant to the Knowledge Unit." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.6867994"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including formal automata, formal languages, and algorithmic correctness, but does not delve into quantum computation." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.6867994"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including formal automata, formal languages, and algorithmic correctness, but does not delve into quantum computation." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.7138155"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on algorithm verification and complexity, while the KU covers logic programming concepts." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.70884264"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on formal aspects and verification, lacking coverage of common algorithms and their examples as in the KU." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.70884264"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the objectives of writing formal reductions, choosing properties to prove an algorithm's complexity, and writing proofs of correction and complexity, which aligns with the KU's learning outcomes." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.6867994"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on algorithm verification and complexity, while KU emphasizes automata, computability, and formal languages with minimal overlap." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.6867994"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on algorithm verification and correctness, lacking the broad theoretical coverage of the KU." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.7138155"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on algorithm verification and complexity, while the KU covers logic programming concepts." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.70884264"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on formal proofs and complexity reductions, while KU emphasizes algorithm concepts, common examples, and performance impacts." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.7138155"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as algorithm verification, program verification, and logic programming, which are all relevant to the Knowledge Unit." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.6867994"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on algorithm verification and complexity, while KU emphasizes automata, computability, and formal languages with minimal overlap." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.70884264"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the objectives of writing formal reductions, choosing properties to prove an algorithm's complexity, and writing proofs of correction and complexity, which aligns with the KU's learning outcomes." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.70884264"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on formal proofs and complexity reductions, while KU emphasizes algorithm concepts, common examples, and performance impacts." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.7138155"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on algorithm verification/complexity, while KU emphasizes logic programming fundamentals (unification, Horn clauses, etc.) not directly covered." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.6867994"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on algorithm verification and correctness, lacking the broad theoretical coverage of the KU." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns2:uetext """Label: Etude des algorithmes Objectif: (résultats d'apprentissage) - Être capable d'écrire formellement des réductions, simples, de NP-complétude
- Savoir choisir des propriétés à vérifier pour prouver un algorithme et pour établir sa complexité
temporelle
- Savoir écrire, pour des algorithmes simples, des preuves de correction et des preuves de
complexité temporelle
- Être capable de travailler en groupe Course content: Vérification de programme
• Vérification dynamiques : aléatoire ; fonctionnelle ; structurelle
• Vérification statique : informelle ; formelle (Hoare et Dijkstra) : correction, terminaison. Course name: http://example.org/course/UE_X31I010""" .

ns1:UE_X31I020 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.7006189"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "Covers tree/graph algorithms, complexity calculation, and efficiency analysis aligned with KU's core topics." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Discrete_Discrete_Mathematics.txt> ;
            ns2:ku_text """Pages: 187-188 HOURS CS Core = 29 KA Core = 11 MSF-Discrete: Discrete
Mathematics CS Core: 1\\. Sets, relations, functions, cardinality 2\\. Recursive
mathematical definitions 3\\. Proof techniques (induction, proof by
contradiction) 4\\. Permutations, combinations, counting, pigeonhole principle
5\\. Modular arithmetic 6\\. Logic: truth tables, connectives (operators),
inference rules, formulas, normal forms, simple predicate logic 7\\. Graphs:
basic definitions 8\\. Order notation Illustrative Learning Outcomes: CS Core:
1\\. Sets, Relations, and Functions, Cardinality a. Explain with examples the
basic terminology of functions, relations, and sets. b. Perform the operations
associated with sets, functions, and relations. c. Relate practical examples
to the appropriate set, function, or relation model, and interpret the
associated operations and terminology in context. d. Calculate the size of a
finite set, including making use of the sum and product rules and inclusion-
exclusion principle. e. Explain the difference between finite, countable, and
uncountable sets. 2\\. Recursive mathematical definitions a. Apply recursive
definitions of sequences or structures (e.g., Fibonacci numbers, linked lists,
parse trees, fractals). b. Formulate inductive proofs of statements about
recursive definitions. c. Solve a variety of basic recurrence relations. d.
Analyze a problem to determine underlying recurrence relations. e. Given a
recursive/iterative code snippet, describe its underlying recurrence relation,
hypothesize a closed form for the recurrence relation, and prove the
hypothesis correct (usually, using induction). 3\\. Proof Techniques a.
Identify the proof technique used in a given proof. b. Outline the basic
structure of each proof technique (direct proof, proof by contradiction, and
induction) described in this unit. c. Apply each of the proof techniques
(direct proof, proof by contradiction, and induction) correctly in the
construction of a sound argument. d. Determine which type of proof is best for
a given problem. e. Explain the parallels between ideas of mathematical and/or
structural induction to recursion and recursively defined structures. f.
Explain the relationship between weak and strong induction and give examples
of the appropriate use of each. 4\\. Permutations, combinations, and counting
a. Apply counting arguments, including sum and product rules, inclusion-
exclusion principle, and arithmetic/geometric progressions. b. Apply the
pigeonhole principle in the context of a formal proof. c. Compute permutations
and combinations of a set, and interpret the meaning in the context of the
specific application. d. Map real-world applications to appropriate counting
formalisms, such as determining the number of ways to arrange people around a
table, subject to constraints on the seating arrangement, or the number of
ways to determine certain hands in cards (e.g., a full house). 5\\. Modular
arithmetic a. Perform computations involving modular arithmetic. b. Explain
the notion of the greatest common divisor and apply Euclid's algorithm to
compute it. 6\\. Logic a. Convert logical statements from informal language to
propositional and predicate logic expressions. b. Apply formal methods of
symbolic propositional and predicate logic, such as calculating validity of
formulae, computing normal forms, or negating a logical statement. c. Use the
rules of inference to construct proofs in propositional and predicate logic.
d. Describe how symbolic logic can be used to model real-life situations or
applications, including those arising in computing contexts such as software
analysis (e.g., program correctness), database queries, and algorithms. e.
Apply formal logic proofs and/or informal, but rigorous, logical reasoning to
real problems, such as predicting the behavior of software or solving problems
such as puzzles. f. Describe the strengths and limitations of propositional
and predicate logic. g. Explain what it means for a proof in propositional (or
predicate) logic to be valid. 7\\. Graphs a. Illustrate by example the basic
terminology of graph theory, and some of the properties and special cases of
types of graphs, including trees. b. Demonstrate different traversal methods
for trees and graphs, including pre-, post-, and in-order traversal of trees,
along with breadth-first and depth-first search for graphs. c. Model a variety
of real-world problems in computer science using appropriate forms of graphs
and trees, such as representing a network topology, the organization of a
hierarchical file system, or a social network. d. Show how concepts from
graphs and trees appear in data structures, algorithms, proof techniques
(structural induction), and counting. KA Core: The recommended topics are the
same between CS core and KA-core, but with far more hours, the KA-core can
cover these topics in depth and might include more computing-related
applications."""^^xsd:string ;
            ns2:score "0.6974218"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on algorithm implementation and data structures, while KU requires broader discrete math theory (proofs, logic, counting) not explicitly covered." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Discrete_Discrete_Mathematics" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.7006189"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers most of the knowledge unit's topics, including algorithm implementation, problem-solving, and complexity calculation." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.7006189"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "Covers tree/graph algorithms, complexity calculation, and efficiency analysis aligned with KU's core topics." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6989193"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on data structures/algorithms, while KU covers logic programming concepts like unification and predicate logic not addressed here." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Discrete_Discrete_Mathematics.txt> ;
            ns2:ku_text """Pages: 187-188 HOURS CS Core = 29 KA Core = 11 MSF-Discrete: Discrete
Mathematics CS Core: 1\\. Sets, relations, functions, cardinality 2\\. Recursive
mathematical definitions 3\\. Proof techniques (induction, proof by
contradiction) 4\\. Permutations, combinations, counting, pigeonhole principle
5\\. Modular arithmetic 6\\. Logic: truth tables, connectives (operators),
inference rules, formulas, normal forms, simple predicate logic 7\\. Graphs:
basic definitions 8\\. Order notation Illustrative Learning Outcomes: CS Core:
1\\. Sets, Relations, and Functions, Cardinality a. Explain with examples the
basic terminology of functions, relations, and sets. b. Perform the operations
associated with sets, functions, and relations. c. Relate practical examples
to the appropriate set, function, or relation model, and interpret the
associated operations and terminology in context. d. Calculate the size of a
finite set, including making use of the sum and product rules and inclusion-
exclusion principle. e. Explain the difference between finite, countable, and
uncountable sets. 2\\. Recursive mathematical definitions a. Apply recursive
definitions of sequences or structures (e.g., Fibonacci numbers, linked lists,
parse trees, fractals). b. Formulate inductive proofs of statements about
recursive definitions. c. Solve a variety of basic recurrence relations. d.
Analyze a problem to determine underlying recurrence relations. e. Given a
recursive/iterative code snippet, describe its underlying recurrence relation,
hypothesize a closed form for the recurrence relation, and prove the
hypothesis correct (usually, using induction). 3\\. Proof Techniques a.
Identify the proof technique used in a given proof. b. Outline the basic
structure of each proof technique (direct proof, proof by contradiction, and
induction) described in this unit. c. Apply each of the proof techniques
(direct proof, proof by contradiction, and induction) correctly in the
construction of a sound argument. d. Determine which type of proof is best for
a given problem. e. Explain the parallels between ideas of mathematical and/or
structural induction to recursion and recursively defined structures. f.
Explain the relationship between weak and strong induction and give examples
of the appropriate use of each. 4\\. Permutations, combinations, and counting
a. Apply counting arguments, including sum and product rules, inclusion-
exclusion principle, and arithmetic/geometric progressions. b. Apply the
pigeonhole principle in the context of a formal proof. c. Compute permutations
and combinations of a set, and interpret the meaning in the context of the
specific application. d. Map real-world applications to appropriate counting
formalisms, such as determining the number of ways to arrange people around a
table, subject to constraints on the seating arrangement, or the number of
ways to determine certain hands in cards (e.g., a full house). 5\\. Modular
arithmetic a. Perform computations involving modular arithmetic. b. Explain
the notion of the greatest common divisor and apply Euclid's algorithm to
compute it. 6\\. Logic a. Convert logical statements from informal language to
propositional and predicate logic expressions. b. Apply formal methods of
symbolic propositional and predicate logic, such as calculating validity of
formulae, computing normal forms, or negating a logical statement. c. Use the
rules of inference to construct proofs in propositional and predicate logic.
d. Describe how symbolic logic can be used to model real-life situations or
applications, including those arising in computing contexts such as software
analysis (e.g., program correctness), database queries, and algorithms. e.
Apply formal logic proofs and/or informal, but rigorous, logical reasoning to
real problems, such as predicting the behavior of software or solving problems
such as puzzles. f. Describe the strengths and limitations of propositional
and predicate logic. g. Explain what it means for a proof in propositional (or
predicate) logic to be valid. 7\\. Graphs a. Illustrate by example the basic
terminology of graph theory, and some of the properties and special cases of
types of graphs, including trees. b. Demonstrate different traversal methods
for trees and graphs, including pre-, post-, and in-order traversal of trees,
along with breadth-first and depth-first search for graphs. c. Model a variety
of real-world problems in computer science using appropriate forms of graphs
and trees, such as representing a network topology, the organization of a
hierarchical file system, or a social network. d. Show how concepts from
graphs and trees appear in data structures, algorithms, proof techniques
(structural induction), and counting. KA Core: The recommended topics are the
same between CS core and KA-core, but with far more hours, the KA-core can
cover these topics in depth and might include more computing-related
applications."""^^xsd:string ;
            ns2:score "0.6974218"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as algorithm implementation, graph theory, and mathematical concepts like sets, relations, and functions." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Discrete_Discrete_Mathematics" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.7006189"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers tree traversal, graph theory, algorithm complexity, and data structure choice, which are central to the KU." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.7006189"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers most of the knowledge unit's topics, including algorithm implementation, problem-solving, and complexity calculation." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Discrete_Discrete_Mathematics.txt> ;
            ns2:ku_text """Pages: 187-188 HOURS CS Core = 29 KA Core = 11 MSF-Discrete: Discrete
Mathematics CS Core: 1\\. Sets, relations, functions, cardinality 2\\. Recursive
mathematical definitions 3\\. Proof techniques (induction, proof by
contradiction) 4\\. Permutations, combinations, counting, pigeonhole principle
5\\. Modular arithmetic 6\\. Logic: truth tables, connectives (operators),
inference rules, formulas, normal forms, simple predicate logic 7\\. Graphs:
basic definitions 8\\. Order notation Illustrative Learning Outcomes: CS Core:
1\\. Sets, Relations, and Functions, Cardinality a. Explain with examples the
basic terminology of functions, relations, and sets. b. Perform the operations
associated with sets, functions, and relations. c. Relate practical examples
to the appropriate set, function, or relation model, and interpret the
associated operations and terminology in context. d. Calculate the size of a
finite set, including making use of the sum and product rules and inclusion-
exclusion principle. e. Explain the difference between finite, countable, and
uncountable sets. 2\\. Recursive mathematical definitions a. Apply recursive
definitions of sequences or structures (e.g., Fibonacci numbers, linked lists,
parse trees, fractals). b. Formulate inductive proofs of statements about
recursive definitions. c. Solve a variety of basic recurrence relations. d.
Analyze a problem to determine underlying recurrence relations. e. Given a
recursive/iterative code snippet, describe its underlying recurrence relation,
hypothesize a closed form for the recurrence relation, and prove the
hypothesis correct (usually, using induction). 3\\. Proof Techniques a.
Identify the proof technique used in a given proof. b. Outline the basic
structure of each proof technique (direct proof, proof by contradiction, and
induction) described in this unit. c. Apply each of the proof techniques
(direct proof, proof by contradiction, and induction) correctly in the
construction of a sound argument. d. Determine which type of proof is best for
a given problem. e. Explain the parallels between ideas of mathematical and/or
structural induction to recursion and recursively defined structures. f.
Explain the relationship between weak and strong induction and give examples
of the appropriate use of each. 4\\. Permutations, combinations, and counting
a. Apply counting arguments, including sum and product rules, inclusion-
exclusion principle, and arithmetic/geometric progressions. b. Apply the
pigeonhole principle in the context of a formal proof. c. Compute permutations
and combinations of a set, and interpret the meaning in the context of the
specific application. d. Map real-world applications to appropriate counting
formalisms, such as determining the number of ways to arrange people around a
table, subject to constraints on the seating arrangement, or the number of
ways to determine certain hands in cards (e.g., a full house). 5\\. Modular
arithmetic a. Perform computations involving modular arithmetic. b. Explain
the notion of the greatest common divisor and apply Euclid's algorithm to
compute it. 6\\. Logic a. Convert logical statements from informal language to
propositional and predicate logic expressions. b. Apply formal methods of
symbolic propositional and predicate logic, such as calculating validity of
formulae, computing normal forms, or negating a logical statement. c. Use the
rules of inference to construct proofs in propositional and predicate logic.
d. Describe how symbolic logic can be used to model real-life situations or
applications, including those arising in computing contexts such as software
analysis (e.g., program correctness), database queries, and algorithms. e.
Apply formal logic proofs and/or informal, but rigorous, logical reasoning to
real problems, such as predicting the behavior of software or solving problems
such as puzzles. f. Describe the strengths and limitations of propositional
and predicate logic. g. Explain what it means for a proof in propositional (or
predicate) logic to be valid. 7\\. Graphs a. Illustrate by example the basic
terminology of graph theory, and some of the properties and special cases of
types of graphs, including trees. b. Demonstrate different traversal methods
for trees and graphs, including pre-, post-, and in-order traversal of trees,
along with breadth-first and depth-first search for graphs. c. Model a variety
of real-world problems in computer science using appropriate forms of graphs
and trees, such as representing a network topology, the organization of a
hierarchical file system, or a social network. d. Show how concepts from
graphs and trees appear in data structures, algorithms, proof techniques
(structural induction), and counting. KA Core: The recommended topics are the
same between CS core and KA-core, but with far more hours, the KA-core can
cover these topics in depth and might include more computing-related
applications."""^^xsd:string ;
            ns2:score "0.6974218"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as algorithm implementation, graph theory, and mathematical concepts like sets, relations, and functions." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Discrete_Discrete_Mathematics" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Discrete_Discrete_Mathematics.txt> ;
            ns2:ku_text """Pages: 187-188 HOURS CS Core = 29 KA Core = 11 MSF-Discrete: Discrete
Mathematics CS Core: 1\\. Sets, relations, functions, cardinality 2\\. Recursive
mathematical definitions 3\\. Proof techniques (induction, proof by
contradiction) 4\\. Permutations, combinations, counting, pigeonhole principle
5\\. Modular arithmetic 6\\. Logic: truth tables, connectives (operators),
inference rules, formulas, normal forms, simple predicate logic 7\\. Graphs:
basic definitions 8\\. Order notation Illustrative Learning Outcomes: CS Core:
1\\. Sets, Relations, and Functions, Cardinality a. Explain with examples the
basic terminology of functions, relations, and sets. b. Perform the operations
associated with sets, functions, and relations. c. Relate practical examples
to the appropriate set, function, or relation model, and interpret the
associated operations and terminology in context. d. Calculate the size of a
finite set, including making use of the sum and product rules and inclusion-
exclusion principle. e. Explain the difference between finite, countable, and
uncountable sets. 2\\. Recursive mathematical definitions a. Apply recursive
definitions of sequences or structures (e.g., Fibonacci numbers, linked lists,
parse trees, fractals). b. Formulate inductive proofs of statements about
recursive definitions. c. Solve a variety of basic recurrence relations. d.
Analyze a problem to determine underlying recurrence relations. e. Given a
recursive/iterative code snippet, describe its underlying recurrence relation,
hypothesize a closed form for the recurrence relation, and prove the
hypothesis correct (usually, using induction). 3\\. Proof Techniques a.
Identify the proof technique used in a given proof. b. Outline the basic
structure of each proof technique (direct proof, proof by contradiction, and
induction) described in this unit. c. Apply each of the proof techniques
(direct proof, proof by contradiction, and induction) correctly in the
construction of a sound argument. d. Determine which type of proof is best for
a given problem. e. Explain the parallels between ideas of mathematical and/or
structural induction to recursion and recursively defined structures. f.
Explain the relationship between weak and strong induction and give examples
of the appropriate use of each. 4\\. Permutations, combinations, and counting
a. Apply counting arguments, including sum and product rules, inclusion-
exclusion principle, and arithmetic/geometric progressions. b. Apply the
pigeonhole principle in the context of a formal proof. c. Compute permutations
and combinations of a set, and interpret the meaning in the context of the
specific application. d. Map real-world applications to appropriate counting
formalisms, such as determining the number of ways to arrange people around a
table, subject to constraints on the seating arrangement, or the number of
ways to determine certain hands in cards (e.g., a full house). 5\\. Modular
arithmetic a. Perform computations involving modular arithmetic. b. Explain
the notion of the greatest common divisor and apply Euclid's algorithm to
compute it. 6\\. Logic a. Convert logical statements from informal language to
propositional and predicate logic expressions. b. Apply formal methods of
symbolic propositional and predicate logic, such as calculating validity of
formulae, computing normal forms, or negating a logical statement. c. Use the
rules of inference to construct proofs in propositional and predicate logic.
d. Describe how symbolic logic can be used to model real-life situations or
applications, including those arising in computing contexts such as software
analysis (e.g., program correctness), database queries, and algorithms. e.
Apply formal logic proofs and/or informal, but rigorous, logical reasoning to
real problems, such as predicting the behavior of software or solving problems
such as puzzles. f. Describe the strengths and limitations of propositional
and predicate logic. g. Explain what it means for a proof in propositional (or
predicate) logic to be valid. 7\\. Graphs a. Illustrate by example the basic
terminology of graph theory, and some of the properties and special cases of
types of graphs, including trees. b. Demonstrate different traversal methods
for trees and graphs, including pre-, post-, and in-order traversal of trees,
along with breadth-first and depth-first search for graphs. c. Model a variety
of real-world problems in computer science using appropriate forms of graphs
and trees, such as representing a network topology, the organization of a
hierarchical file system, or a social network. d. Show how concepts from
graphs and trees appear in data structures, algorithms, proof techniques
(structural induction), and counting. KA Core: The recommended topics are the
same between CS core and KA-core, but with far more hours, the KA-core can
cover these topics in depth and might include more computing-related
applications."""^^xsd:string ;
            ns2:score "0.6974218"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers some aspects of trees and graphs but does not address the broader topics in the KU such as sets, relations, functions, recursive definitions, proof techniques, permutations, combinations, modular arithmetic, and logic." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Discrete_Discrete_Mathematics" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Discrete_Discrete_Mathematics.txt> ;
            ns2:ku_text """Pages: 187-188 HOURS CS Core = 29 KA Core = 11 MSF-Discrete: Discrete
Mathematics CS Core: 1\\. Sets, relations, functions, cardinality 2\\. Recursive
mathematical definitions 3\\. Proof techniques (induction, proof by
contradiction) 4\\. Permutations, combinations, counting, pigeonhole principle
5\\. Modular arithmetic 6\\. Logic: truth tables, connectives (operators),
inference rules, formulas, normal forms, simple predicate logic 7\\. Graphs:
basic definitions 8\\. Order notation Illustrative Learning Outcomes: CS Core:
1\\. Sets, Relations, and Functions, Cardinality a. Explain with examples the
basic terminology of functions, relations, and sets. b. Perform the operations
associated with sets, functions, and relations. c. Relate practical examples
to the appropriate set, function, or relation model, and interpret the
associated operations and terminology in context. d. Calculate the size of a
finite set, including making use of the sum and product rules and inclusion-
exclusion principle. e. Explain the difference between finite, countable, and
uncountable sets. 2\\. Recursive mathematical definitions a. Apply recursive
definitions of sequences or structures (e.g., Fibonacci numbers, linked lists,
parse trees, fractals). b. Formulate inductive proofs of statements about
recursive definitions. c. Solve a variety of basic recurrence relations. d.
Analyze a problem to determine underlying recurrence relations. e. Given a
recursive/iterative code snippet, describe its underlying recurrence relation,
hypothesize a closed form for the recurrence relation, and prove the
hypothesis correct (usually, using induction). 3\\. Proof Techniques a.
Identify the proof technique used in a given proof. b. Outline the basic
structure of each proof technique (direct proof, proof by contradiction, and
induction) described in this unit. c. Apply each of the proof techniques
(direct proof, proof by contradiction, and induction) correctly in the
construction of a sound argument. d. Determine which type of proof is best for
a given problem. e. Explain the parallels between ideas of mathematical and/or
structural induction to recursion and recursively defined structures. f.
Explain the relationship between weak and strong induction and give examples
of the appropriate use of each. 4\\. Permutations, combinations, and counting
a. Apply counting arguments, including sum and product rules, inclusion-
exclusion principle, and arithmetic/geometric progressions. b. Apply the
pigeonhole principle in the context of a formal proof. c. Compute permutations
and combinations of a set, and interpret the meaning in the context of the
specific application. d. Map real-world applications to appropriate counting
formalisms, such as determining the number of ways to arrange people around a
table, subject to constraints on the seating arrangement, or the number of
ways to determine certain hands in cards (e.g., a full house). 5\\. Modular
arithmetic a. Perform computations involving modular arithmetic. b. Explain
the notion of the greatest common divisor and apply Euclid's algorithm to
compute it. 6\\. Logic a. Convert logical statements from informal language to
propositional and predicate logic expressions. b. Apply formal methods of
symbolic propositional and predicate logic, such as calculating validity of
formulae, computing normal forms, or negating a logical statement. c. Use the
rules of inference to construct proofs in propositional and predicate logic.
d. Describe how symbolic logic can be used to model real-life situations or
applications, including those arising in computing contexts such as software
analysis (e.g., program correctness), database queries, and algorithms. e.
Apply formal logic proofs and/or informal, but rigorous, logical reasoning to
real problems, such as predicting the behavior of software or solving problems
such as puzzles. f. Describe the strengths and limitations of propositional
and predicate logic. g. Explain what it means for a proof in propositional (or
predicate) logic to be valid. 7\\. Graphs a. Illustrate by example the basic
terminology of graph theory, and some of the properties and special cases of
types of graphs, including trees. b. Demonstrate different traversal methods
for trees and graphs, including pre-, post-, and in-order traversal of trees,
along with breadth-first and depth-first search for graphs. c. Model a variety
of real-world problems in computer science using appropriate forms of graphs
and trees, such as representing a network topology, the organization of a
hierarchical file system, or a social network. d. Show how concepts from
graphs and trees appear in data structures, algorithms, proof techniques
(structural induction), and counting. KA Core: The recommended topics are the
same between CS core and KA-core, but with far more hours, the KA-core can
cover these topics in depth and might include more computing-related
applications."""^^xsd:string ;
            ns2:score "0.6974218"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers some aspects of trees and graphs but does not address the broader topics in the KU such as sets, relations, functions, recursive definitions, proof techniques, permutations, combinations, modular arithmetic, and logic." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Discrete_Discrete_Mathematics" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns2:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns2:score "0.7006189"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers tree traversal, graph theory, algorithm complexity, and data structure choice, which are central to the KU." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6989193"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on data structures and algorithms, while the KU covers logic programming, with no overlapping content." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6989193"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on data structures/algorithms, while KU covers logic programming concepts like unification and predicate logic not addressed here." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6989193"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as algorithm implementation, graph theory, and data structures, which align with the knowledge unit's objectives and learning outcomes." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Discrete_Discrete_Mathematics.txt> ;
            ns2:ku_text """Pages: 187-188 HOURS CS Core = 29 KA Core = 11 MSF-Discrete: Discrete
Mathematics CS Core: 1\\. Sets, relations, functions, cardinality 2\\. Recursive
mathematical definitions 3\\. Proof techniques (induction, proof by
contradiction) 4\\. Permutations, combinations, counting, pigeonhole principle
5\\. Modular arithmetic 6\\. Logic: truth tables, connectives (operators),
inference rules, formulas, normal forms, simple predicate logic 7\\. Graphs:
basic definitions 8\\. Order notation Illustrative Learning Outcomes: CS Core:
1\\. Sets, Relations, and Functions, Cardinality a. Explain with examples the
basic terminology of functions, relations, and sets. b. Perform the operations
associated with sets, functions, and relations. c. Relate practical examples
to the appropriate set, function, or relation model, and interpret the
associated operations and terminology in context. d. Calculate the size of a
finite set, including making use of the sum and product rules and inclusion-
exclusion principle. e. Explain the difference between finite, countable, and
uncountable sets. 2\\. Recursive mathematical definitions a. Apply recursive
definitions of sequences or structures (e.g., Fibonacci numbers, linked lists,
parse trees, fractals). b. Formulate inductive proofs of statements about
recursive definitions. c. Solve a variety of basic recurrence relations. d.
Analyze a problem to determine underlying recurrence relations. e. Given a
recursive/iterative code snippet, describe its underlying recurrence relation,
hypothesize a closed form for the recurrence relation, and prove the
hypothesis correct (usually, using induction). 3\\. Proof Techniques a.
Identify the proof technique used in a given proof. b. Outline the basic
structure of each proof technique (direct proof, proof by contradiction, and
induction) described in this unit. c. Apply each of the proof techniques
(direct proof, proof by contradiction, and induction) correctly in the
construction of a sound argument. d. Determine which type of proof is best for
a given problem. e. Explain the parallels between ideas of mathematical and/or
structural induction to recursion and recursively defined structures. f.
Explain the relationship between weak and strong induction and give examples
of the appropriate use of each. 4\\. Permutations, combinations, and counting
a. Apply counting arguments, including sum and product rules, inclusion-
exclusion principle, and arithmetic/geometric progressions. b. Apply the
pigeonhole principle in the context of a formal proof. c. Compute permutations
and combinations of a set, and interpret the meaning in the context of the
specific application. d. Map real-world applications to appropriate counting
formalisms, such as determining the number of ways to arrange people around a
table, subject to constraints on the seating arrangement, or the number of
ways to determine certain hands in cards (e.g., a full house). 5\\. Modular
arithmetic a. Perform computations involving modular arithmetic. b. Explain
the notion of the greatest common divisor and apply Euclid's algorithm to
compute it. 6\\. Logic a. Convert logical statements from informal language to
propositional and predicate logic expressions. b. Apply formal methods of
symbolic propositional and predicate logic, such as calculating validity of
formulae, computing normal forms, or negating a logical statement. c. Use the
rules of inference to construct proofs in propositional and predicate logic.
d. Describe how symbolic logic can be used to model real-life situations or
applications, including those arising in computing contexts such as software
analysis (e.g., program correctness), database queries, and algorithms. e.
Apply formal logic proofs and/or informal, but rigorous, logical reasoning to
real problems, such as predicting the behavior of software or solving problems
such as puzzles. f. Describe the strengths and limitations of propositional
and predicate logic. g. Explain what it means for a proof in propositional (or
predicate) logic to be valid. 7\\. Graphs a. Illustrate by example the basic
terminology of graph theory, and some of the properties and special cases of
types of graphs, including trees. b. Demonstrate different traversal methods
for trees and graphs, including pre-, post-, and in-order traversal of trees,
along with breadth-first and depth-first search for graphs. c. Model a variety
of real-world problems in computer science using appropriate forms of graphs
and trees, such as representing a network topology, the organization of a
hierarchical file system, or a social network. d. Show how concepts from
graphs and trees appear in data structures, algorithms, proof techniques
(structural induction), and counting. KA Core: The recommended topics are the
same between CS core and KA-core, but with far more hours, the KA-core can
cover these topics in depth and might include more computing-related
applications."""^^xsd:string ;
            ns2:score "0.6974218"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on algorithm implementation and data structures, while KU requires broader discrete math theory (proofs, logic, counting) not explicitly covered." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Discrete_Discrete_Mathematics" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6989193"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as algorithm implementation, graph theory, and data structures, which align with the knowledge unit's objectives and learning outcomes." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6989193"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on data structures and algorithms, while the KU covers logic programming, with no overlapping content." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns2:uetext """Label: Algorithmique et Structures de données 3 Objectif: (résultats d'apprentissage) •
implémenter des algorithmes de parcours et de manipulation d’arbres (Application) ;
•
résoudre des problèmes simples de la théorie des graphes en employant une approche gloutonne
lorsqu’elle est appropriée (Analyse) ;
•
calculer la complexité d'un algorithme en fonction des structures de données choisies (Synthèse) ;
• choisir la structure de données la plus efficace pour la résolution d'un problème (Synthèse) ; Course content: Structures de données arborescentes
o monodimensionnelles : arbres binaires, arbres AVL, classes-union etc. Course name: http://example.org/course/UE_X31I020""" .

ns1:UE_X31I030 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Formalism_Formal_Semantics.txt> ;
            ns2:ku_text """Pages: 145-146 HOURS CS Core = 0 KA Core = 0 FPL-Formalism: Formal Semantics
Non-core: 1\\. Syntax vs semantics 2\\. Approaches to semantics: axiomatic,
operational, denotational, type-based 3\\. Axiomatic semantics of abstract
constructs such as assignment, selection, iteration using precondition, post-
conditions, and loop invariant 4\\. Operational semantics analysis of abstract
constructs and sequence of such as assignment, expression evaluation,
selection, iteration using environment and store a. Symbolic execution b.
Constraint checkers 5\\. Denotational semantics a. Lambda Calculus. (See also:
AL-Models, FPL-Functional) 6\\. Proofs by induction over language semantics 7\\.
Formal definitions and proofs for type systems (See also: FPL-Types) a.
Propositions as types (implication as a function, conjunction as a product,
disjunction as a sum) b. Dependent types (universal quantification as
dependent function, existential quantification as dependent product) c.
Parametricity Illustrative learning outcomes: Non-core: 1\\. Construct formal
semantics for a small language. 2\\. Write a lambda-calculus program and show
its evaluation to a normal form. 3\\. Discuss the different approaches of
operational, denotational, and axiomatic semantics. 4\\. Use induction to prove
properties of all programs in a language. 5\\. Use induction to prove
properties of all programs in a language that is well-typed according to a
formally defined type system. 6\\. Use parametricity to establish the behavior
of code given only its type."""^^xsd:string ;
            ns2:score "0.6712515"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as formal semantics, automates, and transducteurs, which align with the knowledge unit's objectives and learning outcomes." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Formalism_Formal_Semantics" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.7020704"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "Covers finite automata, regular grammars, conversions, and Chomsky hierarchy basics but lacks depth on undecidability proofs and advanced topics like Rice's theorem." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Formalism_Formal_Semantics.txt> ;
            ns2:ku_text """Pages: 145-146 HOURS CS Core = 0 KA Core = 0 FPL-Formalism: Formal Semantics
Non-core: 1\\. Syntax vs semantics 2\\. Approaches to semantics: axiomatic,
operational, denotational, type-based 3\\. Axiomatic semantics of abstract
constructs such as assignment, selection, iteration using precondition, post-
conditions, and loop invariant 4\\. Operational semantics analysis of abstract
constructs and sequence of such as assignment, expression evaluation,
selection, iteration using environment and store a. Symbolic execution b.
Constraint checkers 5\\. Denotational semantics a. Lambda Calculus. (See also:
AL-Models, FPL-Functional) 6\\. Proofs by induction over language semantics 7\\.
Formal definitions and proofs for type systems (See also: FPL-Types) a.
Propositions as types (implication as a function, conjunction as a product,
disjunction as a sum) b. Dependent types (universal quantification as
dependent function, existential quantification as dependent product) c.
Parametricity Illustrative learning outcomes: Non-core: 1\\. Construct formal
semantics for a small language. 2\\. Write a lambda-calculus program and show
its evaluation to a normal form. 3\\. Discuss the different approaches of
operational, denotational, and axiomatic semantics. 4\\. Use induction to prove
properties of all programs in a language. 5\\. Use induction to prove
properties of all programs in a language that is well-typed according to a
formally defined type system. 6\\. Use parametricity to establish the behavior
of code given only its type."""^^xsd:string ;
            ns2:score "0.6712515"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as formal semantics, automates, and transducteurs, which align with the knowledge unit's objectives and learning outcomes." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Formalism_Formal_Semantics" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.6711116"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on automata/grammars theory, while KU covers scripting/system tasks with minimal overlap except basic regular expressions." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Formalism_Formal_Semantics.txt> ;
            ns2:ku_text """Pages: 145-146 HOURS CS Core = 0 KA Core = 0 FPL-Formalism: Formal Semantics
Non-core: 1\\. Syntax vs semantics 2\\. Approaches to semantics: axiomatic,
operational, denotational, type-based 3\\. Axiomatic semantics of abstract
constructs such as assignment, selection, iteration using precondition, post-
conditions, and loop invariant 4\\. Operational semantics analysis of abstract
constructs and sequence of such as assignment, expression evaluation,
selection, iteration using environment and store a. Symbolic execution b.
Constraint checkers 5\\. Denotational semantics a. Lambda Calculus. (See also:
AL-Models, FPL-Functional) 6\\. Proofs by induction over language semantics 7\\.
Formal definitions and proofs for type systems (See also: FPL-Types) a.
Propositions as types (implication as a function, conjunction as a product,
disjunction as a sum) b. Dependent types (universal quantification as
dependent function, existential quantification as dependent product) c.
Parametricity Illustrative learning outcomes: Non-core: 1\\. Construct formal
semantics for a small language. 2\\. Write a lambda-calculus program and show
its evaluation to a normal form. 3\\. Discuss the different approaches of
operational, denotational, and axiomatic semantics. 4\\. Use induction to prove
properties of all programs in a language. 5\\. Use induction to prove
properties of all programs in a language that is well-typed according to a
formally defined type system. 6\\. Use parametricity to establish the behavior
of code given only its type."""^^xsd:string ;
            ns2:score "0.6712515"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on automata/grammars, while KU covers formal semantics, type systems, and proofs, with no substantial overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Formalism_Formal_Semantics" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.6711116"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on automata/grammars theory, while KU covers scripting/system tasks with minimal overlap except basic regular expressions." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.7020704"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including formal automata, formal languages, and grammars, as well as decidability, computability, and halting. The lecture also touches on algorithmic correctness, determinism, and nondeterminism." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.6711116"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as automates and transducteurs, which align with the KU's focus on scripting and system tasks." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.7020704"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers some aspects of automata and formal languages but lacks substantial coverage of the broader KU topics." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.7020704"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including formal automata, formal languages, and grammars, as well as decidability, computability, and halting. The lecture also touches on algorithmic correctness, determinism, and nondeterminism." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.7020704"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers some aspects of automata and formal languages but lacks substantial coverage of the broader KU topics." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.6711116"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as automates and transducteurs, which align with the KU's focus on scripting and system tasks." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Formalism_Formal_Semantics.txt> ;
            ns2:ku_text """Pages: 145-146 HOURS CS Core = 0 KA Core = 0 FPL-Formalism: Formal Semantics
Non-core: 1\\. Syntax vs semantics 2\\. Approaches to semantics: axiomatic,
operational, denotational, type-based 3\\. Axiomatic semantics of abstract
constructs such as assignment, selection, iteration using precondition, post-
conditions, and loop invariant 4\\. Operational semantics analysis of abstract
constructs and sequence of such as assignment, expression evaluation,
selection, iteration using environment and store a. Symbolic execution b.
Constraint checkers 5\\. Denotational semantics a. Lambda Calculus. (See also:
AL-Models, FPL-Functional) 6\\. Proofs by induction over language semantics 7\\.
Formal definitions and proofs for type systems (See also: FPL-Types) a.
Propositions as types (implication as a function, conjunction as a product,
disjunction as a sum) b. Dependent types (universal quantification as
dependent function, existential quantification as dependent product) c.
Parametricity Illustrative learning outcomes: Non-core: 1\\. Construct formal
semantics for a small language. 2\\. Write a lambda-calculus program and show
its evaluation to a normal form. 3\\. Discuss the different approaches of
operational, denotational, and axiomatic semantics. 4\\. Use induction to prove
properties of all programs in a language. 5\\. Use induction to prove
properties of all programs in a language that is well-typed according to a
formally defined type system. 6\\. Use parametricity to establish the behavior
of code given only its type."""^^xsd:string ;
            ns2:score "0.6712515"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on automata/grammars, while KU covers formal semantics, type systems, and proofs, with no substantial overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Formalism_Formal_Semantics" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.6711116"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on automata and formal languages, while the KU covers shell scripting and system tasks." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Formalism_Formal_Semantics.txt> ;
            ns2:ku_text """Pages: 145-146 HOURS CS Core = 0 KA Core = 0 FPL-Formalism: Formal Semantics
Non-core: 1\\. Syntax vs semantics 2\\. Approaches to semantics: axiomatic,
operational, denotational, type-based 3\\. Axiomatic semantics of abstract
constructs such as assignment, selection, iteration using precondition, post-
conditions, and loop invariant 4\\. Operational semantics analysis of abstract
constructs and sequence of such as assignment, expression evaluation,
selection, iteration using environment and store a. Symbolic execution b.
Constraint checkers 5\\. Denotational semantics a. Lambda Calculus. (See also:
AL-Models, FPL-Functional) 6\\. Proofs by induction over language semantics 7\\.
Formal definitions and proofs for type systems (See also: FPL-Types) a.
Propositions as types (implication as a function, conjunction as a product,
disjunction as a sum) b. Dependent types (universal quantification as
dependent function, existential quantification as dependent product) c.
Parametricity Illustrative learning outcomes: Non-core: 1\\. Construct formal
semantics for a small language. 2\\. Write a lambda-calculus program and show
its evaluation to a normal form. 3\\. Discuss the different approaches of
operational, denotational, and axiomatic semantics. 4\\. Use induction to prove
properties of all programs in a language. 5\\. Use induction to prove
properties of all programs in a language that is well-typed according to a
formally defined type system. 6\\. Use parametricity to establish the behavior
of code given only its type."""^^xsd:string ;
            ns2:score "0.6712515"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers formal languages and automata, while the KU focuses on formal semantics and type systems, which are distinct areas." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Formalism_Formal_Semantics" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.7020704"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "Covers finite automata, regular grammars, conversions, and Chomsky hierarchy basics but lacks depth on undecidability proofs and advanced topics like Rice's theorem." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Formalism_Formal_Semantics.txt> ;
            ns2:ku_text """Pages: 145-146 HOURS CS Core = 0 KA Core = 0 FPL-Formalism: Formal Semantics
Non-core: 1\\. Syntax vs semantics 2\\. Approaches to semantics: axiomatic,
operational, denotational, type-based 3\\. Axiomatic semantics of abstract
constructs such as assignment, selection, iteration using precondition, post-
conditions, and loop invariant 4\\. Operational semantics analysis of abstract
constructs and sequence of such as assignment, expression evaluation,
selection, iteration using environment and store a. Symbolic execution b.
Constraint checkers 5\\. Denotational semantics a. Lambda Calculus. (See also:
AL-Models, FPL-Functional) 6\\. Proofs by induction over language semantics 7\\.
Formal definitions and proofs for type systems (See also: FPL-Types) a.
Propositions as types (implication as a function, conjunction as a product,
disjunction as a sum) b. Dependent types (universal quantification as
dependent function, existential quantification as dependent product) c.
Parametricity Illustrative learning outcomes: Non-core: 1\\. Construct formal
semantics for a small language. 2\\. Write a lambda-calculus program and show
its evaluation to a normal form. 3\\. Discuss the different approaches of
operational, denotational, and axiomatic semantics. 4\\. Use induction to prove
properties of all programs in a language. 5\\. Use induction to prove
properties of all programs in a language that is well-typed according to a
formally defined type system. 6\\. Use parametricity to establish the behavior
of code given only its type."""^^xsd:string ;
            ns2:score "0.6712515"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers formal languages and automata, while the KU focuses on formal semantics and type systems, which are distinct areas." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Formalism_Formal_Semantics" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.6711116"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on automata and formal languages, while the KU covers shell scripting and system tasks." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns2:uetext """Label: Langage et automates Objectif: (résultats d'apprentissage)
- Savoir si un mot est engendré par une grammaire rationnelle, algébrique ou contextuelle
- Connaître les propriétés d'un automate fini
- Savoir rendre déterministe un automate fini
- Savoir minimaliser le nombre d'états d'un automate fini déterministe
- Savoir si un mot est accepté par un automate fini
- Savoir transformer une grammaire rationnelle en une expression rationnelle ou en un automate
fini et inversement Course content: formes normales. Automates à pile et transducteurs finis. Course name: http://example.org/course/UE_X31I030""" .

ns1:UE_X31M060 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.65873235"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the majority of the knowledge unit, focusing on vectors, matrices, and linear systems, with some overlap in topics such as eigenvectors and eigenvalues." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.65803635"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap: Lecture focuses on dynamical systems/differential equations, while KU covers automata theory, computability, and formal languages." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.65873235"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on dynamical systems and differential equations, while KU covers broader linear algebra topics (e.g., matrices, eigenvalues, PCA/SVD). Overlap exists on eigenvalues for stability, but core KU content is not fully addressed." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.6645275"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the fundamental concepts of object-oriented programming, including classes, inheritance, polymorphism, and encapsulation, which aligns with the knowledge unit's objectives." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.6645275"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture on dynamic systems does not cover the object-oriented programming concepts described in the KU." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.65803635"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture on dynamic systems does not cover the formal automata and computability topics in the KU." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns2:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns2:score "0.65803635"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including formal automata, formal languages, decidability, and algorithmic correctness, indicating a substantial coverage." ;
            ns1:ka "Algorithmic_Foundations_AL" ;
            ns1:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.65873235"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on dynamic systems and differential equations, not linear algebra topics." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.6645275"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap: Lecture focuses on differential equations/systems dynamics, while KU covers object-oriented programming concepts." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns2:uetext """Label: Systèmes dynamiques Objectif: (résultats d'apprentissage) comportement en temps grand ; établir lien avec les équations différentielles linéaires scalaires
d’ordre 2.
- déterminer la nature d’un équilibre (stable asymptotiquement stable) pour un système différentiel
autonome. Course content: Partie II : systèmes différentiels autonomes Course name: http://example.org/course/UE_X31M060""" .

ns1:UE_X31M070 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Probability_Probability.txt> ;
            ns2:ku_text """Pages: 188-189 HOURS CS Core = 11 KA Core = 29 MSF-Probability: Probability CS
Core: 1\\. Basic notions: sample spaces, events, probability, conditional
probability, Bayes' rule 2\\. Discrete random variables and distributions 3\\.
Continuous random variables and distributions 4\\. Expectation, variance, law
of large numbers, central limit theorem 5\\. Conditional distributions and
expectation 6\\. Applications to computing, the difference between probability
and statistics (as subjects) KA Core: The recommended topics are the same
between CS core and KA-core, but with far more hours, the KA-core can cover
these topics in depth and might include more computing-related applications.
Illustrative Learning Outcomes: CS Core: 1\\. Basic notions: sample spaces,
events, probability, conditional probability, Bayes' rule a. Translate a prose
description of a probabilistic process into a formal setting of sample spaces,
outcome probabilities, and events. b. Calculate the probability of simple
events. c. Determine whether two events are independent. d. Compute
conditional probabilities, including through applying (and explaining) Bayes'
Rule. 2\\. Discrete random variables and distributions a. Define the concept of
a random variable and indicator random variable. b. Determine whether two
random variables are independent. c. Identify common discrete distributions
(e.g., uniform, Bernoulli, binomial, geometric). 3\\. Continuous random
variables and distributions a. Identify common continuous distributions (e.g.,
uniform, normal, exponential). b. Calculate probabilities using cumulative
density functions. 4\\. Expectation, variance, law of large numbers, central
limit theorem a. Define the concept of expectation and variance of a random
variable. b. Compute the expected value and variance of simple or common
discrete/continuous random variables. c. Explain the relevance of the law of
large numbers and central limit theorem to probability calculations. 5\\.
Conditional distributions and expectation a. Explain the distinction between
joint, marginal, and conditional distributions. b. Compute marginal and
conditional distributions from a full distribution, for both discrete and
continuous random variables. c. Compute conditional expectations for both
discrete and continuous random variables. 6\\. Applications to computing a.
Describe how probability can be used to model real-life situations or
applications, such as predictive text, hash tables, and quantum computation.
b. Apply probabilistic processes to solving computational problems, such as
through randomized algorithms or in security contexts."""^^xsd:string ;
            ns2:score "0.67168164"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses narrowly on the 'méthode de la fonction muette,' not covering the broad range of probability topics in the KU." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Probability_Probability" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.679868"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses narrowly on numerical probabilities and a specific method, while the KU covers a broader range of probabilistic reasoning and machine learning topics." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.679868"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on probabilistic methods (Bayes theorem, Bayesian networks) but does not cover broader KU topics like symbolic representations, Markov chains, or machine learning concepts." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Probability_Probability.txt> ;
            ns2:ku_text """Pages: 188-189 HOURS CS Core = 11 KA Core = 29 MSF-Probability: Probability CS
Core: 1\\. Basic notions: sample spaces, events, probability, conditional
probability, Bayes' rule 2\\. Discrete random variables and distributions 3\\.
Continuous random variables and distributions 4\\. Expectation, variance, law
of large numbers, central limit theorem 5\\. Conditional distributions and
expectation 6\\. Applications to computing, the difference between probability
and statistics (as subjects) KA Core: The recommended topics are the same
between CS core and KA-core, but with far more hours, the KA-core can cover
these topics in depth and might include more computing-related applications.
Illustrative Learning Outcomes: CS Core: 1\\. Basic notions: sample spaces,
events, probability, conditional probability, Bayes' rule a. Translate a prose
description of a probabilistic process into a formal setting of sample spaces,
outcome probabilities, and events. b. Calculate the probability of simple
events. c. Determine whether two events are independent. d. Compute
conditional probabilities, including through applying (and explaining) Bayes'
Rule. 2\\. Discrete random variables and distributions a. Define the concept of
a random variable and indicator random variable. b. Determine whether two
random variables are independent. c. Identify common discrete distributions
(e.g., uniform, Bernoulli, binomial, geometric). 3\\. Continuous random
variables and distributions a. Identify common continuous distributions (e.g.,
uniform, normal, exponential). b. Calculate probabilities using cumulative
density functions. 4\\. Expectation, variance, law of large numbers, central
limit theorem a. Define the concept of expectation and variance of a random
variable. b. Compute the expected value and variance of simple or common
discrete/continuous random variables. c. Explain the relevance of the law of
large numbers and central limit theorem to probability calculations. 5\\.
Conditional distributions and expectation a. Explain the distinction between
joint, marginal, and conditional distributions. b. Compute marginal and
conditional distributions from a full distribution, for both discrete and
continuous random variables. c. Compute conditional expectations for both
discrete and continuous random variables. 6\\. Applications to computing a.
Describe how probability can be used to model real-life situations or
applications, such as predictive text, hash tables, and quantum computation.
b. Apply probabilistic processes to solving computational problems, such as
through randomized algorithms or in security contexts."""^^xsd:string ;
            ns2:score "0.68258643"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the majority of the knowledge unit's topics, including basic notions, discrete and continuous random variables, expectation, variance, and conditional distributions." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Probability_Probability" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.679868"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the fundamental concepts of probabilistic reasoning, Bayes theorem, and Bayesian inference, which are a significant part of the KU." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Probability_Probability.txt> ;
            ns2:ku_text """Pages: 188-189 HOURS CS Core = 11 KA Core = 29 MSF-Probability: Probability CS
Core: 1\\. Basic notions: sample spaces, events, probability, conditional
probability, Bayes' rule 2\\. Discrete random variables and distributions 3\\.
Continuous random variables and distributions 4\\. Expectation, variance, law
of large numbers, central limit theorem 5\\. Conditional distributions and
expectation 6\\. Applications to computing, the difference between probability
and statistics (as subjects) KA Core: The recommended topics are the same
between CS core and KA-core, but with far more hours, the KA-core can cover
these topics in depth and might include more computing-related applications.
Illustrative Learning Outcomes: CS Core: 1\\. Basic notions: sample spaces,
events, probability, conditional probability, Bayes' rule a. Translate a prose
description of a probabilistic process into a formal setting of sample spaces,
outcome probabilities, and events. b. Calculate the probability of simple
events. c. Determine whether two events are independent. d. Compute
conditional probabilities, including through applying (and explaining) Bayes'
Rule. 2\\. Discrete random variables and distributions a. Define the concept of
a random variable and indicator random variable. b. Determine whether two
random variables are independent. c. Identify common discrete distributions
(e.g., uniform, Bernoulli, binomial, geometric). 3\\. Continuous random
variables and distributions a. Identify common continuous distributions (e.g.,
uniform, normal, exponential). b. Calculate probabilities using cumulative
density functions. 4\\. Expectation, variance, law of large numbers, central
limit theorem a. Define the concept of expectation and variance of a random
variable. b. Compute the expected value and variance of simple or common
discrete/continuous random variables. c. Explain the relevance of the law of
large numbers and central limit theorem to probability calculations. 5\\.
Conditional distributions and expectation a. Explain the distinction between
joint, marginal, and conditional distributions. b. Compute marginal and
conditional distributions from a full distribution, for both discrete and
continuous random variables. c. Compute conditional expectations for both
discrete and continuous random variables. 6\\. Applications to computing a.
Describe how probability can be used to model real-life situations or
applications, such as predictive text, hash tables, and quantum computation.
b. Apply probabilistic processes to solving computational problems, such as
through randomized algorithms or in security contexts."""^^xsd:string ;
            ns2:score "0.68258643"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses narrowly on the 'méthode de la fonction muette,' not covering the broad range of probability topics in the KU." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Probability_Probability" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Probability_Probability.txt> ;
            ns2:ku_text """Pages: 188-189 HOURS CS Core = 11 KA Core = 29 MSF-Probability: Probability CS
Core: 1\\. Basic notions: sample spaces, events, probability, conditional
probability, Bayes' rule 2\\. Discrete random variables and distributions 3\\.
Continuous random variables and distributions 4\\. Expectation, variance, law
of large numbers, central limit theorem 5\\. Conditional distributions and
expectation 6\\. Applications to computing, the difference between probability
and statistics (as subjects) KA Core: The recommended topics are the same
between CS core and KA-core, but with far more hours, the KA-core can cover
these topics in depth and might include more computing-related applications.
Illustrative Learning Outcomes: CS Core: 1\\. Basic notions: sample spaces,
events, probability, conditional probability, Bayes' rule a. Translate a prose
description of a probabilistic process into a formal setting of sample spaces,
outcome probabilities, and events. b. Calculate the probability of simple
events. c. Determine whether two events are independent. d. Compute
conditional probabilities, including through applying (and explaining) Bayes'
Rule. 2\\. Discrete random variables and distributions a. Define the concept of
a random variable and indicator random variable. b. Determine whether two
random variables are independent. c. Identify common discrete distributions
(e.g., uniform, Bernoulli, binomial, geometric). 3\\. Continuous random
variables and distributions a. Identify common continuous distributions (e.g.,
uniform, normal, exponential). b. Calculate probabilities using cumulative
density functions. 4\\. Expectation, variance, law of large numbers, central
limit theorem a. Define the concept of expectation and variance of a random
variable. b. Compute the expected value and variance of simple or common
discrete/continuous random variables. c. Explain the relevance of the law of
large numbers and central limit theorem to probability calculations. 5\\.
Conditional distributions and expectation a. Explain the distinction between
joint, marginal, and conditional distributions. b. Compute marginal and
conditional distributions from a full distribution, for both discrete and
continuous random variables. c. Compute conditional expectations for both
discrete and continuous random variables. 6\\. Applications to computing a.
Describe how probability can be used to model real-life situations or
applications, such as predictive text, hash tables, and quantum computation.
b. Apply probabilistic processes to solving computational problems, such as
through randomized algorithms or in security contexts."""^^xsd:string ;
            ns2:score "0.67168164"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on a specific method (fonction muette) while KU requires comprehensive coverage of probability fundamentals and applications." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Probability_Probability" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Probability_Probability.txt> ;
            ns2:ku_text """Pages: 188-189 HOURS CS Core = 11 KA Core = 29 MSF-Probability: Probability CS
Core: 1\\. Basic notions: sample spaces, events, probability, conditional
probability, Bayes' rule 2\\. Discrete random variables and distributions 3\\.
Continuous random variables and distributions 4\\. Expectation, variance, law
of large numbers, central limit theorem 5\\. Conditional distributions and
expectation 6\\. Applications to computing, the difference between probability
and statistics (as subjects) KA Core: The recommended topics are the same
between CS core and KA-core, but with far more hours, the KA-core can cover
these topics in depth and might include more computing-related applications.
Illustrative Learning Outcomes: CS Core: 1\\. Basic notions: sample spaces,
events, probability, conditional probability, Bayes' rule a. Translate a prose
description of a probabilistic process into a formal setting of sample spaces,
outcome probabilities, and events. b. Calculate the probability of simple
events. c. Determine whether two events are independent. d. Compute
conditional probabilities, including through applying (and explaining) Bayes'
Rule. 2\\. Discrete random variables and distributions a. Define the concept of
a random variable and indicator random variable. b. Determine whether two
random variables are independent. c. Identify common discrete distributions
(e.g., uniform, Bernoulli, binomial, geometric). 3\\. Continuous random
variables and distributions a. Identify common continuous distributions (e.g.,
uniform, normal, exponential). b. Calculate probabilities using cumulative
density functions. 4\\. Expectation, variance, law of large numbers, central
limit theorem a. Define the concept of expectation and variance of a random
variable. b. Compute the expected value and variance of simple or common
discrete/continuous random variables. c. Explain the relevance of the law of
large numbers and central limit theorem to probability calculations. 5\\.
Conditional distributions and expectation a. Explain the distinction between
joint, marginal, and conditional distributions. b. Compute marginal and
conditional distributions from a full distribution, for both discrete and
continuous random variables. c. Compute conditional expectations for both
discrete and continuous random variables. 6\\. Applications to computing a.
Describe how probability can be used to model real-life situations or
applications, such as predictive text, hash tables, and quantum computation.
b. Apply probabilistic processes to solving computational problems, such as
through randomized algorithms or in security contexts."""^^xsd:string ;
            ns2:score "0.68258643"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on a specific method (fonction muette) while KU requires comprehensive coverage of probability fundamentals and applications." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Probability_Probability" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Probability_Probability.txt> ;
            ns2:ku_text """Pages: 188-189 HOURS CS Core = 11 KA Core = 29 MSF-Probability: Probability CS
Core: 1\\. Basic notions: sample spaces, events, probability, conditional
probability, Bayes' rule 2\\. Discrete random variables and distributions 3\\.
Continuous random variables and distributions 4\\. Expectation, variance, law
of large numbers, central limit theorem 5\\. Conditional distributions and
expectation 6\\. Applications to computing, the difference between probability
and statistics (as subjects) KA Core: The recommended topics are the same
between CS core and KA-core, but with far more hours, the KA-core can cover
these topics in depth and might include more computing-related applications.
Illustrative Learning Outcomes: CS Core: 1\\. Basic notions: sample spaces,
events, probability, conditional probability, Bayes' rule a. Translate a prose
description of a probabilistic process into a formal setting of sample spaces,
outcome probabilities, and events. b. Calculate the probability of simple
events. c. Determine whether two events are independent. d. Compute
conditional probabilities, including through applying (and explaining) Bayes'
Rule. 2\\. Discrete random variables and distributions a. Define the concept of
a random variable and indicator random variable. b. Determine whether two
random variables are independent. c. Identify common discrete distributions
(e.g., uniform, Bernoulli, binomial, geometric). 3\\. Continuous random
variables and distributions a. Identify common continuous distributions (e.g.,
uniform, normal, exponential). b. Calculate probabilities using cumulative
density functions. 4\\. Expectation, variance, law of large numbers, central
limit theorem a. Define the concept of expectation and variance of a random
variable. b. Compute the expected value and variance of simple or common
discrete/continuous random variables. c. Explain the relevance of the law of
large numbers and central limit theorem to probability calculations. 5\\.
Conditional distributions and expectation a. Explain the distinction between
joint, marginal, and conditional distributions. b. Compute marginal and
conditional distributions from a full distribution, for both discrete and
continuous random variables. c. Compute conditional expectations for both
discrete and continuous random variables. 6\\. Applications to computing a.
Describe how probability can be used to model real-life situations or
applications, such as predictive text, hash tables, and quantum computation.
b. Apply probabilistic processes to solving computational problems, such as
through randomized algorithms or in security contexts."""^^xsd:string ;
            ns2:score "0.67168164"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the majority of the knowledge unit's topics, including basic notions, discrete and continuous random variables, expectation, variance, and conditional distributions." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Probability_Probability" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ] ;
    ns2:uetext """Label: Probabilités numériques Objectif: (résultats d'apprentissage) • Course content: Méthode de la fonction muette.
• Course name: http://example.org/course/UE_X31M070""" .

ns1:UE_X31T060 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Testing_and_Quality_Assurance.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Testing and Quality Assurance:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Testing and Quality Assurance. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.654318"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the technical aspects of SE-Testing and Quality Assurance." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Testing_and_Quality_Assurance" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.65111214"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional integration and workplace skills, while the KU covers technical machine learning topics." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.65111214"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on professional skills (internships, ethics, organizational roles), while KU covers technical ML concepts (algorithms, evaluation, overfitting) not addressed." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.6692901"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on professional integration, intern rights, and entrepreneurship, not intellectual property, plagiarism, or programmer ethics." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.6692901"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on professional integration, intern rights, and entrepreneurship, not intellectual property, plagiarism, or programmer ethics." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.65111214"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics. The lecture also provides practical examples and illustrations, which align with the KU's emphasis on real-world applications." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Testing_and_Quality_Assurance.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Testing and Quality Assurance:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Testing and Quality Assurance. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.654318"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in topics; lecture focuses on professional skills, not SE-TQA concepts." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Testing_and_Quality_Assurance" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.6692901"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics related to intellectual property, responsibility, and professional ethics, which align with the KU's learning outcomes." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.65111214"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional integration and workplace skills, while the KU covers technical machine learning topics." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Testing_and_Quality_Assurance.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Testing and Quality Assurance:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Testing and Quality Assurance. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.654318"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional opening and entrepreneurship, whereas the KU covers SE-Testing and Quality Assurance, which are unrelated topics." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Testing_and_Quality_Assurance" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Testing_and_Quality_Assurance.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Testing and Quality Assurance:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Testing and Quality Assurance. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.654318"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in topics; lecture focuses on professional skills, not SE-TQA concepts." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Testing_and_Quality_Assurance" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.6692901"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the specific knowledge areas outlined in the KU, such as intellectual property rights, plagiarism, and professional ethics in programming." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.65111214"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics. The lecture also provides practical examples and illustrations, which align with the KU's emphasis on real-world applications." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Testing_and_Quality_Assurance.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Testing and Quality Assurance:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Testing and Quality Assurance. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.654318"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional opening and entrepreneurship, whereas the KU covers SE-Testing and Quality Assurance, which are unrelated topics." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Testing_and_Quality_Assurance" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.6692901"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics related to intellectual property, responsibility, and professional ethics, which align with the KU's learning outcomes." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Testing_and_Quality_Assurance.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Testing and Quality Assurance:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Testing and Quality Assurance. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.654318"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the technical aspects of SE-Testing and Quality Assurance." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Testing_and_Quality_Assurance" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.65111214"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on professional skills (internships, ethics, organizational roles), while KU covers technical ML concepts (algorithms, evaluation, overfitting) not addressed." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.6692901"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the specific knowledge areas outlined in the KU, such as intellectual property rights, plagiarism, and professional ethics in programming." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns2:uetext """Label: Ouverture professionnelle - Informatique Objectif: (résultats d'apprentissage) - étudié une structure en particulier, en lien avec son projet professionnel
- par le biais d’un jeu de rôle, pris conscience du rôle des différents services (RH, marketing,
commercial,…) d’une structure dans le développement et le déploiement d’un projet
- connaissance de ses droits et devoirs en tant que stagiaire et aura travaillé sur sa manière de
s’intégrer et de s’adapter dans un nouveau milieu professionnel
- connaissance de ce qu’est l’entreprenariat et des dispositifs en lien à l’université Course content: 4h00 : TD 4 : Simulations d’entretiens en sous-groupes autonomes et présentation du pitch
(évaluation).
4h00 : TD 5 : Les différentes structures et organisations possibles dans le monde du travail / Droits
et devoirs du stagiaire.
1h20 : TD 6 : L’après licence : en sous-groupes, argumentation de ses perspectives post-licence. Course name: http://example.org/course/UE_X31T060""" .

ns1:UE_X32A060 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Constructs_Advanced_Programming_Constructs.txt> ;
            ns2:ku_text """Pages: 144 HOURS CS Core = 0 KA Core = 0 FPL-Constructs: Advanced Programming
Constructs Non-core: 1\\. Encapsulation mechanisms 2\\. Delayed evaluation and
infinite streams 3\\. Compare and contrast delayed evaluation vs eager
evaluation 4\\. Unification vs assertion vs expression evaluation 5\\. Control
abstractions: exception handling, continuations, monads. 6\\. Object-oriented
abstractions: multiple inheritance, mixins, traits, multimethods 7\\.
Metaprogramming: macros, generative programming, model-based development 8\\.
String manipulation via pattern-matching (regular expressions) 9\\. Dynamic
code evaluation ("eval") 10\\. Language support for checking assertions,
invariants, and pre/post-conditions 11\\. Domain specific languages, such as
database languages, data science languages, embedded computing languages,
synchronous languages, hardware interface languages 12\\. Massive parallel high
performance computing models and languages Illustrative learning outcomes:
Non-core: 1\\. Use various advanced programming constructs and idioms
correctly. 2\\. Discuss how various advanced programming constructs aim to
improve program structure, software quality, and programmer productivity. 3\\.
Discuss how various advanced programming constructs interact with the
definition and implementation of other language features."""^^xsd:string ;
            ns2:score "0.6455945"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional English and communication skills, while the KU covers advanced programming constructs, with no overlap in content." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Constructs_Advanced_Programming_Constructs" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Constructs_Advanced_Programming_Constructs.txt> ;
            ns2:ku_text """Pages: 144 HOURS CS Core = 0 KA Core = 0 FPL-Constructs: Advanced Programming
Constructs Non-core: 1\\. Encapsulation mechanisms 2\\. Delayed evaluation and
infinite streams 3\\. Compare and contrast delayed evaluation vs eager
evaluation 4\\. Unification vs assertion vs expression evaluation 5\\. Control
abstractions: exception handling, continuations, monads. 6\\. Object-oriented
abstractions: multiple inheritance, mixins, traits, multimethods 7\\.
Metaprogramming: macros, generative programming, model-based development 8\\.
String manipulation via pattern-matching (regular expressions) 9\\. Dynamic
code evaluation ("eval") 10\\. Language support for checking assertions,
invariants, and pre/post-conditions 11\\. Domain specific languages, such as
database languages, data science languages, embedded computing languages,
synchronous languages, hardware interface languages 12\\. Massive parallel high
performance computing models and languages Illustrative learning outcomes:
Non-core: 1\\. Use various advanced programming constructs and idioms
correctly. 2\\. Discuss how various advanced programming constructs aim to
improve program structure, software quality, and programmer productivity. 3\\.
Discuss how various advanced programming constructs interact with the
definition and implementation of other language features."""^^xsd:string ;
            ns2:score "0.6455945"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in content; lecture focuses on language skills while KU covers advanced programming constructs" ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Constructs_Advanced_Programming_Constructs" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445035"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional English and communication skills, while the KU covers technical programming and development platforms, with no overlap in content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Constructs_Advanced_Programming_Constructs.txt> ;
            ns2:ku_text """Pages: 144 HOURS CS Core = 0 KA Core = 0 FPL-Constructs: Advanced Programming
Constructs Non-core: 1\\. Encapsulation mechanisms 2\\. Delayed evaluation and
infinite streams 3\\. Compare and contrast delayed evaluation vs eager
evaluation 4\\. Unification vs assertion vs expression evaluation 5\\. Control
abstractions: exception handling, continuations, monads. 6\\. Object-oriented
abstractions: multiple inheritance, mixins, traits, multimethods 7\\.
Metaprogramming: macros, generative programming, model-based development 8\\.
String manipulation via pattern-matching (regular expressions) 9\\. Dynamic
code evaluation ("eval") 10\\. Language support for checking assertions,
invariants, and pre/post-conditions 11\\. Domain specific languages, such as
database languages, data science languages, embedded computing languages,
synchronous languages, hardware interface languages 12\\. Massive parallel high
performance computing models and languages Illustrative learning outcomes:
Non-core: 1\\. Use various advanced programming constructs and idioms
correctly. 2\\. Discuss how various advanced programming constructs aim to
improve program structure, software quality, and programmer productivity. 3\\.
Discuss how various advanced programming constructs interact with the
definition and implementation of other language features."""^^xsd:string ;
            ns2:score "0.6455945"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in content; lecture focuses on language skills while KU covers advanced programming constructs" ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Constructs_Advanced_Programming_Constructs" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445035"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional English and communication skills, while the KU covers technical programming and development platforms, with no overlap in content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445035"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on language skills, not technical CS platform/programming content" ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Constructs_Advanced_Programming_Constructs.txt> ;
            ns2:ku_text """Pages: 144 HOURS CS Core = 0 KA Core = 0 FPL-Constructs: Advanced Programming
Constructs Non-core: 1\\. Encapsulation mechanisms 2\\. Delayed evaluation and
infinite streams 3\\. Compare and contrast delayed evaluation vs eager
evaluation 4\\. Unification vs assertion vs expression evaluation 5\\. Control
abstractions: exception handling, continuations, monads. 6\\. Object-oriented
abstractions: multiple inheritance, mixins, traits, multimethods 7\\.
Metaprogramming: macros, generative programming, model-based development 8\\.
String manipulation via pattern-matching (regular expressions) 9\\. Dynamic
code evaluation ("eval") 10\\. Language support for checking assertions,
invariants, and pre/post-conditions 11\\. Domain specific languages, such as
database languages, data science languages, embedded computing languages,
synchronous languages, hardware interface languages 12\\. Massive parallel high
performance computing models and languages Illustrative learning outcomes:
Non-core: 1\\. Use various advanced programming constructs and idioms
correctly. 2\\. Discuss how various advanced programming constructs aim to
improve program structure, software quality, and programmer productivity. 3\\.
Discuss how various advanced programming constructs interact with the
definition and implementation of other language features."""^^xsd:string ;
            ns2:score "0.6455945"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional English and communication skills, while the KU covers advanced programming constructs, with no overlap in content." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Constructs_Advanced_Programming_Constructs" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445035"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on language skills, not technical CS platform/programming content" ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445035"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional English for IT, while the KU covers computer science development platforms, programming languages, and constraints, with no apparent overlap." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Constructs_Advanced_Programming_Constructs.txt> ;
            ns2:ku_text """Pages: 144 HOURS CS Core = 0 KA Core = 0 FPL-Constructs: Advanced Programming
Constructs Non-core: 1\\. Encapsulation mechanisms 2\\. Delayed evaluation and
infinite streams 3\\. Compare and contrast delayed evaluation vs eager
evaluation 4\\. Unification vs assertion vs expression evaluation 5\\. Control
abstractions: exception handling, continuations, monads. 6\\. Object-oriented
abstractions: multiple inheritance, mixins, traits, multimethods 7\\.
Metaprogramming: macros, generative programming, model-based development 8\\.
String manipulation via pattern-matching (regular expressions) 9\\. Dynamic
code evaluation ("eval") 10\\. Language support for checking assertions,
invariants, and pre/post-conditions 11\\. Domain specific languages, such as
database languages, data science languages, embedded computing languages,
synchronous languages, hardware interface languages 12\\. Massive parallel high
performance computing models and languages Illustrative learning outcomes:
Non-core: 1\\. Use various advanced programming constructs and idioms
correctly. 2\\. Discuss how various advanced programming constructs aim to
improve program structure, software quality, and programmer productivity. 3\\.
Discuss how various advanced programming constructs interact with the
definition and implementation of other language features."""^^xsd:string ;
            ns2:score "0.6455945"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover any of the advanced programming constructs listed in the KU, and its focus is on English language skills and presentation techniques." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Constructs_Advanced_Programming_Constructs" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.63936734"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional English and presentation skills, while the KU covers programming languages and inclusivity, with no overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445035"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional English for IT, while the KU covers computer science development platforms, programming languages, and constraints, with no apparent overlap." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Constructs_Advanced_Programming_Constructs.txt> ;
            ns2:ku_text """Pages: 144 HOURS CS Core = 0 KA Core = 0 FPL-Constructs: Advanced Programming
Constructs Non-core: 1\\. Encapsulation mechanisms 2\\. Delayed evaluation and
infinite streams 3\\. Compare and contrast delayed evaluation vs eager
evaluation 4\\. Unification vs assertion vs expression evaluation 5\\. Control
abstractions: exception handling, continuations, monads. 6\\. Object-oriented
abstractions: multiple inheritance, mixins, traits, multimethods 7\\.
Metaprogramming: macros, generative programming, model-based development 8\\.
String manipulation via pattern-matching (regular expressions) 9\\. Dynamic
code evaluation ("eval") 10\\. Language support for checking assertions,
invariants, and pre/post-conditions 11\\. Domain specific languages, such as
database languages, data science languages, embedded computing languages,
synchronous languages, hardware interface languages 12\\. Massive parallel high
performance computing models and languages Illustrative learning outcomes:
Non-core: 1\\. Use various advanced programming constructs and idioms
correctly. 2\\. Discuss how various advanced programming constructs aim to
improve program structure, software quality, and programmer productivity. 3\\.
Discuss how various advanced programming constructs interact with the
definition and implementation of other language features."""^^xsd:string ;
            ns2:score "0.6455945"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover any of the advanced programming constructs listed in the KU, and its focus is on English language skills and presentation techniques." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Constructs_Advanced_Programming_Constructs" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.63936734"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap; lecture focuses on English communication skills, while KU addresses programming language design and accessibility." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.63936734"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap; lecture focuses on English communication skills, while KU addresses programming language design and accessibility." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.63936734"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on professional English and presentation skills, while the KU covers programming languages and inclusivity, with no overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.63936734"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on presentation skills and vocabulary in English for IT professionals, whereas the KU covers a broader range of topics, including programming languages, accessibility, and ethics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns2:score "0.63936734"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on presentation skills and vocabulary in English for IT professionals, whereas the KU covers a broader range of topics, including programming languages, accessibility, and ethics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ] ;
    ns2:uetext """Label: Anglais Professionnel Informatique Objectif: (résultats d'apprentissage) 3. faire une présentation orale s’appuyant sur le travail de groupe préparé dans le rapport écrit, en
s’exprimant dans un anglais clair et phonologiquement approprié et en communiquant avec un
degré d’aisance et de spontanéité qui rende possible une interaction normale avec un locuteur natif,
sans recours excessif aux notes
4. utiliser des outils de présentation adaptés à la situation de communication
5. répondre à des questions de compréhension sur des documents audio authentiques
1. Développement du vocabulaire utilisé en anglais professionnel (vocabulaire susceptible d’être
utilisé dans les tests TOEIC)
2. Discussion des spécificités des CV aux États-Unis et en Grande-Bretagne
3. Contenu d’une lettre de motivation Course content: d’une lettre de motivation Course name: http://example.org/course/UE_X32A060""" .

ns1:UE_X32I010 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns2:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns2:score "0.680581"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on decidability, recursion, induction, and unification, while KU emphasizes functional programming concepts like closures, higher-order functions, and evaluation strategies not explicitly covered." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.67110866"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on theoretical CS (decidability, recursion), while KU addresses object-oriented programming concepts, which are unrelated." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.67110866"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on theoretical CS (decidability, recursion), while KU addresses object-oriented programming concepts, which are unrelated." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.67110866"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the fundamental concepts of object-oriented programming, including classes, inheritance, polymorphism, and encapsulation, which aligns with the knowledge unit's objectives." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.67663896"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers some foundational concepts but lacks detailed coverage of logic programming specifics like Horn clauses and quantifiers." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.67110866"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers foundational topics in computability and formal methods, while the KU focuses on object-oriented programming concepts. There is no substantial overlap between the two." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns2:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns2:score "0.680581"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the fundamental concepts of functional programming, including lambda expressions, recursion, and higher-order functions, which aligns with the KU's objectives." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.67663896"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers some foundational concepts but lacks detailed coverage of logic programming specifics like Horn clauses and quantifiers." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.67663896"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers most of the knowledge units, including Godel's enumeration, recursive functions, and logical programming concepts, indicating a substantial coverage of the KU." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.67663896"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "Covers unification, recursion, induction, and logic program structures (e.g., Horn clauses) aligned with KU core topics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.67110866"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the fundamental concepts of object-oriented programming, including classes, inheritance, polymorphism, and encapsulation, which aligns with the knowledge unit's objectives." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns2:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns2:score "0.680581"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the fundamental concepts of functional programming, including lambda expressions, recursion, and higher-order functions, which aligns with the KU's objectives." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.67663896"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "Covers unification, recursion, induction, and logic program structures (e.g., Horn clauses) aligned with KU core topics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.67663896"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers most of the knowledge units, including Godel's enumeration, recursive functions, and logical programming concepts, indicating a substantial coverage of the KU." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns2:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns2:score "0.680581"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on theoretical CS concepts like decidability and recursion, while the KU covers functional programming specifics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns2:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns2:score "0.680581"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on decidability, recursion, induction, and unification, while KU emphasizes functional programming concepts like closures, higher-order functions, and evaluation strategies not explicitly covered." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-OOP_Object-Oriented_Programming.txt> ;
            ns2:ku_text """Pages: 130-131 HOURS CS Core = 4 + 1 (SDF) KA Core = 1 FPL-OOP: Object-
Oriented Programming CS Core: 1\\. Imperative programming as a subset of
object-oriented programming. 2\\. Object-oriented design: a. Decomposition into
objects carrying state and having behavior. b. Class-hierarchy design for
modeling. 3\\. Definition of classes: fields, methods, and constructors. (See
also: SDF-Fundamentals) 4\\. Subclasses, inheritance (including multiple
inheritance), and method overriding. 5\\. Dynamic dispatch: definition of
method-call. 6\\. Exception handling. (See also: SDF-Fundamentals, PDC-
Coordination, SE-Construction) 7\\. Object-oriented idioms for encapsulation:
a. Privacy, data hiding, and visibility of class members. b. Interfaces
revealing only method signatures. c. Abstract base classes, traits and mixins.
8\\. Dynamic vs static properties. 9\\. Composition vs inheritance. 10\\.
Subtyping: a. Subtype polymorphism; implicit upcasts in typed languages. b.
Notion of behavioral replacement: subtypes acting like supertype. c.
Relationship between subtyping and inheritance. KA Core: 11\\. Collection
classes, iterators, and other common library components. 12\\. Metaprogramming
and reflection. Illustrative Learning Outcomes: CS Core: 1\\. Enumerate the
differences between imperative and object-oriented programming paradigms. 2\\.
Compose a class through design, implementation, and testing to meet behavioral
requirements. 3\\. Build a simple class hierarchy utilizing subclassing that
allows code to be reused for distinct subclasses. 4\\. Predict and validate
control flow in a program using dynamic dispatch. 5\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 6\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. 7\\. Compare and contrast the benefits and costs/impact of using
inheritance (subclasses) and composition (specifically, how to base
composition on higher order functions). 8\\. Explain the relationship between
object-oriented inheritance (code-sharing and overriding) and subtyping (the
idea of a subtype being usable in a context that expects the supertype). 9\\.
Use object-oriented encapsulation mechanisms such as interfaces and private
members. 10\\. Define and use iterators and other operations on aggregates,
including operations that take functions as arguments, in multiple programming
languages, selecting the most natural idioms for each language. (See also:
FPL-Functional) KA Core: 11\\. Use collection classes and iterators effectively
to solve a problem."""^^xsd:string ;
            ns2:score "0.67110866"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture covers foundational topics in computability and formal methods, while the KU focuses on object-oriented programming concepts. There is no substantial overlap between the two." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-OOP_Object-Oriented_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns2:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns2:score "0.680581"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on theoretical CS concepts like decidability and recursion, while the KU covers functional programming specifics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns2:uetext """Label: Informatique Fondamentale 2 Objectif: (résultats d'apprentissage) - distinguer un problème décidable d'un problème indécidable
- comprendre la résolution de problèmes par réduction
- comprendre la construction des fonctions et prédicats récursifs primitifs
- savoir faire une preuve par induction
- savoir construire des objets inductivement
- savoir construire des termes, les manipuler, et les transformer
- comprendre le mécanisme d'unification
- savoir ordonner des termes Course content: Énumérations de Godel. Fonctions récursives. Course name: http://example.org/course/UE_X32I010""" .

ns1:UE_X32I020 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6953278"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on functional programming (higher-order functions, pattern matching, type inference), while KU emphasizes logic programming (Horn clauses, unification, Prolog concepts). Core topics don't overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.69681424"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the topics of intellectual property rights, plagiarism, responsibility and liability, and professional work ethics, which are all part of the KU." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.69681424"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on functional programming concepts, while the KU covers ethical and legal aspects of programming, with no overlap in content." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6917418"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on functional programming, while the KU covers formal methods in software engineering, which are distinct areas." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6917418"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, such as conceiving and employing higher-order functions, and explaining the mechanism of type inference, which aligns with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.69681424"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the topics of intellectual property rights, plagiarism, responsibility and liability, and professional work ethics, which are all part of the KU." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6917418"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Topics mismatch: Functional programming vs formal methods" ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.69681424"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on functional programming techniques, while KU addresses professional ethics and intellectual property." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6917418"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Topics mismatch: Functional programming vs formal methods" ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.69681424"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on functional programming concepts, while the KU covers ethical and legal aspects of programming, with no overlap in content." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6953278"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on functional programming, while the KU covers logic programming topics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6917418"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, such as conceiving and employing higher-order functions, and explaining the mechanism of type inference, which aligns with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6953278"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers most of the knowledge units, including universal vs existential quantifiers, first-order predicate logic, and unification algorithm, which are the core topics of the KU." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6917418"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on functional programming, while the KU covers formal methods in software engineering, which are distinct areas." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns2:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns2:score "0.69681424"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on functional programming techniques, while KU addresses professional ethics and intellectual property." ;
            ns1:ka "Software_Development_Fundamentals_SDF" ;
            ns1:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6953278"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on functional programming (higher-order functions, pattern matching, type inference), while KU emphasizes logic programming (Horn clauses, unification, Prolog concepts). Core topics don't overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6953278"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on functional programming, while the KU covers logic programming topics." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns2:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns2:score "0.6953278"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers most of the knowledge units, including universal vs existential quantifiers, first-order predicate logic, and unification algorithm, which are the core topics of the KU." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ] ;
    ns2:uetext """Label: Programmation fonctionnelle Objectif: (résultats d'apprentissage) •
concevoir et employer des fonctions d’ordre supérieure (Application) ;
•
employer la programmation par filtrage de motifs pour les traitements symboliques (Application) ;
• expliquer et savoir simuler le mécanisme d’inférence de type (Compréhension) ; Course content: • Course name: http://example.org/course/UE_X32I020""" .

ns1:UE_X32I030 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as program abstraction, representation, and semantics, as well as data structures and control abstraction." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization modeling and MIP solvers, while KU covers programming language abstractions and semantics with no direct overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization techniques, while the KU requires calculus fundamentals, which are not covered here." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization modeling and MIP solvers, while KU covers programming language abstractions and semantics with no direct overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as program abstraction, representation, and semantics, as well as data structures and control abstraction." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as program abstraction, representation, and semantics, as well as data structures and control abstraction." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization techniques, while the KU requires calculus fundamentals, which are not covered here." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers programming language concepts, which are distinct areas." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as optimization, calculus, and problem-solving, which align with the learning outcomes described in the KU." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers programming language concepts, which are distinct areas." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization modeling and MIP solvers, while KU covers programming language abstractions and semantics with no direct overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers calculus topics, with minimal overlap." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers programming language concepts, which are distinct areas." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers calculus topics, with minimal overlap." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers programming language concepts, which are distinct areas." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as program abstraction, representation, and semantics, as well as data structures and control abstraction." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization techniques, while the KU requires calculus fundamentals, which are not covered here." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization modeling and MIP solvers, while KU covers programming language abstractions and semantics with no direct overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as optimization, calculus, and problem-solving, which align with the learning outcomes described in the KU." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers programming language concepts, which are distinct areas." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization modeling and MIP solvers, while KU covers programming language abstractions and semantics with no direct overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as program abstraction, representation, and semantics, as well as data structures and control abstraction." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers calculus topics, with minimal overlap." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6225283"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization modeling and MIP solvers, while KU covers programming language abstractions and semantics with no direct overlap." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on operational research and optimization, while the KU covers programming language concepts, which are distinct areas." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Abstraction_Program_Abstraction_and_Representation.txt> ;
            ns2:ku_text """Pages: 140-141 HOURS CS Core = 0 KA Core = 3 FPL-Abstraction: Program
Abstraction and Representation KA Core: 1\\. BNF and regular expressions 2\\.
Programs that take (other) programs as input such as interpreters, compilers,
type-checkers, documentation generators 3\\. Components of a language: a.
Definitions of alphabets, delimiters, sentences, syntax, and semantics b.
Syntax vs semantics 4\\. Program as a set of non-ambiguous meaningful sentences
5\\. Basic programming abstractions: constants, variables, declarations
(including nested declarations), command, expression, assignment, selection,
definite and indefinite iteration, iterators, function, procedure, modules,
exception handling (See also: SDF-Fundamentals) 6\\. Mutable vs immutable
variables: advantages and disadvantages of reusing existing memory location vs
advantages of copying and keeping old values; storing partial computation vs
recomputation 7\\. Types of variables: static, local, nonlocal, global; need
and issues with nonlocal and global variables. 8\\. Scope rules: static vs
dynamic; visibility of variables; side-effects. 9\\. Side-effects induced by
nonlocal variables, global variables and aliased variables. Non-core: 10\\.
L-values and R-values: mapping mutable variable-name to L-values; mapping
immutable variablenames to R-values 11\\. Environment vs store and their
properties 12\\. Data and control abstraction 13\\. Mechanisms for information
exchange between program units such as procedures, functions, and modules:
nonlocal variables, global variables, parameter-passing, import-export between
modules 14\\. Data structures to represent code for execution, translation, or
transmission. 15\\. Low level instruction representation such as virtual
machine instructions, assembly language, and binary representation (See also:
AR-Representation, AR-Assembly) 16\\. Lambda calculus, variable binding, and
variable renaming. (See also: AL-Models, FPL-Formalism) 17\\. Types of
semantics: operational, axiomatic, denotational, behavioral; define and use
abstract syntax trees; contrast with concrete syntax. Illustrative learning
outcomes: KA Core: 1\\. Illustrate the scope of variables and visibility using
simple programs. 2\\. Illustrate different types of parameter-passing using
simple pseudo programming language. 3\\. Explain side-effect using global and
nonlocal variables and how to fix such programs. 4\\. Explain how programs that
process other programs treat the other programs as their input data. 5\\.
Describe a grammar and an abstract syntax tree for a small language. 6\\.
Describe the benefits of having program representations other than strings of
source code. 7\\. Implement a program to process some representation of code
for some purpose, such as an interpreter, an expression optimizer, or a
documentation generator."""^^xsd:string ;
            ns2:score "0.6306107"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as program abstraction, representation, and semantics, as well as data structures and control abstraction." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Abstraction_Program_Abstraction_and_Representation" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns2:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns2:score "0.6273762"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as optimization, calculus, and problem-solving, which align with the learning outcomes described in the KU." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ] ;
    ns2:uetext """Label: Recherche opérationnelle Objectif: (résultats d'apprentissage)
(A-M)
- Connaître les notions de calendrier au plus tôt, calendrier au plus tard pour un ensemble de
tâche, et la notion de marge d'une tâche dans le contexte d'un problème d'ordonnancement simple
(M)
- Etre capable de déterminer un calendrier au plus tôt, un calendrier au plus tard et les marges
des tâches, dans le contexte d'un problème d'ordonnancement simple (A)
- Introduction à la problématique de l'optimisation multi-objectif : connaissance de la notion de
solution efficace, limite de l'utilisation de la somme pondérée (I)
- Utilisation d'un langage de modélisation algébrique : comprendre la différence entre un modèle
explicite et un modèle implicite (I)
- Utilisation d'un langage de modélisation algébrique : être capable d'écrire un modèle implicite
(A)
- Utilisation d'un langage de modélisation algébrique : comprendre l'utilisation d'une structure de
matrice creuse pour décrire des contraintes (I)
- Utilisation d'un langage de modélisation algébrique : être capable d'utiliser une structure de
matrice creuse pour décrire des contraintes (A)
- Utilisation d'un langage de modélisation algébrique : être capable de détermine si le choix d'une
matrice creuse est pertinent ou pas pour décrire des contraintes (A)
- Utilisation d'un solveur MIP : comprendre l'utilisation d'un solveur MIP en tant que bibliothèque
de fonction et être capable de l'utiliser pour résoudre un unique problème de programmation
linéaire en variables mixtes (A)
- Utilisation d'un solveur MIP : être capable d'implémenter un algorithme donné, en faisant des
appels successifs à un solveur MIP pour résoudre un problème de programmation linéaire en
variables mixtes (A) Course content: fondamental :
- Course name: http://example.org/course/UE_X32I030""" .

ns1:UE_X32I130 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.6324861"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in specific topics or learning outcomes mentioned." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.6324861"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the course content and concepts of SE-Software Architecture, aligning with the Knowledge Unit's objectives." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445092"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the development platforms, programming via API, platform languages, and programming under constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6401858"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in specific topics or learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.6324861"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in specific topics or learning outcomes mentioned." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.6324861"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not substantially cover the KU as it lacks specific details on software architecture concepts." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6401858"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on scientific computing, while the KU covers formal methods in software engineering." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6401858"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, placeholder topics, and illustrates learning outcomes, indicating a substantial coverage of the KU." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445092"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not substantially cover the knowledge described in the KU." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6401858"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on scientific computing, while the KU covers formal methods in software engineering." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.6324861"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the course content and concepts of SE-Software Architecture, aligning with the Knowledge Unit's objectives." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445092"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture content 'du cours' lacks specific details matching KU's platform constraints, APIs, languages, or learning outcomes." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445092"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the development platforms, programming via API, platform languages, and programming under constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6401858"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, placeholder topics, and illustrates learning outcomes, indicating a substantial coverage of the KU." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns2:score "0.6324861"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not substantially cover the KU as it lacks specific details on software architecture concepts." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445092"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture content 'du cours' lacks specific details matching KU's platform constraints, APIs, languages, or learning outcomes." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6401858"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in specific topics or learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6445092"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not substantially cover the knowledge described in the KU." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns2:uetext "Label: Projet d'informatique scientifique Objectif: (résultats d'apprentissage) Course content: du cours Course name: http://example.org/course/UE_X32I130" .

ns1:UE_X32M060 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.6771118"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on optimization, while the KU covers broader linear algebra topics." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.6846708"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers most of the topics listed in the KU, including vectors, matrices, linear independence, orthogonality, and eigenvectors, with some overlap in the topics of linear systems and dimensionality reduction." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.6756775"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization theory (convexity, conditions), while KU covers broader ML topics (algorithms, ethics, evaluation) not substantially addressed." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.6846708"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on optimization, while the KU covers broader linear algebra topics." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.6771118"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers most of the topics listed in the KU, including vectors, matrices, linear independence, orthogonality, and eigenvectors, with some overlap in the topics of linear systems and dimensionality reduction." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.6846708"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization conditions/convexity, while KU covers broader linear algebra fundamentals." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns2:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns2:score "0.6771118"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on optimization conditions/convexity, while KU covers broader linear algebra fundamentals." ;
            ns1:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns1:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.6756775"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on optimization, which is a part of the KU, but the KU covers a broader range of topics in machine learning not addressed in the lecture." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns2:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns2:score "0.6756775"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, optimization, and neural networks, but does not exhaustively cover all aspects of the KU." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ] ;
    ns2:uetext """Label: Optimisation Objectif: (résultats d'apprentissage) - établir les conditions nécessaires du premier ordre
- analyser les conditions du second ordre pour un programme sans contraintes
- déterminer la convexité d'ensembles et de fonctions
- résoudre des programmes convexes
• Course content: Conditions du deuxième ordre (matrices bordantes)
• Course name: http://example.org/course/UE_X32M060""" .

ns1:UE_X32M070 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.70215297"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on statistical inference and maximum likelihood estimation, which partially overlaps with probabilistic reasoning in the KU, but does not cover the broader topics like knowledge representation, machine learning tasks, or decision-making under uncertainty." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Probability_Probabilistic_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:77-78 HOURS CS Core = 0 KA Core = 0 AI-Probability: Probabilistic
Representation and Reasoning Non-core: 1\\. Conditional Independence review 2\\.
Knowledge representations a. Bayesian Networks i. Exact inference and its
complexity ii. Markov blankets and d-separation iii. Randomized sampling
(Monte Carlo) methods (e.g., Gibbs sampling) b. Markov Networks 78 c.
Relational probability models d. Hidden Markov Models 3\\. Decision Theory a.
Preferences and utility functions b. Maximizing expected utility c. Game
theory Illustrative Learning Outcomes: 1\\. Compute the probability of a
hypothesis given the evidence in a Bayesian network. 2\\. Explain how
conditional independence assertions allow for greater efficiency of
probabilistic systems. 3\\. Identify examples of knowledge representations for
reasoning under uncertainty. 4\\. State the complexity of exact inference.
Identify methods for approximate inference. 5\\. Design and implement at least
one knowledge representation for reasoning under uncertainty. 6\\. Describe the
complexities of temporal probabilistic reasoning. 7\\. Design and implement an
HMM as one example of a temporal probabilistic system. 8\\. Describe the
relationship between preferences and utility functions. 9\\. Explain how
utility functions and probabilistic reasoning can be combined to make rational
decisions."""^^xsd:string ;
            ns2:score "0.6983979"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the topics of Bayesian Networks, Markov Networks, and Hidden Markov Models, which are all part of the Knowledge Unit's content." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-Probability_Probabilistic_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Probability_Probabilistic_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:77-78 HOURS CS Core = 0 KA Core = 0 AI-Probability: Probabilistic
Representation and Reasoning Non-core: 1\\. Conditional Independence review 2\\.
Knowledge representations a. Bayesian Networks i. Exact inference and its
complexity ii. Markov blankets and d-separation iii. Randomized sampling
(Monte Carlo) methods (e.g., Gibbs sampling) b. Markov Networks 78 c.
Relational probability models d. Hidden Markov Models 3\\. Decision Theory a.
Preferences and utility functions b. Maximizing expected utility c. Game
theory Illustrative Learning Outcomes: 1\\. Compute the probability of a
hypothesis given the evidence in a Bayesian network. 2\\. Explain how
conditional independence assertions allow for greater efficiency of
probabilistic systems. 3\\. Identify examples of knowledge representations for
reasoning under uncertainty. 4\\. State the complexity of exact inference.
Identify methods for approximate inference. 5\\. Design and implement at least
one knowledge representation for reasoning under uncertainty. 6\\. Describe the
complexities of temporal probabilistic reasoning. 7\\. Design and implement an
HMM as one example of a temporal probabilistic system. 8\\. Describe the
relationship between preferences and utility functions. 9\\. Explain how
utility functions and probabilistic reasoning can be combined to make rational
decisions."""^^xsd:string ;
            ns2:score "0.6983979"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses narrowly on statistical inference and maximum likelihood estimation, not covering the broader probabilistic reasoning and decision theory topics of the KU." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-Probability_Probabilistic_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Probability_Probabilistic_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:77-78 HOURS CS Core = 0 KA Core = 0 AI-Probability: Probabilistic
Representation and Reasoning Non-core: 1\\. Conditional Independence review 2\\.
Knowledge representations a. Bayesian Networks i. Exact inference and its
complexity ii. Markov blankets and d-separation iii. Randomized sampling
(Monte Carlo) methods (e.g., Gibbs sampling) b. Markov Networks 78 c.
Relational probability models d. Hidden Markov Models 3\\. Decision Theory a.
Preferences and utility functions b. Maximizing expected utility c. Game
theory Illustrative Learning Outcomes: 1\\. Compute the probability of a
hypothesis given the evidence in a Bayesian network. 2\\. Explain how
conditional independence assertions allow for greater efficiency of
probabilistic systems. 3\\. Identify examples of knowledge representations for
reasoning under uncertainty. 4\\. State the complexity of exact inference.
Identify methods for approximate inference. 5\\. Design and implement at least
one knowledge representation for reasoning under uncertainty. 6\\. Describe the
complexities of temporal probabilistic reasoning. 7\\. Design and implement an
HMM as one example of a temporal probabilistic system. 8\\. Describe the
relationship between preferences and utility functions. 9\\. Explain how
utility functions and probabilistic reasoning can be combined to make rational
decisions."""^^xsd:string ;
            ns2:score "0.6983979"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on statistical inference (MLE, Cramer Rao), while KU covers Bayesian networks, decision theory, and probabilistic models not addressed." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-Probability_Probabilistic_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.70215297"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on statistical inference (MLE, Cramer-Rao) but does not cover KU's broader scope of symbolic representations, Markov chains, or machine learning taxonomy" ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.72146"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on statistical inference and maximum likelihood estimation, which partially overlaps with probabilistic reasoning in the KU, but does not cover the broader topics like knowledge representation, machine learning tasks, or decision-making under uncertainty." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.72146"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as Bayesian inference, probabilistic reasoning, and Bayes' theorem, which are a significant part of the KU." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.70215297"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers topics such as Bayesian inference, probabilistic reasoning, and Bayes' theorem, which are a significant part of the KU." ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning.txt> ;
            ns2:ku_text """Pages:70-70 HOURS CS Core = 2 KA Core = 2 AI-KRR: Fundamental Knowledge
Representation and Reasoning CS Core: 1\\. Types of representations a.
Symbolic, logical i. Creating a representation from a natural language problem
statement b. Learned subsymbolic representations c. Graphical models (e.g.,
naive Bayes, Bayesian network) 2\\. Review of probabilistic reasoning, Bayes
theorem (See also: MSF-Probability) 3\\. Bayesian reasoning a. Bayesian
inference KA Core: 4\\. Random variables and probability distributions a.
Axioms of probability b. Probabilistic inference c. Bayes' Rule (derivation)
d. Bayesian inference (more complex examples) 5\\. Independence 6\\. Conditional
Independence 7\\. Markov chains and Markov models 8\\. Utility and decision
making Illustrative Learning Outcomes: 1\\. Given a natural language problem
statement, encode it as a symbolic or logical representation. 2\\. Explain how
we can make decisions under uncertainty, using concepts such as Bayes theorem
and utility. 3\\. Compute a probabilistic inference in a real-world problem
using Bayes' theorem to determine the probability of a hypothesis given
evidence. 4\\. Apply Bayes' rule to determine the probability of a hypothesis
given evidence. 5\\. Compute the probability of outcomes and test whether
outcomes are independent. 71 AI-ML: Machine Learning CS Core: 1\\. Definition
and examples of a broad variety of machine learning tasks a. Supervised
learning i. Classification ii. Regression b. Reinforcement learning c.
Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability"""^^xsd:string ;
            ns2:score "0.72146"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on statistical inference (MLE, Cramer-Rao) but does not cover KU's broader scope of symbolic representations, Markov chains, or machine learning taxonomy" ;
            ns1:ka "Artificial_Intelligence_AI" ;
            ns1:ku "AI-KRR_Fundamental_Knowledge_Representation_and_Reasoning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns2:uetext """Label: Inférence statistique Objectif: (résultats d'apprentissage) maximum de vraisemblance) qui s'y prête le mieux. Déterminer les caractéristiques de cet
estimateur et discuter son efficacité.
• Course content: •
borne de Cramer Rao, définition d'un estimateur efficace,
asymptotiquement efficace. Exemples. Course name: http://example.org/course/UE_X32M070""" .

ns1:UE_XLG5TU200 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not SE-Formal Methods content." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the technical content of the Knowledge Unit." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not platform-specific programming or constraints." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not SE-Formal Methods content." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not SE-Formal Methods content." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not platform-specific programming or constraints." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not technical scripting topics listed in KU." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods, not the technical content of the KU." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not technical scripting topics listed in KU." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods, not the technical content of the KU." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods, not the technical content of the KU." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including scripting, error handling, piping, system commands, environment variables, file abstraction, data structures, and regular expressions." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not platform-specific programming or constraints." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not technical scripting topics listed in KU." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the technical details of development platforms, programming languages, and constraints described in the KU." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including scripting, error handling, piping, system commands, environment variables, file abstraction, data structures, and regular expressions." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the technical content of the Knowledge Unit." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the technical details of development platforms, programming languages, and constraints described in the KU." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers a significant portion of the KU, including scripting, error handling, piping, system commands, environment variables, file abstraction, data structures, and regular expressions." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Scripting_Shell_Scripting.txt> ;
            ns2:ku_text """Pages: 133-134 HOURS CS Core = 2 KA Core = 0 FPL-Scripting: Shell Scripting CS
Core: 1\\. Error/exception handling 2\\. Piping (See also: AR-Organization, SF-
Overview, OS-Process) 3\\. System commands (See also: SF-Overview) a. Interface
with operating systems (See also: SF-Overview, OS-Principles) 4\\. Environment
variables (See also: SF-Overview) 5\\. File abstraction and operators (See
also: SDF-Fundamentals, OS-Files, SF-Resource) 6\\. Data structures, such as
arrays and lists. (See also: AL-Foundational, SDF-Fundamentals, SDFData-
Structures) 7\\. Regular expressions (See also: AL-Models) 8\\. Programs and
processes (See also: OS-Process) 9\\. Workflow Illustrative learning outcomes:
CS Core: 1\\. Create and execute automated scripts to manage various system
tasks. 2\\. Solve various text processing problems through scripting."""^^xsd:string ;
            ns2:score "0.62935567"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the technical content of the Knowledge Unit." ;
            ns1:ka "Foundations_of_Programming_Languages_FPL" ;
            ns1:ku "FPL-Scripting_Shell_Scripting" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6374133"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6453911"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the technical details of development platforms, programming languages, and constraints described in the KU." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns2:uetext "Label: Stage libre Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG5TU200" .

ns1:UE_XLG6TU200 ns2:to [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not graphics/visualization content" ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, while KU covers technical platform constraints and programming specifics." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the detailed technical content of the Knowledge Unit." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in subject matter; lecture focuses on teaching methods while KU is about formal methods in SE" ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the detailed technical content of the Knowledge Unit." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods and course structure, not the specific graphics and visualization topics of the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not graphics/visualization content" ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods and course structure, not the specific graphics and visualization topics of the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods and course structure, not the specific graphics and visualization topics of the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the detailed technical content of the Knowledge Unit." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, while KU covers technical platform constraints and programming specifics." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, while KU covers technical platform constraints and programming specifics." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, while KU covers technical platform constraints and programming specifics." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the detailed technical content of the Knowledge Unit." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not graphics/visualization content" ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not graphics/visualization content" ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods and course structure, not the specific graphics and visualization topics of the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in subject matter; lecture focuses on teaching methods while KU is about formal methods in SE" ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in subject matter; lecture focuses on teaching methods while KU is about formal methods in SE" ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in subject matter; lecture focuses on teaching methods while KU is about formal methods in SE" ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods and course structure, not the specific graphics and visualization topics of the KU." ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "No overlap in subject matter; lecture focuses on teaching methods while KU is about formal methods in SE" ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture does not cover the detailed technical content of the Knowledge Unit." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns2:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns2:score "0.6470485"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, while KU covers technical platform constraints and programming specifics." ;
            ns1:ka "Specialized_Platform_Development_SPD" ;
            ns1:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "1" ;
            ns1:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns2:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns2:score "0.6385061"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns1:ka "Software_Engineering_SE" ;
            ns1:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns2:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns2:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns2:score "0.62958026"^^xsd:float ;
            ns1:answer "0" ;
            ns1:explain "Lecture focuses on teaching methods, not graphics/visualization content" ;
            ns1:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns1:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns2:uetext "Label: Stage libre Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG6TU200" .

