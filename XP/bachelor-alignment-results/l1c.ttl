@prefix ns1: <http://align.org/> .
@prefix ns2: <http://example.org/course/> .
@prefix ns3: <http://provo.org/> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

ns2:UE_XLG1AU050 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English language teaching methods, while the KU covers technical NLP topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not NLP technical content." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including deterministic and stochastic grammars, parsing algorithms, and semantic representations, as well as information retrieval, language translation, and text classification." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applying principles in practical scenarios, and analyzing the importance of this topic in computing, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter (English teaching methods vs. CS programming platforms)" ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applying principles in practical scenarios, and analyzing the importance of this topic in computing, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not NLP technical content." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English language teaching methods, while the KU covers technical NLP topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Different subjects (English teaching methods vs. CS Formal Methods)" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including deterministic and stochastic grammars, parsing algorithms, and semantic representations, as well as information retrieval, language translation, and text classification." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not NLP technical content." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English language teaching methods, while the KU covers technical NLP topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English teaching methods, not Computer Science topics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Different subjects (English teaching methods vs. CS Formal Methods)" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including deterministic and stochastic grammars, parsing algorithms, and semantic representations, as well as information retrieval, language translation, and text classification." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English teaching methods, not Computer Science topics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English teaching methods, while the KU covers formal methods in software engineering, indicating no substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including deterministic and stochastic grammars, parsing algorithms, and semantic representations, as well as information retrieval, language translation, and text classification." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applying principles in practical scenarios, and analyzing the importance of this topic in computing, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English language teaching methods, while the KU covers technical NLP topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Different subjects (English teaching methods vs. CS Formal Methods)" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English teaching methods, while the KU covers formal methods in software engineering, indicating no substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English teaching methods, not Computer Science topics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.6266171"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not NLP technical content." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter (English teaching methods vs. CS programming platforms)" ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English teaching methods, while the KU covers formal methods in software engineering, indicating no substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Different subjects (English teaching methods vs. CS Formal Methods)" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English teaching methods, not Computer Science topics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter (English teaching methods vs. CS programming platforms)" ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applying principles in practical scenarios, and analyzing the importance of this topic in computing, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62474287"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on English teaching methods, while the KU covers formal methods in software engineering, indicating no substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6294993"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter (English teaching methods vs. CS programming platforms)" ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns1:uetext "Label: 1st year English S1 Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG1AU050" .

ns2:UE_XLG1IU010 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific ethical and professional topics outlined in the Knowledge Unit." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not ethics/intellectual property topics in KU" ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not formal methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not ethics/intellectual property topics in KU" ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not formal methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general teaching methods without covering the specific SE-Formal Methods topics outlined in the KU." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not the technical content of the KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not ethics/intellectual property topics in KU" ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of this topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general teaching methods without covering the specific SE-Formal Methods topics outlined in the KU." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not the technical content of the KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of this topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers intellectual property rights, plagiarism, responsibility, and professional ethics, which are all key aspects of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific ethical and professional topics outlined in the Knowledge Unit." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not the technical content of the KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of this topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not ethics/intellectual property topics in KU" ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific ethical and professional topics outlined in the Knowledge Unit." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of this topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not the technical content of the KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers intellectual property rights, plagiarism, responsibility, and professional ethics, which are all key aspects of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6455054"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not formal methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers intellectual property rights, plagiarism, responsibility, and professional ethics, which are all key aspects of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general teaching methods without covering the specific SE-Formal Methods topics outlined in the KU." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific ethical and professional topics outlined in the Knowledge Unit." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6287668"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers intellectual property rights, plagiarism, responsibility, and professional ethics, which are all key aspects of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general teaching methods without covering the specific SE-Formal Methods topics outlined in the KU." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.62820685"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not formal methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns1:uetext "Label: Informatique Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG1IU010" .

ns2:UE_XLG1MU040 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like linear algebra and analysis but lacks depth in key areas such as eigenvectors, PCA, and detailed applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like sequences and limits but lacks substantial coverage of multivariate calculus, optimization, and ODEs." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as linear algebra, matrices, vectors, and eigenvectors, with a focus on geometric interpretations and applications to computer science." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as linear algebra, matrices, vectors, and eigenvectors, with a focus on geometric interpretations and applications to computer science." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like linear algebra and analysis but lacks depth in key areas such as eigenvectors, PCA, and detailed applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers linear algebra basics but lacks depth on orthogonality, eigenvalues, Gram-Schmidt, and specific CS applications like PCA/SVD emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like sequences and limits but lacks substantial coverage of multivariate calculus, optimization, and ODEs." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers linear algebra basics but lacks depth on orthogonality, eigenvalues, Gram-Schmidt, and specific CS applications like PCA/SVD emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as linear algebra, matrices, vectors, and eigenvectors, with a focus on geometric interpretations and applications to computer science." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers most of the topics listed in the KU, including algebraic linear systems, analysis of functions, interpolation, and optimization, which align with the course content." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers sequences/limits and basic calculus but lacks multivariate calculus, ODEs, Taylor series, and Euler method." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers sequences/limits and basic calculus but lacks multivariate calculus, ODEs, Taylor series, and Euler method." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as linear algebra, matrices, vectors, and eigenvectors, with a focus on geometric interpretations and applications to computer science." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers most of the topics listed in the KU, including algebraic linear systems, analysis of functions, interpolation, and optimization, which align with the course content." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers sequences/limits and basic calculus but lacks multivariate calculus, ODEs, Taylor series, and Euler method." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like linear algebra and analysis but lacks depth in key areas such as eigenvectors, PCA, and detailed applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers linear algebra basics but lacks depth on orthogonality, eigenvalues, Gram-Schmidt, and specific CS applications like PCA/SVD emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers linear algebra basics but lacks depth on orthogonality, eigenvalues, Gram-Schmidt, and specific CS applications like PCA/SVD emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers most of the topics listed in the KU, including algebraic linear systems, analysis of functions, interpolation, and optimization, which align with the course content." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers linear algebra basics but lacks depth on orthogonality, eigenvalues, Gram-Schmidt, and specific CS applications like PCA/SVD emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers linear algebra basics but lacks depth on orthogonality, eigenvalues, Gram-Schmidt, and specific CS applications like PCA/SVD emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like linear algebra and analysis but lacks depth in key areas such as eigenvectors, PCA, and detailed applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like linear algebra and analysis but lacks depth in key areas such as eigenvectors, PCA, and detailed applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as linear algebra, matrices, vectors, and eigenvectors, with a focus on geometric interpretations and applications to computer science." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6921985"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as linear algebra, matrices, vectors, and eigenvectors, with a focus on geometric interpretations and applications to computer science." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.70131767"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like linear algebra and analysis but lacks depth in key areas such as eigenvectors, PCA, and detailed applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7110028"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like sequences and limits but lacks substantial coverage of multivariate calculus, optimization, and ODEs." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext """Label: Mathématiques générales pour l'informatique 1 Objectif: (résultats d'apprentissage)
formatique
• Développer une approche informatique pour analyser un problème mathématique Course content: • Algèbre linéaire : matrices, systèmes linéaires — Application : puissances de
matrices pour les graphes et les automates, optimisation linéaire.
• Analyse : fonctions d’une variable réelle, fonctions usuelles (fonctions trigonométriques, fonction
exponentielle, fonction logarithmique), continuité, dérivabilité, primitives — Application : résolution
approchée d’équations.
• Interpolation, méthodes d’intégration numérique.
• Suites, limites et comportements asymptotiques des suites — Application pos-
sible : complexité asymptotique des algorithmes. Course name: http://example.org/course/UE_XLG1MU040""" .

ns2:UE_XLG1PU020 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering and signal processing, whereas the KU covers programming fundamentals, data types, and structured programming. The topics do not overlap significantly." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering and signal processing, whereas the KU covers programming fundamentals, data types, and structured programming. The topics do not overlap significantly." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers electrical engineering topics, while the KU focuses on programming concepts; they are unrelated." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers electrical engineering topics, while the KU focuses on programming concepts; they are unrelated." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical engineering/mathematics, KU covers programming fundamentals. No overlap." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical engineering/mathematics, KU covers programming fundamentals. No overlap." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers electrical engineering topics, while the KU focuses on programming concepts; they are unrelated." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering and signal processing, whereas the KU covers programming fundamentals, data types, and structured programming. The topics do not overlap significantly." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering and signal processing, whereas the KU covers programming fundamentals, data types, and structured programming. The topics do not overlap significantly." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical circuits/signals; KU covers linear algebra, which is unrelated." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical engineering/mathematics, KU covers programming fundamentals. No overlap." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers electrical engineering topics, while the KU focuses on programming concepts; they are unrelated." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as signal analysis, impedance, and circuit calculations, which align with the KU's focus on linear algebra and its applications." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical engineering/mathematics, KU covers programming fundamentals. No overlap." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6576587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering and signal processing, whereas the KU covers programming fundamentals, data types, and structured programming. The topics do not overlap significantly." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Linear_Linear_Algebra.txt> ;
            ns1:ku_text """Pages: 191-192 HOURS CS Core = 5 KA Core = 35 MSF-Linear: Linear Algebra CS
Core: 1\\. Vectors: definitions, vector operations, geometric interpretation,
angles: Matrices: definition, matrix operations, meaning of Ax=b. KA Core: 2\\.
Matrices, matrix-vector equation, geometric interpretation, geometric
transformations with matrices 3\\. Solving equations, row-reduction 4\\. Linear
independence, span, basis 5\\. Orthogonality, projection, least-squares,
orthogonal bases 6\\. Linear combinations of polynomials, Bezier curves 7\\.
Eigenvectors and eigenvalues 8\\. Applications to computer science: Principal
Components Analysis (PCA), Singular Value Decomposition (SVD), page-rank,
graphics Illustrative Learning Outcomes: CS Core: 1\\. Vectors: definitions,
vector operations, geometric interpretation, angles a. Describe algebraic and
geometric representations of vectors in Rn and their operations, including
addition, scalar multiplication, and dot product. b. List properties of
vectors in Rn. c. Compute angles between vectors in Rn. KA Core: 2\\. Matrices,
matrix-vector equation, geometric interpretation, geometric transformations
with matrices a. Perform common matrix operations, such as addition, scalar
multiplication, multiplication, and transposition. b. Relate a matrix to a
homogeneous system of linear equations. c. Recognize when two matrices can be
multiplied. d. Relate various matrix transformations to geometric
illustrations. 3\\. Solving equations, row-reduction a. Formulate, solve,
apply, and interpret properties of linear systems. b. Perform row operations
on a matrix. c. Relate an augmented matrix to a system of linear equations. d.
Solve linear systems of equations using the language of matrices. e. Translate
word problems into linear equations. f. Perform Gaussian elimination. 4\\.
Linear independence, span, basis a. Define subspace of a vector space. b. List
examples of subspaces of a vector space. c. Recognize and use basic properties
of subspaces and vector spaces. d. Determine if specific subsets of a vector
space are subspaces. e. Discuss the existence of a basis of an abstract vector
space. f. Describe coordinates of a vector relative to a given basis. g.
Determine a basis for and the dimension of a finite-dimensional space. h.
Discuss spanning sets for vectors in Rn. i. Discuss linear independence for
vectors in Rn. j. Define the dimension of a vector space. 5\\. Orthogonality,
projection, least-squares, orthogonal bases a. Explain the Gram-Schmidt
orthogonalization process. b. Define orthogonal projections. c. Define
orthogonal complements. d. Compute the orthogonal projection of a vector onto
a subspace, given a basis for the subspace. e. Explain how orthogonal
projections relate to least square approximations. 6\\. Linear combinations of
polynomials, Bezier curves a. Identify polynomials as generalized vectors. b.
Explain linear combinations of basic polynomials. c. Describe orthogonality
for polynomials. d. Distinguish between basic polynomials and Bernstein
polynomials. e. Apply Bernstein polynomials to Bezier curves. 7\\. Eigenvectors
and eigenvalues a. Find the eigenvalues and eigenvectors of a matrix. b.
Define eigenvalues and eigenvectors geometrically. c. Use characteristic
polynomials to compute eigenvalues and eigenvectors. d. Use eigenspaces of
matrices, when possible, to diagonalize a matrix. e. Perform diagonalization
of matrices. f. Explain the significance of eigenvectors and eigenvalues. g.
Find the characteristic polynomial of a matrix. h. Use eigenvectors to
represent a linear transformation with respect to a particularly nice basis.
8\\. Applications to computer science: PCA, SVD, page-rank, graphics a. Explain
the geometric properties of PCA. b. Relate PCA to dimensionality reduction. c.
Relate PCA to solving least-squares problems. d. Relate PCA to solving
eigenvector problems. e. Apply PCA to reducing the dimensionality of a high-
dimensional dataset (e.g., images). f. Explain the page-rank algorithm and
understand how it relates to eigenvector problems. g. Explain the geometric
differences between SVD and PCA. h. Apply SVD to a concrete example (e.g.,
movie rankings)."""^^xsd:string ;
            ns1:score "0.6551864"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on electrical engineering topics, while the KU covers linear algebra." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Linear_Linear_Algebra" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers electrical engineering topics, while the KU focuses on programming concepts; they are unrelated." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Fundamental_Programming_Concepts_and_Practices.txt> ;
            ns1:ku_text """Pages : 168-169 CS Core : 20, KA Core : None CS Core: 1\\. Basic concepts such
as variables, primitive data types, expressions, and their evaluation 2\\. How
imperative programs work: state and state transitions on execution of
statements, flow of control 3\\. Basic constructs such as assignment
statements, conditional and iterative statements, basic I/O 4\\. Key modularity
constructs such as functions (and methods and classes, if supported in the
language) and related concepts like parameter passing, scope, abstraction,
data encapsulation (See also: FPL-OOP) 5\\. Input and output using files and
APIs 6\\. Structured data types available in the chosen programming language
like sequences (e.g., arrays, lists), associative containers (e.g.,
dictionaries, maps), others (e.g., sets, tuples) and when and how to use them
(See also: AL-Foundational) 7\\. Libraries and frameworks provided by the
language (when/where applicable) 8\\. Recursion 9\\. Dealing with runtime errors
in programs (e.g., exception handling). 10\\. Basic concepts of programming
errors, testing, and debugging (See also: SE-Construction, SEC-Coding) 11\\.
Documenting/commenting code at the program and module level.(See also: SE-
Construction) 12\\. Develop a security mindset. (See also: SEC-Foundations)
Illustrative Learning Outcomes: CS Core: In these learning outcomes, the term
"develop" means "design, write, test, and debug." 1\\. Develop programs that
use the fundamental programming constructs: assignment and expressions, basic
I/O, conditional and iterative statements. 2\\. Develop programs using
functions with parameter passing. 3\\. Develop programs that effectively use
the different structured data types provided in the language like
arrays/lists, dictionaries, and sets. 4\\. Develop programs that use file I/O
to provide data persistence across multiple executions. 5\\. Develop programs
that use language-provided libraries and frameworks (where applicable). 6\\.
Develop programs that use APIs to access or update data (e.g., from the web).
7\\. Develop programs that create simple classes and instantiate objects of
those classes (if supported by the language). 8\\. Explain the concept of
recursion and identify when and how to use it effectively. 9\\. Develop
recursive functions. 10\\. Develop programs that can handle runtime errors.
11\\. Read a given program and explain what it does. 12\\. Write comments for a
program or a module specifying what it does. 13\\. Trace the flow of control
during the execution of a program. 14\\. Use appropriate terminology to
identify elements of a program (e.g., identifier, operator, operand)."""^^xsd:string ;
            ns1:score "0.6567445"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on electrical engineering/mathematics, KU covers programming fundamentals. No overlap." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Fundamental_Programming_Concepts_and_Practices" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns1:uetext """Label: Electricité et outils mathématiques associés Objectif: (résultats d'apprentissage)
chimique, énergie mécanique).
● saura déterminer les caractéristiques d'un signal sinusoïdal à partir de son expression
mathématique : amplitude, valeur efficace, période, fréquence, pulsation, phase à l'origine
● saura déterminer les caractéristiques d'un signal sinusoïdal à partir de son oscillogramme
● saura déterminer les déphasages entre deux signaux synchrones à partir de leurs expressions
mathématiques ou à partir de leurs oscillogrammes
● saura déterminer l'impédance complexe équivalente d'un groupement d'impédances en série
et/ou en parallèle
● saura déterminer par la méthode des nombres complexes les tensions et les courants dans un
circuit en régime sinusoïdal
● saura effectuer un calcul de puissance active par une méthode directe ou à partir du théorème de Course content: 2. Les conducteurs ohmiques ou résistances
3. Les générateurs
4. Les récepteurs
5. Méthodes de résolution de circuits électriques Course name: http://example.org/course/UE_XLG1PU020""" .

ns2:UE_XLG1PU030 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as formal automata, formal languages, and decidability, but does not exhaustively cover all aspects of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits and tools, while KU covers formal languages, automata theory, computability, and theoretical proofs. No substantial overlap." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as formal automata, formal languages, and decidability, but does not exhaustively cover all aspects of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, not covering the formal automata, languages, and computability topics of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as formal automata, formal languages, and decidability, but does not exhaustively cover all aspects of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, not covering the formal automata, languages, and computability topics of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, not covering the formal automata, languages, and computability topics of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, not covering the formal automata, languages, and computability topics of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits and tools, while KU covers formal languages, automata theory, computability, and theoretical proofs. No substantial overlap." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as formal automata, formal languages, and decidability, but does not exhaustively cover all aspects of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits and tools, while KU covers formal languages, automata theory, computability, and theoretical proofs. No substantial overlap." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits and tools, while KU covers formal languages, automata theory, computability, and theoretical proofs. No substantial overlap." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits/Boolean algebra, while KU covers logic programming theory (unification, Horn clauses, Prolog concepts). No substantial overlap." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as formal automata, formal languages, and decidability, but does not exhaustively cover all aspects of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on digital logic circuits and tools, while KU covers formal languages, automata theory, computability, and theoretical proofs. No substantial overlap." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as simplifying Boolean expressions, designing digital circuits, and using logical connectives, which align with the KU's objectives." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6762781"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.6881512"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, while the KU covers logic programming concepts." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Algorithmic_Foundations_AL/AL-Models_Computational_Models_and_Formal_Languages.txt> ;
            ns1:ku_text """Pages:93-95 HOURS CS Core = 9 KA Core = 23 AL-Models: Computational Models and
Formal Languages CS Core: 1\\. Formal automata a. Finite State b. Pushdown c.
Linear Bounded d. Turing Machine 2\\. Formal languages, grammars and Chomsky
Hierarchy (See also: FPL-Translation, FPL-Syntax) a. Regular (Type-3) i.
Regular Expressions b. Context-Free (Type-2) c. Context-Sensitive (Type-1) d.
Recursively Enumerable (Type-0) 3\\. Relations among formal automata,
languages, and grammars 4\\. Decidability, (un)computability, and halting 5\\.
The Church-Turing thesis 6\\. Algorithmic correctness a. Invariants (e.g., in
iteration, recursion, tree search) KA Core: 7\\. Deterministic and
nondeterministic automata 8\\. Pumping Lemma proofs a. Proof of Finite
State/Regular-Language limitation b. Pushdown Automata/Context-Free-Language
limitation 9\\. Decidability a. Arithmetization and diagonalization 10\\.
Reducibility and reductions 11\\. Time complexity based on Turing Machine 12\\.
Space complexity (e.g., Pspace, Savitch's Theorem) 13\\. Equivalent models of
algorithmic computation a. Turing Machines and Variations (e.g., multi-tape,
non-deterministic) b. Lambda Calculus (See also: FPL-Functional) c. Mu-
Recursive Functions Non-core: 14\\. Quantum computation (See also: AR-Quantum)
a. Postulates of quantum mechanics i. State space 94 ii. State evolution iii.
State composition iv. State measurement b. Column vector representations of
qubits c. Matrix representations of quantum operations d. Simple quantum gates
(e.g., XNOT, CNOT) Illustrative Learning Outcomes: CS Core: 1\\. For each
formal automaton in this unit: a. Explain its definition comparing its
characteristics with this unit's other automata, b. Using an example, explain
step-by-step how the automaton operates on input including whether it accepts
the associated input, c. Explain an example of inputs that can and cannot be
accepted by the automaton. 2\\. Given a problem, develop an appropriate
automaton that addresses the problem. 3\\. Develop a regular expression for a
given regular language expressed in natural language. 4\\. Explain the
difference between regular expressions (Type-3 acceptors) and the regular
expressions (Type-2 acceptors) used in programming languages. 5\\. For each
formal model in this unit: a. Explain its definition comparing its
characteristics with the others in this unit, b. Explain example inputs that
are and cannot be accepted by the language/grammar. 6\\. Explain a universal
Turing Machine and its operation. 7\\. Present to an audience of co-workers and
managers the impossibility of providing them a program that checks all other
programs, including some seemingly simple ones, for infinite loops including
an explanation of the Halting problem, why it has no algorithmic solution, and
its significance for real-world algorithmic computation. 8\\. Explain examples
of classic uncomputable problems. 9\\. Explain the Church-Turing Thesis and its
significance for algorithmic computation. 10\\. Explain how (loop) invariants
can be used to prove the correctness of an algorithm. Illustrative Learning
Outcomes: KA Core: 11\\. For each formal automaton in this unit explain
(compare/contrast) its deterministic and nondeterministic capabilities. 12\\.
Apply pumping lemmas, or alternative means, to prove the limitations of Finite
State and Pushdown automata. 13\\. Apply arithmetization and diagonalization to
prove the Halting Problem for Turing Machines is Undecidability. 14\\. Given a
known undecidable language, apply a mapping reduction or computational history
to prove that another language is undecidable. 15\\. Convert among equivalently
powerful notations for a language, including among DFAs, NFAs, and regular
expressions, and between PDAs and CFGs. 16\\. Explain Rice's theorem and its
significance. 95 17\\. Explain an example proof of a problem that is
uncomputable by reducing a classic known uncomputable problem to it. 18\\.
Explain the Primitive and General Recursive functions (zero, successor,
selection, primitive recursion, composition, and Mu), their significance, and
Turing Machine implementations. 19\\. Explain how computation is performed in
Lambda Calculus (e.g., Alpha conversion and Beta reduction) Non-core: 20\\. For
a quantum system give examples that explain the following postulates. a. State
Space - system state represented as a unit vector in Hilbert space, b. State
Evolution - the use of unitary operators to evolve system state, c. State
Composition - the use of tensor product to compose systems states, d. State
Measurement - the probabilistic output of measuring a system state. 21\\.
Explain the operation of a quantum XNOT or CNOT gate on a quantum bit
represented as a matrix and column vector, respectively"""^^xsd:string ;
            ns1:score "0.6994029"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on digital logic and circuit design, not covering the formal automata, languages, and computability topics of the KU." ;
            ns2:ka "Algorithmic_Foundations_AL" ;
            ns2:ku "AL-Models_Computational_Models_and_Formal_Languages" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext """Label: Base de logique numérique Objectif: (résultats d'apprentissage)
- simplifier au maximum une expression booléenne en utilisant l’algèbre de Boole
- simplifier au maximum une expression booléenne en utilisant la méthode de Karnaugh
- dessiner un circuit à base de portes logiques élémentaires à partir des fonctions booléennes des
sorties du circuit
- redessiner un circuit composé de portes logiques élémentaires en n’utilisant qu’un seul type de
porte logique (opérateur complet, porte synonyme)
- faire une simulation d’un circuit avec le logiciel Quartus Prime
- implanter un circuit dans une carte électronique à partir du logiciel Quartus Prime Course content: • Identité de fonctions logiques par analyse de leur table de vérité
• Détermination de l’expression booléenne d’une fonction logique à partir de sa table de vérité
• Tables de Karnaugh Course name: http://example.org/course/UE_XLG1PU030""" .

ns2:UE_XLG1TU050 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific technical topics outlined in the Knowledge Unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific technical topics outlined in the Knowledge Unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap; lecture focuses on teaching methods, not graphics/visualization topics." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform/programming specifics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform/programming specifics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap; lecture focuses on teaching methods, not graphics/visualization topics." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap; lecture focuses on teaching methods, not graphics/visualization topics." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform/programming specifics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap; lecture focuses on teaching methods, not graphics/visualization topics." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform/programming specifics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap; lecture focuses on teaching methods, not graphics/visualization topics." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific technical topics outlined in the Knowledge Unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific technical topics outlined in the Knowledge Unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform/programming specifics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6435205"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not substantially cover the detailed technical content of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods, not formal methods in software engineering." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6363587"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.62948024"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific technical topics outlined in the Knowledge Unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext "Label: Stage libre Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG1TU050" .

ns2:UE_XLG1TU060 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in core topics; lecture focuses on study/professional skills, not usability/human factors principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional methodology and career skills, while the KU covers SE-Usability and Human Factors, which are not addressed in the lecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general professional skills and does not cover the specific legal and ethical topics of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to time management, teamwork, and self-awareness, which align with the KU's focus on formal methods and core concepts in computer science." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on soft skills and career preparation, while the KU covers technical computer science topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to intellectual property, plagiarism, and professional work ethics, which are also part of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap on ethics/legal topics (IP, plagiarism, professional codes). Lecture focuses on study skills, collaboration, and personal development." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in core topics; lecture focuses on study/professional skills, not usability/human factors principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general professional skills and does not cover the specific legal and ethical topics of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional methodology and career skills, while the KU covers SE-Usability and Human Factors, which are not addressed in the lecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on methodology and professional insertion, whereas the KU covers SE-Usability and Human Factors, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in core topics; lecture focuses on study/professional skills, not usability/human factors principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general professional skills and does not cover the specific legal and ethical topics of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on methodology and professional insertion, whereas the KU covers SE-Usability and Human Factors, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap on ethics/legal topics (IP, plagiarism, professional codes). Lecture focuses on study skills, collaboration, and personal development." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on soft skills and career preparation, while the KU covers technical computer science topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on study/professional skills, KU covers formal methods in SE." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on study/professional skills, KU covers formal methods in SE." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on methodology and professional insertion, whereas the KU covers SE-Usability and Human Factors, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to intellectual property, plagiarism, and professional work ethics, which are also part of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on methodology and professional insertion, whereas the KU covers SE-Usability and Human Factors, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional methodology and career skills, while the KU covers SE-Usability and Human Factors, which are not addressed in the lecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on study/professional skills, KU covers formal methods in SE." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to intellectual property, plagiarism, and professional work ethics, which are also part of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to time management, teamwork, and self-awareness, which align with the KU's focus on formal methods and core concepts in computer science." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on study/professional skills, KU covers formal methods in SE." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general professional skills and does not cover the specific legal and ethical topics of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to intellectual property, plagiarism, and professional work ethics, which are also part of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to time management, teamwork, and self-awareness, which align with the KU's focus on formal methods and core concepts in computer science." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to time management, teamwork, and self-awareness, which align with the KU's focus on formal methods and core concepts in computer science." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on soft skills and career preparation, while the KU covers technical computer science topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional methodology and career skills, while the KU covers SE-Usability and Human Factors, which are not addressed in the lecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap on ethics/legal topics (IP, plagiarism, professional codes). Lecture focuses on study skills, collaboration, and personal development." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6801524"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on soft skills and career preparation, while the KU covers technical computer science topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.67398083"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in core topics; lecture focuses on study/professional skills, not usability/human factors principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6652237"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap on ethics/legal topics (IP, plagiarism, professional codes). Lecture focuses on study skills, collaboration, and personal development." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns1:uetext """Label: Méthodologie et insertion professionnelle S1 Objectif: (résultats d'apprentissage) distanciel, portfolio
- d'utiliser les outils de la bibliothèque universitaire et d'en comprendre les apports et le
fonctionnement
- de comprendre le fonctionnement cérébral et les types de mémoire pour les exploiter au mieux
- de collaborer dans le cadre d'un projet simple en communiquant avec ses collaborateurs Course content: - la gestion du temps et du stress
- le travail de groupe et le travail en équipe
- serious game à la BU
sur le second semestre :
- identifier ses préférences de fonctionnement avec ses compétences et points de vigilance
- réaliser un CV complet et identifier les éléments constitutifs indispensables Course name: http://example.org/course/UE_XLG1TU060""" .

ns2:UE_XLG2AU050 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including deterministic and stochastic grammars, parsing algorithms, and semantic representations, as well as information retrieval, language translation, and text classification." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applying principles in practical scenarios, and analyzing the importance of this topic in computing, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter; lecture focuses on teaching methods, while KU addresses SE-Formal Methods in CS." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture and KU are unrelated." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter; lecture focuses on teaching methods, while KU addresses SE-Formal Methods in CS." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter; lecture focuses on teaching methods, KU on programming platforms." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, while KU covers technical NLP concepts." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture and KU are unrelated." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture and KU are unrelated." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture and KU are unrelated." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, while KU covers technical NLP concepts." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture content does not cover the technical aspects of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods in English, which does not cover the technical NLP topics outlined in the Knowledge Unit." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods in English, which does not cover the technical NLP topics outlined in the Knowledge Unit." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, while KU covers technical NLP concepts." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture content does not cover the technical aspects of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applying principles in practical scenarios, and analyzing the importance of this topic in computing, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including deterministic and stochastic grammars, parsing algorithms, and semantic representations, as well as information retrieval, language translation, and text classification." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods in English, which does not cover the technical NLP topics outlined in the Knowledge Unit." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applying principles in practical scenarios, and analyzing the importance of this topic in computing, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on teaching methods in English, which does not cover the technical NLP topics outlined in the Knowledge Unit." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, while KU covers technical NLP concepts." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter; lecture focuses on teaching methods, while KU addresses SE-Formal Methods in CS." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including deterministic and stochastic grammars, parsing algorithms, and semantic representations, as well as information retrieval, language translation, and text classification." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter; lecture focuses on teaching methods, KU on programming platforms." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture content does not cover the technical aspects of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter; lecture focuses on teaching methods, KU on programming platforms." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-NLP_Natural_Language_Processing.txt> ;
            ns1:ku_text """Pages:79-80 HOURS CS Core = 0 KA Core = 0 AI-NLP: Natural Language Processing
Non-core: 1\\. Deterministic and stochastic grammars 2\\. Parsing algorithms a.
CFGs and chart parsers (e.g., CYK) b. Probabilistic CFGs and weighted CYK 3\\.
Representing meaning/Semantics a. Logic-based knowledge representations b.
Semantic roles c. Temporal representations d. Beliefs, desires, and intentions
4\\. Corpus-based methods 5\\. N-grams and HMMs 6\\. Smoothing and backoff 7\\.
Examples of use: POS tagging and morphology 8\\. Information retrieval (See
also: DM-Unstructured) a. Vector space model i. TF & IDF b. Precision and
recall 9\\. Information extraction 10\\. Language translation 11\\. Text
classification, categorization a. Bag of words model 12\\. Deep learning for
NLP (See also: AI-ML) a. RNNs b. Transformers c. Multi-modal embeddings (e.g.,
images + text) d. Generative language models Illustrative Learning Outcomes:
1\\. Define and contrast deterministic and stochastic grammars, providing
examples to show the adequacy of each. 2\\. Simulate, apply, or implement
classic and stochastic algorithms for parsing natural language. 3\\. Identify
the challenges of representing meaning. 4\\. List the advantages of using
standard corpora. Identify examples of current corpora for a variety of NLP
tasks. 5\\. Identify techniques for information retrieval, language
translation, and text classification. 6\\. Implement a TF/IDF transform, use it
to extract features from a corpus, and train an off-the-shelf machine learning
algorithm using those features to do text classification."""^^xsd:string ;
            ns1:score "0.63803875"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including deterministic and stochastic grammars, parsing algorithms, and semantic representations, as well as information retrieval, language translation, and text classification." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-NLP_Natural_Language_Processing" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applying principles in practical scenarios, and analyzing the importance of this topic in computing, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63651514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter; lecture focuses on teaching methods, while KU addresses SE-Formal Methods in CS." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in subject matter; lecture focuses on teaching methods, KU on programming platforms." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.63916475"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture content does not cover the technical aspects of the Knowledge Unit." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext "Label: 1st year English S2 Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG2AU050" .

ns2:UE_XLG2HU010 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some historical aspects but lacks coverage of modern computing developments." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.72681695"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.695742"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Covers early algorithm history but lacks later eras (PC, internet, AI) and societal context depth required by KU." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Society_Ethics_and_the_Profession_SEP/SEP-History.txt> ;
            ns1:ku_text """Pages : 220-221 CS Core : 1, KA Core : 1 History is important because it
provides a mechanism for understanding why our computing systems operate the
way they do, the societal contexts in which current approaches arose, and how
those continue to echo through the discipline today. Not only does computing
affect society but vice-versa, resulting in a complex socio-technical context
that is constantly changing, requiring the perspective of history to put the
present, as well as possible futures, into appropriate perspective. It also
informs decisions based on successes and failures of the past including harm
done and how to not repeat them. The history of computing is often taught in
context with foundational concepts, such as system fundamentals and software
development fundamentals. A focus should be placed on those who, due to
marginalization, have not historically featured as prominently as they should.
CS Core: 1\\. The history of computing: hardware, software, and
human/organizational. 2\\. The role of history in the present including within
different social contexts, and the relevance of this history on the future. KA
Core: 3\\. Age I (Pre-digital): Ancient analog computing (Stonehenge,
Antikythera mechanism, Salisbury Cathedral clock, etc.), human-calculated
number tables, Euclid, Lovelace, Babbage, Godel, Church, Turing, pre-
electronic (electro-mechanical and mechanical) hardware 4\\. Age II (Early
modern computing): ENIAC, UNIVAC, Bombes (Bletchley Park and codebreakers),
computer companies (e.g., IBM), mainframes, etc. 5\\. Age III (PC era): PCs,
modern computer hardware and software, Moore's Law 6\\. Age IV (Internet):
Networking, internet architecture, browsers and their evolution, standards,
born-on-the-internet companies, and services (e.g., Google, Amazon, Microsoft,
etc.), distributed computing 7\\. Age V (Mobile & Cloud): Mobile computing and
smartphones, cloud computing and models thereof (e.g., SaaS), remote servers,
security and privacy, social media 8\\. Age VI (AI): Decision making systems,
recommender systems, generative AI and other machine learning driven tools and
technologies Illustrative Learning Outcomes: CS Core: 1\\. Understand the
relevance and impact of computing history on recent events, present context,
and possible future outcomes, from more than one cultural perspective. 2\\.
Discuss how perspectives held today have been shaped by history, and that
alternative perspectives exist (e.g., fears of AI replacing human workers vs
AI augmenting human work, various views on Moore's Law). KA Core: 3\\. Identify
formative and consequential trends in the history of the computing field. 4\\.
Identify the contributions of pioneering individuals or organizations
(research labs, computer companies, government offices) in the computing
field. 5\\. Discuss the historical context for important moments in history of
computing, such as the move from vacuum tubes to transistors (TRADIC), early
seminal operating systems (e.g., OS 360), Xerox PARC and the first Apple
computer with a GUI, the creation of specific programming language paradigms,
the first computer virus, the creation of the internet, the creation of the
WWW, the dot com bubble, Y2K, the introduction of smartphones, etc. 6\\.
Compare daily life before and after the advent of milestone developments
(e.g., personal computers or the internet)."""^^xsd:string ;
            ns1:score "0.7054188"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the history of algorithms, including ancient, medieval, and modern periods, which aligns with the KU's Age I-VI framework." ;
            ns2:ka "Society_Ethics_and_the_Profession_SEP" ;
            ns2:ku "SEP-History" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ] ;
    ns1:uetext """Label: HST : Histoire des algorithmes Objectif: (résultats d'apprentissage)
• Réfléchir à la fiabilité des sources d'information et à la diversité des interprétations possibles
d'une même source en fonction du contexte
• Comprendre l'historicité des objets et concepts, appréhender les changements des sociétés
humaines et, par conséquence, s'y adapter
• Analyser les paradigmes scientifiques et systèmes de pensée et saisir leur relation aux contextes
sociaux, culturels et temporels de leur production Course content: Histoire des algorithmes sur le temps long où sont abordées les thématiques suivantes :
• Des algorithmes dans l’Antiquité ? Les cas de la Mésopotamie, l’Égypte et la Grèce
• Algorithmes et mathématiques arabes
• Algorithmes de calcul et numération du Moyen Âge au XIXe s.
• Mécanisation du calcul du XVIIe s. au XIXe s.
• Vers le concept d’algorithme
• Des machines analytiques aux ordinateurs
• Une histoire de la cryptologie du Moyen Âge au XXe s. Course name: http://example.org/course/UE_XLG2HU010""" .

ns2:UE_XLG2HU020 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to the KU, such as the importance of understanding historicity and the role of context in scientific paradigms, which align with the KU's focus on SE-Maintenance and Evolution." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/social context of scientific concepts, while KU addresses formal methods in computing—no direct overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of science and energy, not machine learning." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the knowledge unit's content on SE-Formal Methods." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to the KU, such as the importance of understanding historicity and the role of context in scientific paradigms, which align with the KU's focus on SE-Maintenance and Evolution." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of science and technology, while the KU is about software engineering maintenance and evolution, which are not covered." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical scientific concepts while KU addresses software maintenance" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of science and energy, not machine learning." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/social context of scientific concepts, while KU addresses formal methods in computing—no direct overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/social context of scientific concepts, while KU addresses formal methods in computing—no direct overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/science studies aspects, while KU covers technical ML concepts (algorithms, evaluation, ethics in ML) not addressed." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical scientific concepts while KU addresses software maintenance" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of science and energy, not machine learning." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to the KU, such as the importance of understanding historicity and the role of context in scientific paradigms, which align with the KU's focus on SE-Maintenance and Evolution." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/science studies aspects, while KU covers technical ML concepts (algorithms, evaluation, ethics in ML) not addressed." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/science studies aspects, while KU covers technical ML concepts (algorithms, evaluation, ethics in ML) not addressed." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical scientific concepts while KU addresses software maintenance" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/social context of scientific concepts, while KU addresses formal methods in computing—no direct overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical scientific concepts while KU addresses software maintenance" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to energy, historicity, and scientific paradigms, which align with the KU's focus on formal methods and core concepts in computer science." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to energy, historicity, and scientific paradigms, which align with the KU's focus on formal methods and core concepts in computer science." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of science and technology, while the KU is about software engineering maintenance and evolution, which are not covered." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the knowledge unit's content on SE-Formal Methods." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/science studies aspects, while KU covers technical ML concepts (algorithms, evaluation, ethics in ML) not addressed." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to energy, historicity, and scientific paradigms, which align with the KU's focus on formal methods and core concepts in computer science." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to the KU, such as the importance of understanding historicity and the role of context in scientific paradigms, which align with the KU's focus on SE-Maintenance and Evolution." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of science and technology, while the KU is about software engineering maintenance and evolution, which are not covered." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of science and energy, not machine learning." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the knowledge unit's content on SE-Formal Methods." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Maintenance_and_Evolution.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Maintenance and Evolution:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Maintenance and Evolution. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.63342"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of science and technology, while the KU is about software engineering maintenance and evolution, which are not covered." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Maintenance_and_Evolution" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to energy, historicity, and scientific paradigms, which align with the KU's focus on formal methods and core concepts in computer science." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.63546336"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6345667"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the knowledge unit's content on SE-Formal Methods." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext """Label: HST : Matière et énergie Objectif: (résultats d'apprentissage) - Être actif face aux changements et agir en acteur socialement responsable
• Réfléchir à la fiabilité des sources d'information et à la diversité des interprétations possibles
d'une même source en fonction du contexte
• Comprendre l'historicité des objets et concepts, appréhender les changements des sociétés
humaines et, par conséquence, s'y adapter
• Analyser les paradigmes scientifiques et systèmes de pensée et saisir leur relation aux contextes
sociaux, culturels et temporels de leur production Course content: scolastique médiévale, sciences expérimentales à l’époque moderne, conceptions de la matière pour
les naturalistes du XIXe siècle. Plusieurs séances développeront des aspects appliqués des "techno-
sciences" à travers les techniques de l’énergie : machines à vapeur et révolution industrielle au Course name: http://example.org/course/UE_XLG2HU020""" .

ns2:UE_XLG2HU030 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers social responsibility and historical context but does not address programming language specifics." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts related to SE-Usability and Human Factors, such as understanding the historicity of objects and concepts, analyzing paradigms, and adapting to changing contexts, which aligns with the KU's core concepts and illustrative learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts related to SE-Usability and Human Factors, such as understanding the historicity of objects and concepts, analyzing paradigms, and adapting to changing contexts, which aligns with the KU's core concepts and illustrative learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on societal adaptation and historical context, while KU addresses programming language inclusivity/technical accessibility specifics not directly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on societal adaptation and historical context, while KU addresses programming language inclusivity/technical accessibility specifics not directly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical/social analysis, KU on technical usability principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts related to SE-Usability and Human Factors, such as understanding the historicity of objects and concepts, analyzing paradigms, and adapting to changing contexts, which aligns with the KU's core concepts and illustrative learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts related to SE-Usability and Human Factors, such as understanding the historicity of objects and concepts, analyzing paradigms, and adapting to changing contexts, which aligns with the KU's core concepts and illustrative learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, not software architecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on societal adaptation and historical context, while KU addresses programming language inclusivity/technical accessibility specifics not directly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on societal adaptation and historical context, while KU addresses programming language inclusivity/technical accessibility specifics not directly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, while the KU covers software engineering and usability, indicating minimal overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to societal responsibility, historicity, and paradigm analysis, which align with the KU's focus on ethics, accessibility, and inclusivity." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, while the KU covers software engineering and usability, indicating minimal overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical/social analysis, KU on technical usability principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No technical overlap; lecture focuses on societal/historical analysis, while KU requires software architecture concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to societal responsibility, historicity, and paradigm analysis, which align with the KU's focus on ethics, accessibility, and inclusivity." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, while the KU covers software engineering and usability, indicating minimal overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers social responsibility and historical context but does not address programming language specifics." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, not software architecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts related to SE-Usability and Human Factors, such as understanding the historicity of objects and concepts, analyzing paradigms, and adapting to changing contexts, which aligns with the KU's core concepts and illustrative learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, not software architecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, while the KU covers software engineering and usability, indicating minimal overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No technical overlap; lecture focuses on societal/historical analysis, while KU requires software architecture concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical/social analysis, KU on technical usability principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No technical overlap; lecture focuses on societal/historical analysis, while KU requires software architecture concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical/social analysis, KU on technical usability principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, not software architecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture's objectives align with the KU's learning outcomes, covering topics such as reliability of sources, historicity, and scientific paradigms, which are also present in the KU's concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers social responsibility and historical context but does not address programming language specifics." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture's objectives align with the KU's learning outcomes, covering topics such as reliability of sources, historicity, and scientific paradigms, which are also present in the KU's concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts related to SE-Usability and Human Factors, such as understanding the historicity of objects and concepts, analyzing paradigms, and adapting to changing contexts, which aligns with the KU's core concepts and illustrative learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No technical overlap; lecture focuses on societal/historical analysis, while KU requires software architecture concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture's objectives align with the KU's learning outcomes, covering topics such as reliability of sources, historicity, and scientific paradigms, which are also present in the KU's concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, while the KU covers software engineering and usability, indicating minimal overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to societal responsibility, historicity, and paradigm analysis, which align with the KU's focus on ethics, accessibility, and inclusivity." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to societal responsibility, historicity, and paradigm analysis, which align with the KU's focus on ethics, accessibility, and inclusivity." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers social responsibility and historical context but does not address programming language specifics." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on societal adaptation and historical context, while KU addresses programming language inclusivity/technical accessibility specifics not directly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, while the KU covers software engineering and usability, indicating minimal overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers social responsibility and historical context but does not address programming language specifics." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No technical overlap; lecture focuses on societal/historical analysis, while KU requires software architecture concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, not software architecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture's objectives align with the KU's learning outcomes, covering topics such as reliability of sources, historicity, and scientific paradigms, which are also present in the KU's concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on societal adaptation and historical context, while KU addresses programming language inclusivity/technical accessibility specifics not directly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to societal responsibility, historicity, and paradigm analysis, which align with the KU's focus on ethics, accessibility, and inclusivity." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture's objectives align with the KU's learning outcomes, covering topics such as reliability of sources, historicity, and scientific paradigms, which are also present in the KU's concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical context and social responsibility, not software architecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical/social analysis, KU on technical usability principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to societal responsibility, historicity, and paradigm analysis, which align with the KU's focus on ethics, accessibility, and inclusivity." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-SEP_Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages: 147 HOURS CS Core = SEP hours KA Core = SEP hours FPL-SEP: Society,
Ethics, and the Profession Non-core: 1\\. Impact of English-centric programming
languages 2\\. Enhancing accessibility and inclusivity for people with
disabilities - Supporting assistive technologies 3\\. Human factors related to
programming languages and usability a. Impact of syntax on accessibility b.
Supporting cultural differences (e.g., currency, decimals, dates) c.
Neurodiversity 4\\. Etymology of terms such as "class," "master," and "slave"
in programming languages 5\\. Increasing accessibility by supporting multiple
languages within applications (UTF) Illustrative learning outcomes: Non-core:
1\\. Consciously design programming languages to be inclusive and non-
offensive."""^^xsd:string ;
            ns1:score "0.64542603"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers social responsibility and historical context but does not address programming language specifics." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-SEP_Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture's objectives align with the KU's learning outcomes, covering topics such as reliability of sources, historicity, and scientific paradigms, which are also present in the KU's concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.6591502"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on historical/social analysis, KU on technical usability principles." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Software_Architecture.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Software Architecture: Core
Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Software Architecture. 2\\. Apply principles in practical scenarios. 3\\.
Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64193225"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No technical overlap; lecture focuses on societal/historical analysis, while KU requires software architecture concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Software_Architecture" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns1:uetext """Label: HST : Savoir-faire et innovation Objectif: (résultats d'apprentissage) - Être actif face aux changements et agir en acteur socialement responsable
• Réfléchir à la fiabilité des sources d'information et à la diversité des interprétations possibles
d'une même source en fonction du contexte
• Comprendre l'historicité des objets et concepts, appréhender les changements des sociétés
humaines et, par conséquence, s'y adapter
• Analyser les paradigmes scientifiques et systèmes de pensée et saisir leur relation aux contextes
sociaux, culturels et temporels de leur production Course content: contexte de l’époque où les acteurs (savants ou ingénieurs) et les institutions jouent un rôle majeur. Course name: http://example.org/course/UE_XLG2HU030""" .

ns2:UE_XLG2HU040 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on scientific reasoning and historical context, while the KU covers technical machine learning topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU is about formal methods in software engineering, which are distinct areas." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU is about formal methods in software engineering, which are distinct areas." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on history/philosophy of scientific reasoning, while KU addresses technical formal methods in software engineering. No substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of scientific reasoning, historicity, and paradigms, which align with the KU's core concepts and advanced topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU is about formal methods in software engineering, which are distinct areas." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU is about formal methods in software engineering, which are distinct areas." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of scientific reasoning, historicity, and paradigms, which align with the KU's core concepts and advanced topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on scientific reasoning and historical context, while the KU covers technical machine learning topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/philosophical scientific reasoning, while KU covers HCI evaluation methods, statistical tests, and ethics in design. No substantial overlap." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on history/philosophy of scientific reasoning, while KU addresses technical formal methods in software engineering. No substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on the history and philosophy of scientific reasoning styles, whereas the KU covers a broader range of topics, including evaluation methods, study planning, and data management." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of scientific reasoning, historicity, and paradigms, which align with the KU's core concepts and advanced topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on philosophy/history of science, not technical ML concepts like algorithms, evaluation, or ethics in ML as in KU." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on history/philosophy of scientific reasoning, while KU addresses technical formal methods in software engineering. No substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on scientific reasoning and historical context, while the KU covers technical machine learning topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on scientific reasoning and historical context, while the KU covers technical machine learning topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on the history and philosophy of scientific reasoning styles, whereas the KU covers a broader range of topics, including evaluation methods, study planning, and data management." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on philosophy/history of science, not technical ML concepts like algorithms, evaluation, or ethics in ML as in KU." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on history/philosophy of scientific reasoning, while KU addresses technical formal methods in software engineering. No substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on philosophy/history of science, not technical ML concepts like algorithms, evaluation, or ethics in ML as in KU." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on philosophy/history of science, not technical ML concepts like algorithms, evaluation, or ethics in ML as in KU." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/philosophical scientific reasoning, while KU covers HCI evaluation methods, statistical tests, and ethics in design. No substantial overlap." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU covers practical evaluation methods in design and user research." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on the history and philosophy of scientific reasoning styles, whereas the KU covers a broader range of topics, including evaluation methods, study planning, and data management." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU covers practical evaluation methods in design and user research." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/philosophical scientific reasoning, while KU covers HCI evaluation methods, statistical tests, and ethics in design. No substantial overlap." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on philosophy/history of science, not technical ML concepts like algorithms, evaluation, or ethics in ML as in KU." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU covers practical evaluation methods in design and user research." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU covers practical evaluation methods in design and user research." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on the history and philosophy of scientific reasoning styles, whereas the KU covers a broader range of topics, including evaluation methods, study planning, and data management." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of scientific reasoning, historicity, and paradigms, which align with the KU's core concepts and advanced topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on scientific reasoning and historical context, while the KU covers technical machine learning topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of scientific reasoning, historicity, and paradigms, which align with the KU's core concepts and advanced topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on the history and philosophy of scientific reasoning styles, whereas the KU covers a broader range of topics, including evaluation methods, study planning, and data management." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on history/philosophy of scientific reasoning, while KU addresses technical formal methods in software engineering. No substantial overlap." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/philosophical scientific reasoning, while KU covers HCI evaluation methods, statistical tests, and ethics in design. No substantial overlap." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-ML_Machine_Learning.txt> ;
            ns1:ku_text """Pages:71-75 HOURS CS Core = 4 KA Core = 6 AI-ML: Machine Learning CS Core: 1\\.
Definition and examples of a broad variety of machine learning tasks a.
Supervised learning i. Classification ii. Regression b. Reinforcement learning
c. Unsupervised learning i. Clustering 2\\. Fundamental ideas: a. No free lunch
theorem: no one learner can solve all problems; representational design
decisions have consequences. b. Sources of error and undecidability in machine
learning 3\\. A simple statistical-based supervised learning such as linear
regression or decision trees a. Focus on how they work without going into
mathematical or optimization details; enough to understand and use existing
implementations correctly 4\\. The overfitting problem/controlling solution
complexity (regularization, pruning - intuition only) a. The bias
(underfitting) - variance (overfitting) tradeoff 5\\. Working with Data a. Data
preprocessing i. Importance and pitfalls of preprocessing choices b. Handling
missing values (imputing, flag-as-missing) i. Implications of imputing vs
flag-as-missing c. Encoding categorical variables, encoding real-valued data
d. Normalization/standardization e. Emphasis on real data, not textbook
examples 6\\. Representations a. Hypothesis spaces and complexity b. Simple
basis feature expansion, such as squaring univariate features c. Learned
feature representations 7\\. Machine learning evaluation a. Separation of
train, validation, and test sets b. Performance metrics for classifiers c.
Estimation of test performance on held-out data d. Tuning the parameters of a
machine learning model with a validation set e. Importance of understanding
what a model is doing, where its pitfalls/shortcomings are, and the
implications of its decisions 8\\. Basic neural networks a. Fundamentals of
understanding how neural networks work and their training process, without
details of the calculations b. Basic introduction to generative neural
networks (e.g., large language models) 9\\. Ethics for Machine Learning (See
also: SEP-Context) a. Focus on real data, real scenarios, and case studies b.
Dataset/algorithmic/evaluation bias and unintended consequences 72 KA Core:
10\\. Formulation of simple machine learning as an optimization problem, such
as least squares linear regression or logistic regression a. Objective
function b. Gradient descent c. Regularization to avoid overfitting
(mathematical formulation) 11\\. Ensembles of models a. Simple weighted
majority combination 12\\. Deep learning a. Deep feed-forward networks
(intuition only, no mathematics) b. Convolutional neural networks (intuition
only, no mathematics) c. Visualization of learned feature representations from
deep nets d. Other architectures (generative NN, recurrent NN, transformers,
etc.) 13\\. Performance evaluation a. Other metrics for classification (e.g.,
error, precision, recall) b. Performance metrics for regressors c. Confusion
matrix d. Cross-validation i. Parameter tuning (grid/random search, via cross-
validation) 14\\. Overview of reinforcement learning methods 15\\. Two or more
applications of machine learning algorithms a. E.g., medicine and health,
economics, vision, natural language, robotics, game play 16\\. Ethics for
Machine Learning a. Continued focus on real data, real scenarios, and case
studies (See also: SEP-Context) b. Privacy (See also: SEP-Privacy) c. Fairness
(See also: SEP-Privacy) d. Intellectual property e. Explainability Non-core:
17\\. General statistical-based learning, parameter estimation (maximum
likelihood) 18\\. Supervised learning a. Decision trees b. Nearest-neighbor
classification and regression c. Learning simple neural networks / multi-layer
perceptrons d. Linear regression e. Logistic regression f. Support vector
machines (SVMs) and kernels g. Gaussian Processes 19\\. Overfitting a. The
curse of dimensionality b. Regularization (mathematical computations, L2 and
L1 regularization) 20\\. Experimental design 73 a. Data preparation (e.g.,
standardization, representation, one-hot encoding) b. Hypothesis space c.
Biases (e.g., algorithmic, search) d. Partitioning data: stratification,
training set, validation set, test set e. Parameter tuning (grid/random
search, via cross-validation) f. Performance evaluation i. Cross-validation
ii. Metric: error, precision, recall, confusion matrix iii. Receiver operating
characteristic (ROC) curve and area under ROC curve 21\\. Bayesian learning
(Cross-Reference AI/Reasoning Under Uncertainty) a. Naive Bayes and its
relationship to linear models b. Bayesian networks c. Prior/posterior d.
Generative models 22\\. Deep learning a. Deep feed-forward networks b. Neural
tangent kernel and understanding neural network training c. Convolutional
neural networks d. Autoencoders e. Recurrent networks f. Representations and
knowledge transfer g. Adversarial training and generative adversarial networks
h. Attention mechanisms 23\\. Representations a. Manually crafted
representations b. Basis expansion c. Learned representations (e.g., deep
neural networks) 24\\. Unsupervised learning and clustering a. K-means b.
Gaussian mixture models c. Expectation maximization (EM) d. Self-organizing
maps 25\\. Graph analysis (e.g., PageRank) 26\\. Semi-supervised learning 27\\.
Graphical models (See also: AI-Probability) 28\\. Ensembles a. Weighted
majority b. Boosting/bagging c. Random forest d. Gated ensemble 29\\. Learning
theory a. General overview of learning theory / why learning works b. VC
dimension c. Generalization bounds 74 30\\. Reinforcement learning a.
Exploration vs exploitation tradeoff b. Markov decision processes c. Value and
policy iteration d. Policy gradient methods e. Deep reinforcement learning f.
Learning from demonstration and inverse RL 31\\. Explainable / interpretable
machine learning a. Understanding feature importance (e.g., LIME, Shapley
values) b. Interpretable models and representations 32\\. Recommender systems
33\\. Hardware for machine learning a. GPUs / TPUs 34\\. Application of machine
learning algorithms to: a. Medicine and health b. Economics c. Education d.
Vision e. Natural language f. Robotics g. Game play h. Data mining (Cross-
reference DM/Data Analytics) 35\\. Ethics for Machine Learning a. Continued
focus on real data, real scenarios, and case studies (See also: SEP-Context)
b. In depth exploration of dataset/algorithmic/evaluation bias, data privacy,
and fairness (See also: SEP-Privacy, SEP-Context) c. Trust / explainability
Illustrative Learning Outcomes: 1\\. Describe the differences among the three
main styles of learning (supervised, reinforcement, and unsupervised) and
determine which is appropriate to a particular problem domain. 2\\.
Differentiate the terms of AI, machine learning, and deep learning. 3\\. Frame
an application as a classification problem, including the available input
features and output to be predicted (e.g., identifying alphabetic characters
from pixel grid input). 4\\. Apply two or more simple statistical learning
algorithms to a classification task and measure the classifiers' accuracy. 5\\.
Identify overfitting in the context of a problem and learning curves and
describe solutions to overfitting. 6\\. Explain how machine learning works as
an optimization/search process. 7\\. Implement a statistical learning algorithm
and the corresponding optimization process to train the classifier and obtain
a prediction on new data. 8\\. Describe the neural network training process and
resulting learned representations. 75 9\\. Explain proper ML evaluation
procedures, including the differences between training and testing
performance, and what can go wrong with the evaluation process leading to
inaccurate reporting of ML performance. 10\\. Compare two machine learning
algorithms on a dataset, implementing the data preprocessing and evaluation
methodology (e.g., metrics and handling of train/test splits) from scratch.
11\\. Visualize the training progress of a neural network through learning
curves in a well-established toolkit (e.g., TensorBoard) and visualize the
learned features of the network. 12\\. Compare and contrast several learning
techniques (e.g., decision trees, logistic regression, naive Bayes, neural
networks, and belief networks), providing examples of when each strategy is
superior. 13\\. Evaluate the performance of a simple learning system on a real-
world dataset. 14\\. Characterize the state of the art in learning theory,
including its achievements and shortcomings. 15\\. Explain the problem of
overfitting, along with techniques for detecting and managing the problem.
16\\. Explain the triple tradeoff among the size of a hypothesis space, the
size of the training set, and performance accuracy. 17\\. Given a real-world
application of machine learning, describe ethical issues regarding the choices
of data, preprocessing steps, algorithm selection, and
visualization/presentation of results"""^^xsd:string ;
            ns1:score "0.65409935"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as machine learning, supervised and unsupervised learning, neural networks, and ethics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-ML_Machine_Learning" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on historical/philosophical scientific reasoning, while KU covers HCI evaluation methods, statistical tests, and ethics in design. No substantial overlap." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.65138584"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU is about formal methods in software engineering, which are distinct areas." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Human_Computer_Interaction_HCI/HCI-Evaluation_Evaluating_the_Design.txt> ;
            ns1:ku_text """Pages: 178-179 HOURS CS Core = 1 KA Core = 2 HCI-Evaluation: Evaluating the
Design CS Core: 1\\. Methods for evaluation with users a. Formative (e.g.,
needs-finding, exploratory analysis) and summative assessment (e.g.,
functionality and usability testing) b. Elements to evaluate (e.g., utility,
efficiency, learnability, user satisfaction, affective elements such as
pleasure and engagement) c. Understanding ethical approval requirements before
engaging in user research (See also: SETools, SEP-Ethical-Analysis, SEP-
Security, SEP-Privacy, SEP-Professional-Ethics) KA Core: 2\\. Methods for
evaluation with users (See also: SE-Validation) a. Qualitative methods
(qualitative coding and thematic analysis) b. Quantitative methods
(statistical tests) c. Mixed methods (e.g., observation, think-aloud,
interview, survey, experiment) d. Presentation requirements (e.g., reports,
personas) e. User-centered testing f. Heuristic evaluation g. Challenges and
shortcomings to effective evaluation (e.g., sampling, generalization) 3\\.
Study planning a. How to set study goals b. Hypothesis design c. Approvals
from Institutional Research Boards and ethics committees (See also: SEP-
EthicalAnalysis, SEP-Security, SEP-Privacy) d. How to pre-register a study e.
Within-subjects vs between-subjects design 4\\. Implications and impacts of
design with respect to the environment, material, society, security, privacy,
ethics, and broader impacts. (See also: SEC-Foundations) a. The environment b.
Material c. Society d. Security e. Privacy f. Ethics g. Broader impacts Non-
core: 5\\. Techniques and tools for quantitative analysis a. Statistical
packages b. Visualization tools c. Statistical tests (e.g., ANOVA, t-tests,
post-hoc analysis, parametric vs non-parametric tests) d. Data exploration and
visual analytics; how to calculate effect size. 6\\. Data management a. Data
storage and data sharing (open science) b. Sensitivity and identifiability.
Illustrative Learning Outcomes: CS Core: 1\\. Discuss the differences between
formative and summative assessment and their role in evaluating design KA
Core: 2\\. Select appropriate formative or summative evaluation methods at
different points throughout the development of a design. 3\\. Discuss the
benefits of using both qualitative and quantitative methods for evaluation.
4\\. Evaluate the implications and broader impacts of a given design. 5\\. Plan
a usability evaluation for a given user interface, and justify its study
goals, hypothesis design, and study design. 6\\. Conduct a usability evaluation
of a given user interface and draw defensible conclusions given the study
design. Non-core: 7\\. Select and run appropriate statistical tests on provided
study data to test for significance in the results. 8\\. Pre-register a study
design, with planned statistical tests"""^^xsd:string ;
            ns1:score "0.6456514"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on historical and philosophical aspects of scientific reasoning, while the KU covers practical evaluation methods in design and user research." ;
            ns2:ka "Human_Computer_Interaction_HCI" ;
            ns2:ku "HCI-Evaluation_Evaluating_the_Design" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext """Label: HST : Styles de raisonnement scientifiques Objectif: (résultats d'apprentissage) - Être actif face aux changements et agir en acteur socialement responsable
• Réfléchir à la fiabilité des sources d'information et à la diversité des interprétations possibles
d'une même source en fonction du contexte
• Comprendre l'historicité des objets et concepts, appréhender les changements des sociétés
humaines et, par conséquence, s'y adapter
• Analyser les paradigmes scientifiques et systèmes de pensée et saisir leur relation aux contextes
sociaux, culturels et temporels de leur production
- Histoire et philosophie des styles de raisonnement scientifiques.
- Philosophie des sciences exactes. Course content: Le cours présente l'émergence des cadres d'objectivité, dont le calcul
des probabilités, la modélisation et l'expérience, de l'Antiquité à nos jours. Course name: http://example.org/course/UE_XLG2HU040""" .

ns2:UE_XLG2IU010 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture title mentions algorithms but lacks explicit coverage of specific KU topics like algorithm efficiency, examples (sorting/searching), or performance impact details." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the KU's focus on SE-Formal Methods and its applications." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of this topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of this topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture title mentions algorithms but lacks explicit coverage of specific KU topics like algorithm efficiency, examples (sorting/searching), or performance impact details." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as universal vs existential quantifiers, first-order predicate logic, and unification, which are core components of the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific technical details of the Knowledge Unit." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the fundamental concepts of algorithms, including their role in writing programs, and explains some common algorithms, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as universal vs existential quantifiers, first-order predicate logic, and unification, which are core components of the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers algorithmics, which is central to the KU's focus on algorithms and their efficiency." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the fundamental concepts of algorithms, including their role in writing programs, and explains some common algorithms, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the KU's focus on SE-Formal Methods and its applications." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific technical details of the Knowledge Unit." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the specific technical details of the Knowledge Unit." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics: lecture focuses on algorithmic/development methods, while KU covers formal methods in SE." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers algorithmics, which is central to the KU's focus on algorithms and their efficiency." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on general algorithm development, while KU specifies logic programming concepts (unification, Horn clauses, etc.) not explicitly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture title mentions algorithms but lacks explicit coverage of specific KU topics like algorithm efficiency, examples (sorting/searching), or performance impact details." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on general algorithm development, while KU specifies logic programming concepts (unification, Horn clauses, etc.) not explicitly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics: lecture focuses on algorithmic/development methods, while KU covers formal methods in SE." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as universal vs existential quantifiers, first-order predicate logic, and unification, which are core components of the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics: lecture focuses on algorithmic/development methods, while KU covers formal methods in SE." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers algorithmics, which is central to the KU's focus on algorithms and their efficiency." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Logic_Logic_Programming.txt> ;
            ns1:ku_text """Pages: 133 HOURS CS Core = 0 KA Core = 2 + 1 (MSF) FPL-Logic: Logic
Programming KA Core: 1\\. Universal vs existential quantifiers. (See also: AI-
LRR, MSF-Discrete) 2\\. First order predicate logic vs higher order logic. (See
also: AI-LRR, MSF-Discrete) 3\\. Expressing complex relations using logical
connectives and simpler relations. 4\\. Definitions of Horn clause, facts,
goals and subgoals. 5\\. Unification and unification algorithm; unification vs
assertion vs expression evaluation. 6\\. Mixing relations with functions. (See
also: MSF-Discrete) 7\\. Cuts, backtracking, and non-determinism. 8\\. Closed-
world vs open-world assumptions. Non-core: 9\\. Memory overhead of variable
copying in handling iterative programs. 10\\. Programming constructs to store
partial computation and pruning search trees. 11\\. Mixing functional
programming and logic programming using concepts such as equational logic,
narrowing, residuation, and semantic unification. (See also: FPL-Functional)
12\\. Higher-order, constraint, and inductive logic programming. (See also: AI-
LRR) 13\\. Integration with other programming paradigms such as object-oriented
programming. 14\\. Advance programming constructs such as difference-lists,
creating user defined data structures, set of, etc. Illustrative learning
outcomes: KA Core: 1\\. Use a logic language to implement a conventional
algorithm. 2\\. Use a logic language to implement an algorithm employing
implicit search using clauses, relations, and cuts. 3\\. Use a simple
illustrative example to show correspondence between First Order Predicate
Logic (FOPL) and logic programs using Horn clauses. 4\\. Use examples to
illustrate the unification algorithm and its role of parameter-passing in
query reduction. 5\\. Use simple logic programs interleaving relations,
functions, and recursive programming such as factorial and Fibonacci numbers
and simple complex relationships between entities and illustrate execution and
parameter-passing using unification and backtracking. Non-core: 6\\. Illustrate
computation of simple programs such as Fibonacci and show overhead of
recomputation, and then show how to improve execution overhead."""^^xsd:string ;
            ns1:score "0.70347965"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on general algorithm development, while KU specifies logic programming concepts (unification, Horn clauses, etc.) not explicitly covered." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Logic_Logic_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of this topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Algorithms.txt> ;
            ns1:ku_text """Page : 170 CS Core : 6, KA Core : None CS Core: (See also: AL-Foundational,
AL-Complexity) 1\\. Concept of algorithm and notion of algorithm efficiency 2\\.
Some common algorithms (e.g., sorting, searching, tree traversal, graph
traversal) 3\\. Impact of algorithms on time-space efficiency of programs
Illustrative Learning Outcomes: CS Core: 1\\. Explain the role of algorithms
for writing programs. 2\\. Demonstrate how a problem may be solved by different
algorithms, each with different properties. 3\\. Explain some common algorithms
(e.g., sorting, searching, tree traversal, graph traversal). 4\\. Explain the
impact on space/time performance of some algorithms."""^^xsd:string ;
            ns1:score "0.68321896"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the fundamental concepts of algorithms, including their role in writing programs, and explains some common algorithms, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Algorithms" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6851368"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the KU's focus on SE-Formal Methods and its applications." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext "Label: Algorithmique et developpement Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG2IU010" .

ns2:UE_XLG2IU020 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the course content, including key concepts, principles, and importance of SE-Formal Methods, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on databases, while the KU covers development platforms and programming." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Topics unrelated (databases vs. 3D modeling)" ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture on databases does not cover the 3D modeling topics outlined in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on databases while KU is about formal methods in SE" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on databases, while KU covers development platforms, APIs, and programming constraints unrelated to databases." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the course content, including key concepts, principles, and importance of SE-Formal Methods, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on databases while KU is about formal methods in SE" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture on databases does not cover the 3D modeling topics outlined in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers databases, while the KU focuses on SE-Formal Methods, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics; lecture focuses on databases while KU is about formal methods in SE" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the core concepts of GIT-3D Modeling, which aligns with the key concepts and principles mentioned in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on databases, while the KU covers development platforms and programming." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, and platform languages, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on databases, while the KU covers development platforms and programming." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the core concepts of GIT-3D Modeling, which aligns with the key concepts and principles mentioned in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers databases, while the KU focuses on SE-Formal Methods, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Topics unrelated (databases vs. 3D modeling)" ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on databases, while KU covers development platforms, APIs, and programming constraints unrelated to databases." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the core concepts of GIT-3D Modeling, which aligns with the key concepts and principles mentioned in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the course content, including key concepts, principles, and importance of SE-Formal Methods, which aligns with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Topics unrelated (databases vs. 3D modeling)" ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-3D_Modeling.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD GIT-3D Modeling: Core Concepts CS
Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic 3
KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of GIT-3D Modeling.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6338726"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture on databases does not cover the 3D modeling topics outlined in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-3D_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.649452"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on databases, while KU covers development platforms, APIs, and programming constraints unrelated to databases." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64770865"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers databases, while the KU focuses on SE-Formal Methods, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext "Label: Bases de donnees 1 Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG2IU020" .

ns2:UE_XLG2IU030 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the course content, including key concepts and practical applications, which aligns with the Knowledge Unit's objectives." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the course content, including key concepts and practical applications, which aligns with the Knowledge Unit's objectives." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on computer operation, not development platforms/programming constraints outlined in KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on computer operation, while KU covers functional programming concepts like lambda calculus and closures, which are unrelated." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overall concepts of development platforms, programming languages, and constraints, matching the KU's objectives." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Topics mismatch: computers' functioning vs. formal methods in SE" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on computer operation, not development platforms/programming constraints outlined in KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overall concepts of development platforms, programming languages, and constraints, matching the KU's objectives." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on computer functionality, while the KU covers development platforms and programming specifics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overall concepts of development platforms, programming languages, and constraints, matching the KU's objectives." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers basic computer operation, while the KU focuses on formal methods in software engineering." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on computer operation, not development platforms/programming constraints outlined in KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as lambda expressions, effect-free programming, and higher-order functions, which are core to the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers basic computer operation, while the KU focuses on formal methods in software engineering." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as lambda expressions, effect-free programming, and higher-order functions, which are core to the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the detailed functional programming concepts outlined in the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Topics mismatch: computers' functioning vs. formal methods in SE" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on computer functionality, while the KU covers development platforms and programming specifics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the detailed functional programming concepts outlined in the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on computer operation, while KU covers functional programming concepts like lambda calculus and closures, which are unrelated." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the course content, including key concepts and practical applications, which aligns with the Knowledge Unit's objectives." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on computer operation, while KU covers functional programming concepts like lambda calculus and closures, which are unrelated." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers a significant portion of the KU, including topics such as lambda expressions, effect-free programming, and higher-order functions, which are core to the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6372174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on computer functionality, while the KU covers development platforms and programming specifics." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Topics mismatch: computers' functioning vs. formal methods in SE" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Foundations_of_Programming_Languages_FPL/FPL-Functional_Functional_Programming.txt> ;
            ns1:ku_text """Pages: 131-132-133 HOURS CS Core = 4 KA Core = 3 FPL-Functional: Functional
Programming CS Core: 1\\. Lambda expressions and evaluation: (See also: AL-
Models, FPL-Formalism) a. Variable binding and scope rules. (See also: SDF-
Fundamentals) b. Parameter-passing. (See also: SDF-Fundamentals) c. Nested
lambda expressions and reduction order. 2\\. Effect-free programming: a.
Function calls have no side effects, facilitating compositional reasoning. b.
Immutable variables and data copying vs reduction. c. Use of recursion vs
loops vs pipelining (map/reduce). 3\\. Processing structured data (e.g., trees)
via functions with cases for each data variant: a. Functions defined over
compound data in terms of functions applied to the constituent pieces. b.
Persistent data structures. 4\\. Using higher-order functions (taking,
returning, and storing functions). KA Core: 5\\. Metaprogramming and
reflection. 6\\. Function closures (functions using variables in the enclosing
lexical environment). a. Basic meaning and definition - creating closures at
run-time by capturing the environment. b. Canonical idioms: call-backs,
arguments to iterators, reusable code via function arguments. c. Using a
closure to encapsulate data in its environment. d. Delayed versus eager
evaluation. Non-core: 7\\. Graph reduction machine and call-by-need. 8\\.
Implementing delayed evaluation. 9\\. Integration with logic programming
paradigm using concepts such as equational logic, narrowing, residuation and
semantic unification. (See also: FPL-Logic) 10\\. Integration with other
programming paradigms such as imperative and object-oriented. Illustrative
learning outcomes: CS Core: 1\\. Develop basic algorithms that avoid assigning
to mutable states or considering reference equality. 2\\. Develop useful
functions that take and return other functions. 3\\. Compare and contrast how
computational solutions to a problem differ in procedural, functional, and
object-oriented approaches. 4\\. Compare and contrast mechanisms to define and
protect data elements within procedural, functional, and object-oriented
approaches. KA Core: 5\\. Explain a simple example of lambda expression being
implemented using a virtual machine, such as a SECD machine, showing storage
and reclaim of the environment. 6\\. Correctly interpret variables and lexical
scope in a program using function closures. 7\\. Use functional encapsulation
mechanisms such as closures and modular interfaces. 8\\. Compare and contrast
stateful vs stateless execution. 9\\. Define and use iterators and other
operations on aggregates, including operations that take functions as
arguments, in multiple programming languages, selecting the most natural
idioms for each language. (See also: FPL-OOP) Non-core: 10\\. Illustrate graph
reduction using a l-expression using a shared subexpression. 11\\. Illustrate
the execution of a simple nested l-expression using an abstract machine, such
as an ABC machine. 12\\. Illustrate narrowing, residuation, and semantic
unification using simple illustrative examples. 13\\. Illustrate the
concurrency constructs using simple programming examples of known concepts
such as a buffer being read and written concurrently or sequentially. (See
also: FPL-OOP)"""^^xsd:string ;
            ns1:score "0.62810224"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the detailed functional programming concepts outlined in the KU." ;
            ns2:ka "Foundations_of_Programming_Languages_FPL" ;
            ns2:ku "FPL-Functional_Functional_Programming" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.64271784"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers basic computer operation, while the KU focuses on formal methods in software engineering." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext "Label: Fonctionnement des ordinateurs Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG2IU030" .

ns2:UE_XLG2IU040 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.67317307"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on theoretical foundations and teaching methods, not covering the detailed development platforms and programming specifics of the KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6612896"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers intellectual property rights, plagiarism, responsibility, and professional ethics, which are all key aspects of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6740174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers general theoretical foundations, while the KU focuses specifically on SE-Formal Methods and their practical applications, which are not substantially addressed in the lecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6612896"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on theoretical foundations, not specifically covering the detailed ethical and legal aspects outlined in the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6612896"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers intellectual property rights, plagiarism, responsibility, and professional ethics, which are all key aspects of the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.67317307"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the development platforms, programming via API, platform languages, and programming under constraints, which are all key aspects of the KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6612896"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on theoretical bases and teaching methods, while KU addresses ethics/professional responsibility." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6740174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers general theoretical foundations, while the KU focuses specifically on SE-Formal Methods and their practical applications, which are not substantially addressed in the lecture." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.67317307"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on theoretical foundations and teaching methods, not platform-specific programming constraints or languages detailed in KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.67317307"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on theoretical foundations and teaching methods, not covering the detailed development platforms and programming specifics of the KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6740174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods and theoretical bases, while KU requires formal methods concepts and application." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6740174"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods and theoretical bases, while KU requires formal methods concepts and application." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6612896"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on theoretical foundations, not specifically covering the detailed ethical and legal aspects outlined in the KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.6612896"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on theoretical bases and teaching methods, while KU addresses ethics/professional responsibility." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6740174"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the course content, including key concepts, principles, and importance of SE-Formal Methods, which aligns with the KU's objectives." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.67317307"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the development platforms, programming via API, platform languages, and programming under constraints, which are all key aspects of the KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6740174"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the course content, including key concepts, principles, and importance of SE-Formal Methods, which aligns with the KU's objectives." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.67317307"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on theoretical foundations and teaching methods, not platform-specific programming constraints or languages detailed in KU." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns1:uetext "Label: Bases theoriques de l'informatique Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG2IU040" .

ns2:UE_XLG2MU040 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers most of the topics listed in the KU, including sequences, series, limits, derivatives, integration, parametric and polar representations, Taylor series, multivariate calculus, and ordinary differential equations." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on mathematical concepts (functions, geometry, statistics), while KU covers data modeling, relational/ER models, and database structures." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers most of the topics listed in the KU, including sequences, series, limits, derivatives, integration, parametric and polar representations, Taylor series, multivariate calculus, and ordinary differential equations." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like integration and series but lacks substantial coverage of multivariate calculus, optimization, and ODEs." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like integration and series but lacks substantial coverage of multivariate calculus, optimization, and ODEs." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general mathematics for computer science, whereas the KU covers computer vision, audio and speech recognition, and other modalities, with no apparent overlap." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers some topics like integration and series but lacks substantial coverage of multivariate calculus, optimization, and ODEs." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers multivariate calculus and Taylor series but lacks core topics like single-variable calculus, ODEs, optimization, and detailed derivative/integration rules emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers multivariate calculus and Taylor series but lacks core topics like single-variable calculus, ODEs, optimization, and detailed derivative/integration rules emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers most of the topics listed in the KU, including sequences, series, limits, derivatives, integration, parametric and polar representations, Taylor series, multivariate calculus, and ordinary differential equations." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general mathematics for computer science, whereas the KU covers computer vision, audio and speech recognition, and other modalities, with no apparent overlap." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers foundational mathematics but not the specific AI-Vision topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers foundational mathematics but not the specific AI-Vision topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on mathematical foundations (e.g., functions, geometry) rather than AI/vision implementation and algorithms required by the KU." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on general mathematics for computer science, whereas the KU covers computer vision, audio and speech recognition, and other modalities, with no apparent overlap." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on mathematical concepts for computer science, whereas the KU covers data modeling, relational data models, and conceptual models, which are distinct topics." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on mathematical topics like calculus and statistics, which are foundational but do not cover the specific data modeling concepts described in the KU." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on mathematical concepts (functions, geometry, statistics), while KU covers data modeling, relational/ER models, and database structures." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on mathematical concepts for computer science, whereas the KU covers data modeling, relational data models, and conceptual models, which are distinct topics." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on mathematical foundations (e.g., functions, geometry) rather than AI/vision implementation and algorithms required by the KU." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture covers foundational mathematics but not the specific AI-Vision topics." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on mathematical concepts (functions, geometry, statistics), while KU covers data modeling, relational/ER models, and database structures." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on mathematical topics like calculus and statistics, which are foundational but do not cover the specific data modeling concepts described in the KU." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Artificial_Intelligence_AI/AI-Vision_Perception_and_Computer_Vision.txt> ;
            ns1:ku_text """Pages:82-83 HOURS CS Core = 0 KA Core = 0 AI-Vision: Perception and Computer
Vision Non-core: 1\\. Computer vision a. Image acquisition, representation,
processing, and properties b. Shape representation, object recognition, and
segmentation c. Motion analysis d. Generative models 2\\. Audio and speech
recognition 3\\. Touch and proprioception 4\\. Other modalities (e.g.,
olfaction) 5\\. Modularity in recognition 6\\. Approaches to pattern recognition
(See also: AI-ML) a. Classification algorithms and measures of classification
quality b. Statistical techniques c. Deep learning techniques Illustrative
Learning Outcomes: 1\\. Summarize the importance of image and object
recognition in AI and indicate several significant applications of this
technology. 2\\. List at least three image-segmentation approaches, such as
thresholding, edge-based and region- based algorithms, along with their
defining characteristics, strengths, and weaknesses. 3\\. Implement 2d object
recognition based on contour-based and/or region-based shape representations.
4\\. Distinguish the goals of sound-recognition, speech-recognition, and
speaker-recognition and identify how the raw audio signal will be handled
differently in each of these cases. 5\\. Provide at least two examples of a
transformation of a data source from one sensory domain to another, e.g.,
tactile data interpreted as single-band 2d images. 6\\. Implement a feature-
extraction algorithm on real data, e.g., an edge or corner detector for images
or vectors of Fourier coefficients describing a short slice of audio signal.
7\\. Implement an algorithm combining features into higher-level percepts,
e.g., a contour or polygon from visual primitives or phoneme hypotheses from
an audio signal. 8\\. Implement a classification algorithm that segments input
percepts into output categories and quantitatively evaluates the resulting
classification. 9\\. Evaluate the performance of the underlying feature-
extraction, relative to at least one alternative possible approach (whether
implemented or not) in its contribution to the classification task (8), above.
83 10\\. Describe at least three classification approaches, their prerequisites
for applicability, their strengths, and their shortcomings. 11\\. Implement and
evaluate a deep learning solution to problems in computer vision, such as
object or scene recognition."""^^xsd:string ;
            ns1:score "0.6949715"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on mathematical foundations (e.g., functions, geometry) rather than AI/vision implementation and algorithms required by the KU." ;
            ns2:ka "Artificial_Intelligence_AI" ;
            ns2:ku "AI-Vision_Perception_and_Computer_Vision" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on mathematical concepts for computer science, whereas the KU covers data modeling, relational data models, and conceptual models, which are distinct topics." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Mathematical_and_Statistical_Foundations_MSF/MSF-Calculus.txt> ;
            ns1:ku_text """Pages: 192-194 HOURS CS Core = 0 KA Core = 40 MSF-Calculus KA Core: 1\\.
Sequences, series, limits 2\\. Single-variable derivatives: definition,
computation rules (chain rule etc.), derivatives of important functions,
applications 3\\. Single-variable integration: definition, computation rules,
integrals of important functions, fundamental theorem of calculus, definite vs
indefinite, applications (including in probability) 4\\. Parametric and polar
representations 5\\. Taylor series 6\\. Multivariate calculus: partial
derivatives, gradient, chain-rule, vector valued functions, 7\\. Optimization:
convexity, global vs local minima, gradient descent, constrained optimization,
and Lagrange multipliers. 8\\. Ordinary Differential Equations (ODEs):
definition, Euler method, applications to simulation, Monte Carlo integration
9\\. CS applications: gradient descent for machine learning, forward and
inverse kinematics, applications of calculus to probability Note: the calculus
topics listed above are aligned with computer science goals rather than with
traditional calculus courses. For example, multivariate calculus is often a
course by itself, but computer science undergraduates only need parts of it
for machine learning. Illustrative Learning Outcomes: KA Core: 1\\. Sequences,
series, limits a. Explain the difference between infinite sets and sequences.
b. Explain the formal definition of a limit. c. Derive the limit for examples
of sequences and series. d. Explain convergence and divergence. e. Apply
L'Hospital's rule and other approaches to resolving limits. 2\\. Single-
variable derivatives: definition, computation rules (chain rule etc.),
derivatives of important functions, applications a. Explain a derivative in
terms of limits. b. Explain derivatives as functions. c. Perform elementary
derivative calculations from limits. d. Apply sum, product, and quotient
rules. e. Work through examples with important functions. 3\\. Single-variable
integration: definition, computation rules, integrals of important functions,
fundamental theorem of calculus, definite vs indefinite, applications
(including in probability) a. Explain the definitions of definite and
indefinite integrals. b. Apply integration rules to examples with important
functions. c. Explore the use of the fundamental theorem of calculus. d. Apply
integration to problems. 4\\. Parametric and polar representations a. Apply
parametric representations of important curves. b. Apply polar
representations. 5\\. Taylor series a. Derive Taylor series for some important
functions. b. Apply the Taylor series to approximations. 6\\. Multivariate
calculus: partial derivatives, gradient, chain-rule, vector valued functions,
applications to optimization, convexity, global vs local minima. a. Compute
partial derivatives and gradients. b. Work through examples with vector-valued
functions with gradient notation. c. Explain applications to optimization. 7\\.
ODEs: definition, Euler method, applications to simulation a. Apply the Euler
method to integration. b. Apply the Euler method to a single-variable
differential equation. c. Apply the Euler method to multiple variables in an
ODE."""^^xsd:string ;
            ns1:score "0.7347756"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture covers multivariate calculus and Taylor series but lacks core topics like single-variable calculus, ODEs, optimization, and detailed derivative/integration rules emphasized in KU." ;
            ns2:ka "Mathematical_and_Statistical_Foundations_MSF" ;
            ns2:ku "MSF-Calculus" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Date_Management_DM/DM-Modeling_Data_Modeling.txt> ;
            ns1:ku_text """Pages: 116-117 HOURS CS Core = 2 KA Core = 3 DM-Modeling: Data Modeling CS
Core: 1\\. Data modeling (See also: SE-Requirements) 2\\. Relational data model
(See also: MSF-Discrete) KA Core: 3\\. Conceptual models (e.g., entity-
relationship, UML diagrams) 4\\. Semi-structured data models (expressed using
DTD, XML, or JSON Schema, for example) Non-core: 5\\. Spreadsheet models 6\\.
Object-oriented models (See also: FPL-OOP) a. GraphQL 7\\. New features in SQL
8\\. Specialized Data Modeling topics a. Time series data (aggregation, join)
b. Graph data (link traversal) c. Techniques for avoiding inefficient raw data
access (e.g., "avg daily price"): materialized views and special data
structures (e.g., Hyperloglog, bitmap) d. Geo-Spatial data (e.g., GIS
databases) (See also: SPD-Interactive) Illustrative Learning Outcomes: CS
Core: 1\\. Describe the components of the relational data model. 2\\. Model 1:1,
1:n, and n:m relationships using the relational data model. KA Core: 3\\.
Describe the components of the E-R (or some other non-relational) data model.
4\\. Model a given environment using a conceptual data model. 5\\. Model a given
environment using the document-based or key-value store-based data model."""^^xsd:string ;
            ns1:score "0.6957394"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on mathematical topics like calculus and statistics, which are foundational but do not cover the specific data modeling concepts described in the KU." ;
            ns2:ka "Date_Management_DM" ;
            ns2:ku "DM-Modeling_Data_Modeling" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext """Label: Mathématiques générales pour l'informatique 2 Objectif: (résultats d'apprentissage)
formatique
• Développer une approche informatique pour analyser un problème mathématique
• Intégration.
• Séries. Applications : calcul des fonctions classiques, espérance d’une loi de prob-
bilité. Course content: • Développements limités.
• Fonctions de plusieurs variables. Application : surfaces, robotique.
• Géométrie dans le plan et l’espace. Application : manipulation d’images.
• Statistique élémentaire. Nuages de points, régression linéaire. Course name: http://example.org/course/UE_XLG2MU040""" .

ns2:UE_XLG2TU060 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics: lecture focuses on teaching methods, KU covers formal methods technical content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not provide enough detail to confirm substantial coverage of the KU content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform-specific programming constraints or languages." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics: lecture focuses on teaching methods, KU covers formal methods technical content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not address the specific topics of the Knowledge Unit." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not provide enough detail to confirm substantial coverage of the KU content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics: lecture focuses on teaching methods, KU covers formal methods technical content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not provide enough detail to confirm substantial coverage of the KU content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not graphics/visualization topics in KU" ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not address the specific topics of the Knowledge Unit." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers 7 out of 8 learning outcomes and 4 out of 5 fundamental concepts, substantially covering the knowledge described in the KU." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not address the specific topics of the Knowledge Unit." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics: lecture focuses on teaching methods, KU covers formal methods technical content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not graphics/visualization topics in KU" ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers key concepts of SE-Formal Methods, applies principles in practical scenarios, and analyzes the importance of the topic in computing, aligning with the KU's learning outcomes." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not provide enough detail to confirm substantial coverage of the KU content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not address the specific topics of the Knowledge Unit." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the technical details of the knowledge unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not address the specific topics of the Knowledge Unit." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform-specific programming constraints or languages." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not provide enough detail to confirm substantial coverage of the KU content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform-specific programming constraints or languages." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the technical details of the knowledge unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform-specific programming constraints or languages." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers the overview of development platforms, programming via platform-specific API, platform languages, and programming under platform constraints, which aligns with the KU's content." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Specialized_Platform_Development_SPD/SPD-Common_Aspects.txt> ;
            ns1:ku_text """Pages : 240-241 CS Core : 4, KA Core : 2 CS Core: 1\\. Overview of development
platforms (i.e., web, mobile, game, robotics, embedded, and interactive). a.
Input/sensors/control devices/haptic devices b. Resource constraints i.
Computational ii. Data storage iii. Memory iv. Communication c. Requirements -
security, uptime availability, fault tolerance (See also: SE-Reliability, SEC-
Engineering) d. Output/actuators/haptic devices 2\\. Programming via platform-
specific Application Programming Interface (API) vs traditional application
construction 3\\. Overview of platform Languages (e.g., Python, Swift, Lua,
Kotlin) 4\\. Programming under platform constraints and requirements (e.g.,
available development tools, development, security considerations) (See also:
SEC-Foundations) 5\\. Techniques for learning and mastering a platform-specific
programming language Illustrative Learning Outcomes: CS Core: 1\\. List the
constraints of mobile programming. 2\\. List the characteristics of scripting
languages. 3\\. Describe the three-tier model of web programming. 4\\. Describe
how the state is maintained in web programming."""^^xsd:string ;
            ns1:score "0.6463773"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not platform-specific programming constraints or languages." ;
            ns2:ka "Specialized_Platform_Development_SPD" ;
            ns2:ku "SPD-Common_Aspects" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.63994"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics: lecture focuses on teaching methods, KU covers formal methods technical content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the technical details of the knowledge unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the technical details of the knowledge unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not graphics/visualization topics in KU" ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not graphics/visualization topics in KU" ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teaching methods, not graphics/visualization topics in KU" ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Graphics_and_Interactive_Techniques_GIT/GIT-Fundamentals.txt> ;
            ns1:ku_text """Pages: 150-151 HOURS CS Core = 3 KA Core = 2 GIT-Fundamentals: Fundamental
Concepts CS Core: 1\\. Overview of graphics and visualization. 2\\. Basic
graphics pipeline architecture. 3\\. 2D and 3D transformations. 4\\.
Rasterization and rendering techniques. 5\\. Fundamental shading models. KA
Core: 6\\. Advanced rendering techniques. 7\\. Applications of visualization in
different fields. 8\\. Interaction methods for graphical environments.
Illustrative Learning Outcomes: 1\\. Explain the graphics rendering pipeline.
2\\. Differentiate between rasterization and ray tracing. 3\\. Apply
transformations to 2D and 3D models."""^^xsd:string ;
            ns1:score "0.6325534"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture does not cover the technical details of the knowledge unit." ;
            ns2:ka "Graphics_and_Interactive_Techniques_GIT" ;
            ns2:ku "GIT-Fundamentals" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ] ;
    ns1:uetext "Label: Stage libre Objectif: (résultats d'apprentissage) Course content: Méthodes d’enseignement Course name: http://example.org/course/UE_XLG2TU060" .

ns2:UE_XLG2TU090 ns1:to [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to teamwork, communication, and self-awareness, which align with the KU's focus on formal methods and core concepts in computing." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to teamwork, communication, and self-awareness, which align with the KU's focus on formal methods and core concepts in computing." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional integration and methodology, not covering SE-Usability and Human Factors." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on professional skills (CV, teamwork) while KU addresses SE-Usability/Human Factors technical concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on professional skills (CV, teamwork) while KU addresses SE-Usability/Human Factors technical concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to intellectual property, collaboration, and professional ethics, which align with the KU's objectives." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to intellectual property, collaboration, and professional ethics, which align with the KU's objectives." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional integration and methodology, not covering SE-Usability and Human Factors." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teamwork, CV creation, and self-assessment, not intellectual property, ethics, or professional responsibility covered in KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to teamwork, communication, and self-awareness, which align with the KU's focus on formal methods and core concepts in computing." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics (professional skills vs formal methods)" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on methodology and professional insertion, whereas the KU covers SE-Usability and Human Factors, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to intellectual property, collaboration, and professional ethics, which align with the KU's objectives." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on group work, self-assessment, and CV creation, while the KU covers intellectual property, plagiarism, and professional ethics, which are not addressed in the lecture." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional methodology and personal development, not covering the technical SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on group work, self-assessment, and CV creation, while the KU covers intellectual property, plagiarism, and professional ethics, which are not addressed in the lecture." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics (professional skills vs formal methods)" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to teamwork, communication, and self-awareness, which align with the KU's focus on formal methods and core concepts in computing." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional integration and methodology, not covering SE-Usability and Human Factors." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on methodology and professional insertion, whereas the KU covers SE-Usability and Human Factors, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on methodology and professional insertion, whereas the KU covers SE-Usability and Human Factors, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional methodology and personal development, not covering the technical SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on methodology and professional insertion, whereas the KU covers SE-Usability and Human Factors, which are distinct topics." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on group work, self-assessment, and CV creation, while the KU covers intellectual property, plagiarism, and professional ethics, which are not addressed in the lecture." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "1" ;
            ns2:explain "The lecture covers topics related to intellectual property, collaboration, and professional ethics, which align with the KU's objectives." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "llama3-8b-8192" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional methodology and personal development, not covering the technical SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional methodology and personal development, not covering the technical SE-Formal Methods content." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teamwork, CV creation, and self-assessment, not intellectual property, ethics, or professional responsibility covered in KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics (professional skills vs formal methods)" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teamwork, CV creation, and self-assessment, not intellectual property, ethics, or professional responsibility covered in KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on group work, self-assessment, and CV creation, while the KU covers intellectual property, plagiarism, and professional ethics, which are not addressed in the lecture." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on professional skills (CV, teamwork) while KU addresses SE-Usability/Human Factors technical concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on professional skills (CV, teamwork) while KU addresses SE-Usability/Human Factors technical concepts." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Formal_Methods.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Formal Methods: Core Concepts
CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\. Placeholder topic
3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder advanced topic 2
Illustrative Learning Outcomes: 1\\. Explain key concepts of SE-Formal Methods.
2\\. Apply principles in practical scenarios. 3\\. Analyze the importance of
this topic in computing."""^^xsd:string ;
            ns1:score "0.6641214"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "No overlap in topics (professional skills vs formal methods)" ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Formal_Methods" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Engineering_SE/SE-Usability_and_Human_Factors.txt> ;
            ns1:ku_text """Pages: TBD HOURS CS Core = TBD KA Core = TBD SE-Usability and Human Factors:
Core Concepts CS Core: 1\\. Placeholder topic 1 2\\. Placeholder topic 2 3\\.
Placeholder topic 3 KA Core: 4\\. Placeholder advanced topic 1 5\\. Placeholder
advanced topic 2 Illustrative Learning Outcomes: 1\\. Explain key concepts of
SE-Usability and Human Factors. 2\\. Apply principles in practical scenarios.
3\\. Analyze the importance of this topic in computing."""^^xsd:string ;
            ns1:score "0.64842355"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "The lecture focuses on professional integration and methodology, not covering SE-Usability and Human Factors." ;
            ns2:ka "Software_Engineering_SE" ;
            ns2:ku "SE-Usability_and_Human_Factors" ;
            ns3:wasGeneratedBy [ ns3:used "deepseek-r1-distill-llama-70b" ] ],
        [ ns1:ku_source <file:///Users/rekiknour/Desktop/STAGE/SLM-EXP/data/BodyOfKnowledge/Software_Development_Fundamentals_SDF/SDF-Society_Ethics_and_the_Profession.txt> ;
            ns1:ku_text """Pages : 171 CS Core : None, KA Core : None (Hours here are included in
Society, Ethics and the Profession Area) CS Core: 1\\. Intellectual property
rights of programmers for programs they develop. 2\\. Plagiarism and academic
integrity. 3\\. Responsibility and liability of programmers regarding code they
develop for solutions. (See also: SEC-Foundations) 4\\. Basic professional work
ethics of programmers. Illustrative Learning Outcomes: CS Core: 1\\.
Explain/understand some of the intellectual property issues relating to
programs. 2\\. Explain/understand when code developed by others can be used and
proper ways of disclosing their use. 3\\. Explain/understand the responsibility
of programmers when developing code for an overall solution (which may be
developed by a team). 4\\. Explain/understand one or more codes of conduct
applicable to programmers."""^^xsd:string ;
            ns1:score "0.65755624"^^xsd:float ;
            ns2:answer "0" ;
            ns2:explain "Lecture focuses on teamwork, CV creation, and self-assessment, not intellectual property, ethics, or professional responsibility covered in KU." ;
            ns2:ka "Software_Development_Fundamentals_SDF" ;
            ns2:ku "SDF-Society_Ethics_and_the_Profession" ;
            ns3:wasGeneratedBy [ ns3:used "qwen-qwq-32b" ] ] ;
    ns1:uetext """Label: Méthodologie et insertion professionnelle S2 Objectif: (résultats d'apprentissage)
fonctionnement
- de comprendre le fonctionnement cérébral et les types de mémoire pour les exploiter au mieux
- de collaborer dans le cadre d'un projet simple en communiquant avec ses collaborateurs
- d'expliquer ses principaux points forts et points de vigilance
- de réaliser une première version de Curriculum Vitae pour chercher un job étudiant ou un
premier stage Course content: - le travail de groupe et le travail en équipe
- serious game à la BU
sur le second semestre, 3 TD :
- identifier ses préférences de fonctionnement avec ses compétences et points de vigilance
- se projeter en prenant en compte ce que l'étudiant apprécie, sait faire et veut faire/vivre
- réaliser un CV complet et identifier les éléments constitutifs indispensables Course name: http://example.org/course/UE_XLG2TU090""" .

